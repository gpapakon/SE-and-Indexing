<DOC>
<DOCNO>EP-0642116</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Method of generating components of a speech database using the speech synthesis technique and machine for automatic speech recognition
</INVENTION-TITLE>
<CLASSIFICATIONS>G10L1500	G10L1506	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G10L	G10L	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G10L15	G10L15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
The invention relates to a method of generating components of a 
speech database using the speech synthesis technique and to a 

machine for automatic speech recognition. 
Asking a speaker to repeat speech elements on the basis of a 
preventive series of utterances corresponding to automatically 

synthesized utterances of said speech elements, the quality of 
the database thus obtained is better and uniform. 
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
CIT ALCATEL
</APPLICANT-NAME>
<APPLICANT-NAME>
ALCATEL
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
DI RONZA BENEDETTO
</INVENTOR-NAME>
<INVENTOR-NAME>
RICCIO ANTONELLO
</INVENTOR-NAME>
<INVENTOR-NAME>
DI RONZA, BENEDETTO
</INVENTOR-NAME>
<INVENTOR-NAME>
RICCIO, ANTONELLO
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to a method of generating
components of a speech database using the speech synthesis
technique and to a machine for automatic speech recognition.Basically, machines for speech recognition can be divided into
two categories: the first ones are based upon conventional
processors and realize the recognition by comparing the word to
be recognized with words of a pre-established vocabulary; the
second ones are based on special architectures such as neural
networks and the pre-established vocabulary depends on a set of
parameter values characterizing such architectures; hence the
first machines require the generation of a speech database
corresponding to the pre-established vocabulary for their
operation, while the second ones require the generation of a
suitable set of parameter values corresponding to the pre-established
vocabulary which could be considered as a distributed
speech database.As known, the generation of such databases, either concentrated
or distributed, occurs through long and repeated recording
operations; in general, a team of speakers is selected and each
speaker utters a number of times the speech elements
corresponding to a predetermined vocabulary (in general words or,
less frequently, the syllables); the acoustic signals
corresponding to such utterance are acquired and often tape-recorded; 
subsequently a processing step may follow consisting,
e.g., in a background noise filtering, in a sampling and in a
digitizing; lastly, the database real generation is carried out,
which may simply consist in storing on semiconductor storages
according to a pre-established format or, in addition to and
before storage, in the generation of suitable parameters, for
instance LPC (Linear Predictive Code), starting from the acquired
and processed acoustic signals ; in case of neural networks, the
generation of the distributed database occurs by directly providing
the network (that subsequently will carry out the
recognition) with the acquired and processed acoustic signals and
by leaving the network itself changing the values of its
parameters during a step called "training".The word "training", when referred to machines for speech
recognition belonging to the first category, indicates an
operative step during which the concentrated database is enhanced
with new utterances of speech elements belonging or not to the
predetermined vocabulary; not all such machines feature a
"training" step.The generation of such databases must be realized with great care
since the recognition
</DESCRIPTION>
<CLAIMS>
Method of generating a component of a speech database
corresponding to the utterance of a speech element,

comprising the steps of :

a) emitting an automatically synthesized utterance of said
speech element,
b) waiting for a speech acoustic signal corresponding to an
utterance of said speech element, and
c) acquiring said speech acoustic signal;
whereby such acquired speech acoustic signal conceptually

corresponds to said component.
Method according to claim 1, characterized in that said
acquired speech acoustic signal is processed.
Method according to claim 1, characterized in that it
further comprises the step of


d) verifying that said acquired speech acoustic signal
corresponds to an utterance of said speech elements

through comparison with said synthesized utterance.
Method according to claim 1, characterized in that, if said
step b) is longer than a predetermined period of time, said

step c) does not take place and such anomalous condition is
signalled.
Method according to claim 1, characterized in that said
synthesized utterance is so modified to be of unnatural type.
Method according to claim 1, characterized in that said step
a) is preceded by a step for extracting said utterance from

storage means. 
Method according to claim 1, characterized in that said step
a) is preceded by a step of automatic synthesizing said

utterance starting from the corresponding speech element.
Method of generating a speech database corresponding to a

predetermined vocabulary comprising a plurality of speech
elements, characterized in that said steps of the method of

claim 1 are repeated at least once for each speech element
of said vocabulary.
Method of enhancing a speech database corresponding to
utterances of speech elements belonging to a predetermined

vocabulary, through new utterances of speech elements
belonging or not to said vocabulary, characterized in that

the steps of the method of claim 1 are repeated for each new
utterance.
Machine for the automatic recognition of speech in relation
to a predetermined recognition vocabulary of speech

elements, characterized by

a) means for emitting automatically synthesized utterances of said
speech elements,
b) means for waiting for a speech acoustic signal corresponding to
an utterance of a said speech element, and
c) means for acquiring said speech acoustic signal, whereby such
acquired speech acoustic signal conceptually corresponds to

a component to be trained for said recognition vocabulary.
Machine according to claim 10, characterized in that it
comprises storage means designed to contain automatically

synthesized utterances of speech elements of said
recognition vocabulary.
Machine according to claim 10, characterized in that it
comprises an automatic speech synthesizer designed to

synthesize and emit utterances of speech elements even not
comprised in said recognition vocabulary.
</CLAIMS>
</TEXT>
</DOC>
