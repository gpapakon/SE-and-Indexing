<DOC>
<DOCNO>EP-0615227</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Speech coding apparatus using acoustic prototype vectors.
</INVENTION-TITLE>
<CLASSIFICATIONS>G10L1500	G10L1502	G10L1506	G10L1900	G10L1900	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G10L	G10L	G10L	G10L	G10L	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G10L15	G10L15	G10L15	G10L19	G10L19	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A speech coding apparatus in which measured acoustic feature 
vectors are each represented by the best matched prototype 

vector. The prototype vectors are generated by storing a model 
of a training script comprising a series of elementary models. 

The value of at least one feature of a training utterance of 
the training script is measured over each of a series of 

successive time intervals to produce a series of training 
feature vectors. A first set of training feature vectors 

corresponding to a first elementary model in the training 
script is identified. The feature value of each training 

feature vector signal in the first set is compared to the 
parameter value of a first reference vector signal to obtain a 

first closeness score, and is compared to the parameter value 
of a second reference vector to obtain a second closeness score 

for each training feature vector. For each training feature 
vector in the first set, the first closeness score is 

compared with the second closeness score to obtain a reference 
match score. A first subset contains those training feature 

vectors in the first set having reference match scores better 
than a threshold Q. A 
second subset contains those training 
feature vectors in a first set having reference match scores 

less than the threshold Q. One or more partition values are 
generated for a first prototype vector from the first subset of 

training feature vectors, and one or more additional partition 
values are generated for the first prototype vector from the 

second subset of training feature vectors. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
IBM
</APPLICANT-NAME>
<APPLICANT-NAME>
INTERNATIONAL BUSINESS MACHINES CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BAHL LALIT R
</INVENTOR-NAME>
<INVENTOR-NAME>
DE SOUZA PETER VINCENT
</INVENTOR-NAME>
<INVENTOR-NAME>
GOPALAKRISHNAN PONANI S
</INVENTOR-NAME>
<INVENTOR-NAME>
PICHENY MICHAEL ALAN
</INVENTOR-NAME>
<INVENTOR-NAME>
BAHL, LALIT R.
</INVENTOR-NAME>
<INVENTOR-NAME>
DE SOUZA, PETER VINCENT
</INVENTOR-NAME>
<INVENTOR-NAME>
GOPALAKRISHNAN, PONANI S.
</INVENTOR-NAME>
<INVENTOR-NAME>
PICHENY, MICHAEL ALAN
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The invention relates to speech coding, such as for a speech 
recognition system. The first step of speech recognition involves measuring the 
utterance to be recognized. A speech coding apparatus may 
measure, for example, the amplitude of the utterance to be 
recognized in one or more frequency bands during each of a 
series of time intervals (for example, ten-millisecond time 
intervals). Each measurement by the speech coding apparatus may 
be filtered, normalized, or otherwise manipulated to obtain 
desired speech information, with the result being stored as an 
acoustic feature vector. In a speech recognition apparatus, the acoustic feature vectors 
produced by the speech coder from an utterance to be recognized 
are compared to acoustic models of words to find the best 
matched models. In order to simplify the comparison, the 
acoustic feature vectors may be converted from continuous 
variables to discrete variables by vector quantization. The 
discrete variables may then be compared to the acoustic models. The acoustic feature vectors may be quantized by providing a 
finite set of prototype vectors. Each prototype vector has an 
identification (a label), and has one or more sets of parameter 
values. The value of an acoustic feature vector is compared to 
the parameter values of the prototype vectors to find the 
closest prototype vector. The identification (label) of the 
closest prototype vector is output as a coded representation of 
the acoustic feature vector.  Each prototype value may be obtained, for example, by averaging 
the values of a set of acoustic feature vectors corresponding 
to the prototype vector. Acoustic feature vectors may be 
correlated with prototype vectors, for example, by coding an 
utterance of a known training script by using an initial set of 
prototype vectors, and then finding the most probable alignment 
between the acoustic feature vectors and an acoustic model of 
the training script. It has been found, however, that a single average for each 
prototype vector does not accurately model the prototype 
vector. A better model is obtained if each prototype vector 
consists of a mixture of partitions obtained by dividing the 
set of acoustic feature vectors corresponding to the prototype 
vector into a number of clusters. The set of acoustic feature vectors corresponding to a 
prototype vector, may, for example, be grouped according to the 
context (for example, the preceding or following sounds) of 
each acoustic feature vector in the training script. Each 
context
</DESCRIPTION>
<CLAIMS>
A speech coding apparatus comprising: 
means for measuring the value of at least one feature of 

an utterance over each of a series of successive time 
intervals to produce a series of feature vector signals 

representing the feature values; 
means for storing a plurality of prototype vector signals, 

each prototype vector signal comprising at least two 
partitions and having an identification value, each 

partition having at least one parameter value; 
means for comparing the closeness of the feature value of 

a first feature vector signal to the parameter value of at 
least one partition of each prototype vector signal to 

obtain prototype match scores for the first feature vector 
signal and each prototype vector signal; and 

means for outputting at least the identification value of 
the prototype vector signal having the best prototype 

match score as a coded utterance representation signal of 
the first feature vector signal; 

characterized in that the apparatus further comprises 
means for generating the stored prototype vector signals, 

said prototype generating means comprising: 
means for storing a model of a training script, said 

training script model comprising a series of elementary 
models from a finite set of elementary models; 

means for measuring the value of at least one feature of a 
training utterance of the training script over each of a 

series of successive time intervals to produce a series of 
training feature vector signals representing the feature 

values;
 

means for identifying a first set of training feature 
vector signals corresponding to a first elementary model 

in the training script model; 
means for storing at least first and second reference 

vector signals, each reference vector signal having at 
least one parameter value; 

means for comparing the feature value of each training 
feature vector signal in the first set to the parameter 

value of the first reference vector signal to obtain a 
first closeness score for each training feature vector 

signal and the first reference vector signal; 
means for comparing the feature value of each training 

feature vector signal in the first set to the parameter 
value of the second reference vector signal to obtain a 

second closeness score for each training feature vector 
signal and the second reference vector signal; 

means for comparing, for each training feature vector 
signal in the first set, the first closeness score for the 

training feature vector signal with the second closeness 
score for the training feature vector signal to obtain a 

reference match score for each training feature vector 
signal and the first and second reference vector signals; 

means for storing a first subset of the training feature 
vector signals in the first set having reference match 

scores better than a threshold Q, and for storing a second 
subset of the training feature vector signals in the first 

set having reference match scores worse than the threshold 
Q; and 

means for generating one or more partition values for a 
first prototype vector signal from the first subset of 

training feature vector signals, and for generating one or 
more additional partition values for the first prototype 

vector signal from the second subset of training feature 
vector signals. 
A speech coding apparatus as claimed in Claim 1, 
characterized in that: 

each elementary model in the training script has a context 
comprising one or more preceding or following models in 

the training script; and 
the first set of training feature vector signals 

corresponds to a first elementary model in the training 
script in a first context. 
A speech coding apparatus as claimed in Claim 2, 
characterized in that: 

the parameter value of the first reference vector signal 
comprises the mean of the feature values of a second set 

of training feature vector signals corresponding to an 
elementary model in the training script in a second 

context; and 
the parameter value of the second reference vector signal 

comprises the mean of the feature values of a third set of 
training feature vector signals corresponding to an 

elementary model in the training script in a third context 
different from the first and second contexts. 
A speech coding apparatus as claimed in Claim 3, 
characterized in that the means for generating partition 

values comprises means for grouping each subset of 
training feature vector signals into one or more different 

clusters. 
A speech coding apparatus as claimed in Claim 4, 
characterized in that: 

the means for grouping each subset of training feature 
vector signals into one or more different clusters 

comprises:
 

means for storing at least third and fourth reference 
vector signals, each reference vector signal having at 

least one parameter value; 
means for comparing the feature value of each training 

feature vector signal in the first subset to the parameter 
value of the third reference vector signal to obtain a 

third closeness score for the training feature vector 
signal and the third reference vector signal; 

means for comparing the feature value of each training 
feature vector signal in the first subset to the parameter 

value of the fourth reference vector signal to obtain a 
fourth closeness score for the training feature vector 

signal and the fourth reference vector signal; 
means for comparing, for each training feature vector 

signal in the first subset, the third closeness score for 
the training feature vector signal with the fourth 

closeness score for the training feature vector signal to 
obtain a sub-reference match score for each training 

feature vector signal and the third and fourth reference 
vector signals; and 

means for storing a first sub-subset of the training 
feature vector signals in the first subset having 

sub-reference match scores better than a threshold Q', and 
for storing a second sub-subset of the training feature 

vector signals in the first subset having sub-reference 
match scores worse than the threshold Q'; and 

the partition generating means generates one or more 
partition values for the first prototype vector signal 

from the first sub-subset of training feature vector 
signals, and generates one or more additional partition 

values for the first prototype vector signal from the 
second sub-subset of training feature vector signals. 
A speech coding apparatus as claimed in Claim 5, 
characterized in that each partition value comprises the 

mean of the feature values of the training feature vector 
signals in a cluster. 
A speech coding apparatus as claimed in Claim 6, 
characterized in that each partition value further 

comprises the variance of the feature values of the 
training feature vector signals in a cluster. 
A speech coding apparatus as claimed in Claim 7, 
characterized in that the threshold Q is equal to one. 
A speech coding apparatus as claimed in Claim 1, 
characterized in that: 

the training script model comprises a series of phonetic 
models, each phonetic model comprising a series of 

elementary models, each elementary model in the training 
script model having a phonetic context of preceding and 

following phonetic models; and 
the prototype generating means further comprises means for 

generating the first and second reference vector signals, 
the first reference vector signal comprising the mean of 

training feature vector signals corresponding to the first 
elementary model in a first phonetic context of preceding 

and following phonetic models, the second reference vector 
signal comprising the mean of training feature vector 

signals corresponding to the first elementary model in a 
second phonetic context of preceding and following 

phonetic models, different from the first context. 
A speech coding apparatus as claimed in Claim 1, 
characterized in that the measuring means comprises a 

microphone. 
A speech coding apparatus as claimed in Claim 1, 
characterized in that the means for storing prototype 

vector signals comprises electronic readable memory. 
A speech coding method comprising: 
measuring the value of at least one feature of an 

utterance over each of a series of successive time 
intervals to produce a series of feature vector signals 

representing the feature values; 
storing a plurality of prototype vector signals, each 

prototype vector signal comprising at least two partitions 
and having an identification value, each partition having 

at least one parameter value; 
comparing the closeness of the feature value of a first 

feature vector signal to the parameter value of at least 
one partition of each prototype vector signal to obtain 

prototype match scores for the first feature vector signal 
and each prototype vector signal; and 

outputting at least the identification value of the 
prototype vector signal having the best prototype match 

score as a coded utterance representation signal of the 
first feature vector signal; 

characterized in that the method further comprises 
generating the stored prototype vector signals by the 

steps of: 
storing a model of a training script, said training script 

model comprising a series of elementary models from a 
finite set of elementary models; 

measuring the value of at least one feature of a training 
utterance of the training script over each of a series of 

successive time intervals to produce a series of training 
feature vector signals representing the feature values;

 
identifying a first set of training feature vector signals 

corresponding to a first elementary model in the training 
script model; 

storing at least first and second reference vector 
signals, each reference vector signal having at least one 

parameter value; 
comparing the feature value of each training feature 

vector signal in the first set to the parameter value of 
the first reference vector signal to obtain a first 

closeness score for each training feature vector signal 
and the first reference vector signal; 

comparing the feature value of each training feature 
vector signal in the first set to the parameter value of 

the second reference vector signal to obtain a second 
closeness score for each training feature vector signal 

and the second reference vector signal; 
comparing, for each training feature vector signal in the 

first set, the first closeness score for the training 
feature vector signal with the second closeness score for 

the training feature vector signal to obtain a reference 
match score for each training feature vector signal and 

the first and second reference vector signals; 
storing a first subset of the training feature vector 

signals in the first set having reference match scores 
better than a threshold Q, and for storing a second subset 

of the training feature vector signals in the first set 
having reference match scores worse than the threshold Q; 

and 
generating one or more partition values for a first 

prototype vector signal from the first subset of training 
feature vector signals, and for generating one or more 

 
additional partition values for the first prototype vector 

signal from the second subset of training feature vector 
signals. 
A speech coding method as claimed in Claim 12, 
characterized in that: 

each elementary model in the training script has a context 
comprising one or more preceding or following models in 

the training script; and 
the first set of training feature vector signals 

corresponds to a first elementary model in the training 
script in a first context. 
A speech coding method as claimed in Claim 13, 
characterized in that: 

the parameter value of the first reference vector signal 
comprises the mean of the feature values of a second set 

of training feature vector signals corresponding to an 
elementary model in the training script in a second 

context; and 
the parameter value of the second reference vector signal 

comprises the mean of the feature values of a third set of 
training feature vector signals corresponding to an 

elementary model in the training script in a third context 
different from the first and second contexts. 
A speech coding method as claimed in Claim 14, 
characterized in that the step of generating partition 

values comprises the step of grouping each subset of 
training feature vector signals into one or more different 

clusters. 
A speech coding method as claimed in Claim 15, 
characterized in that:

 
the step of grouping each subset of training feature 

vector signals into one or more different clusters 
comprises: 

storing at least third and fourth reference vector 
signals, each reference vector signal having at least one 

parameter value; 
comparing the feature value of each training feature 

vector signal in the first subset to the parameter value 
of the third reference vector signal to obtain a third 

closeness score for the training feature vector signal and 
the third reference vector signal; 

comparing the feature value of each training feature 
vector signal in the first subset to the parameter value 

of the fourth reference vector signal to obtain a fourth 
closeness score for the training feature vector signal and 

the fourth reference vector signal; 
comparing, for each training feature vector signal in the 

first subset, the third closeness score for the training 
feature vector signal with the fourth closeness score for 

the training feature vector signal to obtain a 
sub-reference match score for each training feature vector 

signal and the third and fourth reference vector signals; 
and 

storing a first sub-subset of the training feature vector 
signals in the first subset having sub-reference match 

scores better than a threshold Q', and storing a second 
sub-subset of the training feature vector signals in the 

first subset having sub-reference match scores worse than 
the threshold Q'; and 

the partition generating step generates one or more 
partition values for the first prototype vector signal 

from the first sub-subset of training feature vector 
signals, and generates one or more additional partition 

 
values for the first prototype vector signal from the 

second sub-subset of training feature vector signals. 
A speech coding method as claimed in Claim 16, 
characte
rized in that each partition value comprises the 
mean of the feature values of the training feature vector 

signals in a cluster. 
A speech coding method as claimed in Claim 17, 
characterized in that each partition value further 

comprises the variance of the feature values of the 
training feature vector signals in a cluster. 
A speech coding method as claimed in Claim 18, 
characterized in that the threshold Q is equal to one. 
A speech coding method as claimed in Claim 12, 
characterized in that: 

the training script model comprises a series of phonetic 
models, each phonetic model comprising a series of 

elementary models, each elementary model in the training 
script model having a phonetic context of preceding and 

following phonetic models; and 
the prototype generating step further comprises the step 

of generating the first and second reference vector 
signals, the first reference vector signal comprising the 

mean of training feature vector signals corresponding to 
the first elementary model in a first phonetic context of 

preceding and following phonetic models, the second 
reference vector signal comprising the mean of training 

feature vector signals corresponding to the first 
elementary model in a second phonetic context of preceding 

and following phonetic models, different from the first 
context. 
</CLAIMS>
</TEXT>
</DOC>
