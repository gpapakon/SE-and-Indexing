<DOC>
<DOCNO>EP-0654158</DOCNO> 
<TEXT>
<INVENTION-TITLE>
ADVANCED MASSIVELY-PARALLEL COMPUTER APPARATUS.
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F1516	G06F1516	G06F1576	G06F1580	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	G06F	G06F	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F15	G06F15	G06F15	G06F15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
The organization of a large (up to 8192 processors) massively -parallel computer apparatus (302) capable of teraop (i.e., of the order of 1012) computational rates and teraop data communication rate, in which its operating system includes means for providing the massively-parallel computer appparatus with multiuser time-shared operation is disclosed. Such massively-parallel computer apparatus is particularly suitable for real-time analysis of complex problems that require timely analysis include neural networks, volume visualization, and polygon rendering, as well as weather modeling, medical image, computer vision, molecular modeling and VLSI simulation.
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
SARNOFF DAVID RES CENTER
</APPLICANT-NAME>
<APPLICANT-NAME>
DAVID SARNOFF RESEARCH CENTER, INC.
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
CHIN DANNY
</INVENTOR-NAME>
<INVENTOR-NAME>
PETERS JOSEPH EDWARD JR
</INVENTOR-NAME>
<INVENTOR-NAME>
TAYLOR HERBERT HUDSON JR
</INVENTOR-NAME>
<INVENTOR-NAME>
CHIN, DANNY
</INVENTOR-NAME>
<INVENTOR-NAME>
PETERS, JOSEPH, EDWARD, JR.
</INVENTOR-NAME>
<INVENTOR-NAME>
TAYLOR, HERBERT, HUDSON, JR.
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
 ADVANCED MASSIVELY-PARALLEL COMPUTER APPARATUSThis invention was made with Government support under Contract No. MDA-972- 90-C-0022. The Government has certain rights in the invention. This invention relates to massively-parallel computer apparatus and, more particularly, to such apparatus capable of providing multiuser time-shared operation thereof.BACKGROUND OF THE INVENTION While both large sequentially-operating and parallel-operating supercomputers are known in the art, massively-parallel operation is to be preferred for those computationally- intensive applications which require a vast amount of data computation and data communication to be carried out in real time. Examples of such applications include weather modeling and medical imaging. Real-time analysis of such complex scenarios encountered by such applications operate on very large data sets. The prior-art Princeton Engine (PE) architecture is a single-instruction multiple data(SIMD) linear array of processors. The linear array can be scaled from 64 to 2048 processors in steps of 64 and, in a full configuration, achieves a computational rate of 28,672 Millions of Instructions Per Second (MIPS) for an instruction clock of 14 MHz. Each processor has a local memory and can communicate with its neighbors via two bidirectional channels. Input and output data rates of 14 and 1.8 Gbps, respectively, are provided. The PE host is an Apollo/Mentor Graphics workstation, and high-resolution monitors are used for observation of output results.Each processing element PEO to PEn-1 of the PE contains seven independent, internal 16-bit data paths a 16-bit ALU a 16-bit multiplier a triple-ported register stack with 64 elements; a 16-bit communications port; and up to 640K Bytes of external SRAM local memory. The register file has one address port for read-only access to that file and a second address port for read or write access to that file. An interprocessor communications bus (IPC) permits exchanges of data between neighboring processors during one instruction cycle. On each instruction cycle, up to six simultaneous operations can take place (input or output via the I/O bus, simultaneous read and write at the register file, one multiplication, one ALU operation, and a local memory access).Input data is stored as one pixel per processor in each processor's local memory M0 to Mn-1 for each scan line 0 to v-1 of video. Thus, over a frame period, one pixel column of a video frame is stored in each local memory. The local memory is sufficient to store up to
</DESCRIPTION>
<CLAIMS>
THE INVENTION CLAIMED IS:
1. A parallel computing system comprising:
N blocks, where N is an integer, each block comprising:
M processors, where M is an integer, each processor including an arithmetic and logic unit (ALU), a local memory and an input/output (I/O) interface; and control means, coupled to provide a group of identical instructions to each of die M processors; host means for selectively combining the control means of the N blocks into at least first and second groups of blocks, each group including P blocks, P being an integer less than or equal to N, wherein, for each group of P blocks, a respectively different group of identical processor instructions are provided to each of die P times M processors.
2. The system of claim 1 , wherein: each of the M processors in a block includes an inter-processor communications (IPC) channel by which the processor can transfer data values to other ones of the M processors in die block; the control means of each block including means for programming the M processors in the block to define partitions among the M processors in the block wherein each of the processors in any one partition can communicate, via the IPC channel, only with another processor in die one partition via die IPC channel; and die host means including means for selectively combining the IPC channels of the
N groups of processors to establish respective data communications paths for each of die groups of P blocks; and the IPC channel connecting the M processors in one of the blocks in a predetermined sequence; and the control means of each block includes means for selectively programming the respective IPC channels of each of the M processors in the respective block to: a) pass the data values received from die preceding processor in the sequence to the next processor in the sequence without receiving the data values, b) send data values to more tiian one processor in the sequence, and c) to receive data values which have been sent by another processor in the sequence to multiple processors in the sequence.
3. The system of claim 1 , wherein each processor includes: means for indicating local data conditions in the processor; and means for conditionally executing the instructions provided by the control means based on the indicated local data conditions. 4. A parallel computing system comprising: a plurality of processors, each including: a source of system clock signal, an arithmetic and logic unit (ALU), means for indicating local data conditions in the processor; 


 a local memory, an input/output (I/O) interface, and a profiling counter having a counter value which is incremented, responsive to the system clock signal, when the profiling counter is enabled; control means, responsive to control instructions and coupled to provide a group of identical processor instructions to each of the plurality of processors; and host means for providing the control instructions and die processor instructions to die control means wherein each processor instruction includes a field which is used to enable and disable die respective profiling counters in the plurality of processors.
5. The system of claim 4, wherein: the control means includes a separate profiling counter having a count value which is incremented only when die counter is enabled; and each of the control instructions includes a field which selectively enables and disables die profiling counter of the control means; and wherein: the control means is responsive to a first one of said control instruction to load the profiling counter of the control means with one of an immediate value and a value obtained from a data register coupled to the control means and to a second one of said control instruction to store die count value into the data register; and each of the processors is responsive to a first processor instruction to load the profiling counter of the processor with one of an immediate value and a value obtained from die local memory of the processor and to a second processor instruction to store the count value into the local memory.
6. A processor suitable for use in a parallel computing system, said processor comprising: memory means for holding operand values; an aridimetic and logic unit (ALU) which performs arithmetic and logic operations on the operand values; a multiplier, separate from the ALU which generates arithmetic products of first and second ones of the operand values; a match unit, separate from the ALU which counts a number of matches between a bit pattern and a sequence of bits from the memory means to generate a count value indicating a number of detected matches between the bit pattern and subsequences of the sequence of bits. 7. The processor of claim 6 wherein the bit pattern to be matched has a number of bits less than the number of bits in die sequence of bits, and die match unit includes: means for storing a sequence of templates representing each possible match position of die bit pattern and a corresponding bit pattern in the sequence of bits; 


 means for comparing the sequence of bits to all of the templates in the sequence; and means for providing a count matches between the sequence of bits and the templates as the number of matches. 8. The processor of claim 6, wherein: the multiplier is coupled to provide the generated arithmetic product as an input operand to die ALU; the match unit is coupled in parallel with the multiplier such that the bit pattern is contained in the first operand and the sequence of bits is contained in die second operand and only one of die count value generated by the multiplier and the aritiimetic product generated by the ALU may be applied as an input operand to the ALU at any given time; and the processor is responsive to an instruction word containing a first subfield which is used to cause the ALU to perform one of the arithmetic and logic operations and a second subfield which is used to cause the multiplier to generate the arithmetic product or to cause die matcher to generate die count value.
9. The processor of claim 6, further including: a first accumulator; and a second accumulator; wherein the ALU is coupled to provide output values generated by performing the arithmetic and logic operations on the operand values to both the first and second accumulators concurrentiy.
10. A processor suitable for use in a parallel computing system, said processor comprising: means for providing a processor instruction word; memory means for holding a plurality of arrays of operand values; arithmetic and logic unit (ALU) means, having first and second input ports coupled to receive respective first and second ones of die operand values, for performing arithmetic and logic operations on first and second operand values; first address generator means, coupled to the memory means and responsive to a first field in the instruction word, for selecting individual operands from a first one of the plurality of arrays of operand values to apply to the first input port of the ALU; and second address generator means, coupled to the memory means and responsive to a second field in the instruction word, distinct from the first field, for selecting individual operands from a second one of the plurality of arrays of operand values to apply to the second input port of the ALU.
11. The processor of claim 10, wherein: each of the arrays of operands has a lower bound address and an upper bound address; 


 each of the first and second address generator means includes: means for determining if a generated address value is invalid as being less than the lower bound address or greater than the upper bound address to generate an out of bounds signal; means, responsive to the out of bounds signal, for converting the invalid address value into a predetermined address value which is within the upper bound and lower bound of the array and which addresses a predetermined operand value. 12. A parallel computing system comprising:
P processors, where P is an integer, each processor including: a source of clock signal having a predetermined frequency an arithmetic and logic unit (ALU), coupled to said source of clock signal, which is capable of performing at least one arithmetic operation in a period of the clock signal; and a local memory coupled to fetch and store data values synchronous with die clock signal; control means, coupled to provide instructions to each of the P processors; inter-processor communications (IPC) means coupled to each of the P processors for conveying data values among die P processors, said IPC means including: a bus, coupled to each of the P processors, including means for conveying a data clock signal which causes the IPC means to transfer one of said data values on the bus for each pulse of die data clock signal; means, responsive to the control means, for providing the data clock signal at a first frequency substantially equal to the predetermined frequency and for providing the data clock signal at a second frequency approximately equal to N-times the predetermined frequency, where N is an integer greater than 1. 13. A parallel computing system comprising:
P processors, where P is an integer, each processor including: an arithmetic and logic unit (ALU); and a local memory for holding data values; control means, coupled to provide instructions to each of the P processors; inter-processor communications (IPC) means coupled among the P processors in a predetermined sequence for conveying data values among the P processors, said IPC means including: a bus, coupled to each of the P processors, including means for conveying data values to each of the P processors, wherein the bus is capable of simultaneously conveying 2N-bits where N is an integer and each of the data values held in the local memory is an N-bit data value; and
IPC logic means, responsive to the control means, for causing the bus to transfer data values in one of first and second opposite direction among the sequence of 


processors, and for causing the bus to operate as first and second separate N-bit busses or as a single 2N-bit bus.
14. A parallel computing system comprising:
N blocks, where N is an integer, each block comprising: M processors, where M is an integer, each processor being responsive to processor instructions and including an arithmetic and logic unit (ALU), a local memory and an input/output interface; and control means, responsive to control instructions and coupled to provide a identical groups of the processor instructions to each of the M processors in die block; and host means coupled provide control instructions and processor instructions to the control means of each of the N blocks, wherein the control instructions and processor instructions provided to each block are different from the control instructions and processor instructions provided to each other block.
15. The system of claim 14, wherein: each of the M processors in each block includes an inter-processor communications
(IPC) channel, responsive to IPC instructions for transferring data values among the M processors in the block; means for indicating local data conditions in die processor; means for conditionally executing the processor instructions responsive to the means for indicating local data conditions; and means coupled to the control means and to the IPC channels of each of the M processors for providing each IPC channel with a distinct group of IPC instructions.
16. A parallel computing system comprising:
P processors, where P is an integer greater than 1, each processor including: memory means having N memory locations for holding N data values where N is an integer greater tiian 1 ; output data buffer means, coupled to the memory, for reading ones of said N data values from the memory locations of the memory means in an order determined by a first output control signal and for providing the read data values at instants determined by a second output control signal; input data buffer means, coupled to the memory, for receiving data values at instants determined by a first input control signal and for providing the received data values to the memory means at ones of said memory locations determined by a second input control signal; means for coupling the output buffer means to the input buffer means such that die data values provided by the output buffer means are the data values received by the input buffer means; and 


 programmable control means for providing the first and second output control signals and die first and second input control signals to reorder die data values stored in die respective memory means of the P processors;
17. The system of claim 16, wherein: each of die P processors is identified by a unique processor identifier value; the memory means of each of the processors is responsive to an offset value for providing access to one of die N data values stored in die memory location indicated by die offset value; the programmable control means includes means for providing the first output control signal and die second input control signal to each of the P processors to specify the offset which is used to access the N data values stored in the memory means, wherein the first output control signal and the second input control signal are respectively different functions of P and N.
18. A parallel computing system comprising: M processors, where M is an integer, each processor including an arithmetic and logic unit (ALU), a local memory and an input/output (I/O) interface; and control means, coupled to provide identical processor instructions to each of the M processors; host means coupled to die control means for providing control instructions to die control means the processor instructions for the M processors, the host means comprising: a process table memory which holds information on real-time and non-real-time processes to be executed on die parallel computing system; polling means for determining when a real-time process is to be executed on die parallel computing system; resource allocation means for assigning processors to processes to be executed on die parallel computing system; queue means for queuing real-time and non-real-time processes to be executed on die parallel computing system; and scheduling means responsive to a synchronizing signal for removing processes from the queue means and for causing the assigned processors to execute the removed processes.
19. The system of claim 18 wherein: the process table memory holds an expected program execution time and an expected frame time for each of the real-time processes to be executed on the parallel computing system; and the resource allocation means allocates processors to a new real-time process only when the program execution time of the new real-time process summed with die combined program execution times of all processes currently in the queuing means is less that the shortest frame time of any process currently in the queuing means. 

</CLAIMS>
</TEXT>
</DOC>
