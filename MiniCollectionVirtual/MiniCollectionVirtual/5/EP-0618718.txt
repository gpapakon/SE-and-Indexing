<DOC>
<DOCNO>EP-0618718</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Correcting plate misregistration in colour printing of images defined in a page description language
</INVENTION-TITLE>
<CLASSIFICATIONS>H04N158	G03F300	G06K1500	H04N152	G06K1500	H04N156	H04N152	G03F308	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>H04N	G03F	G06K	H04N	G06K	H04N	H04N	G03F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>H04N1	G03F3	G06K15	H04N1	G06K15	H04N1	H04N1	G03F3	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A method and apparatus for compensation for misregistration of printing plates in printing 
of polychromatic document pages or images, in which a trapping map image is superimposed 

upon a structured graphic image representing the layout of a document page or image 
from which it is derived, so as to prevent light leaks and other errors at the boundaries between 

color regions within the image. The trapping map image is itself a structured graphic 
object to be included as the last object imaged in the data representing the original image. 

The geometrical description of this trapping map image is independent of specific trapping 
decisions applicable to the associated image. Instead, such decisions are controlled by means 

of a user interface providing options ranging from fully automatic to completely manual interactive 
operation. 


</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
BAYER AG
</APPLICANT-NAME>
<APPLICANT-NAME>
AGFA CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
DERMER RICHARD A
</INVENTOR-NAME>
<INVENTOR-NAME>
DERMER, RICHARD A.
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present application is related to the applications of Richard
A. Dermer for "Method for Automatic Trap Selection for Correcting
for Plate Misregistration in Color Printing" (EP 94 104
904.1, published as EP-A-0 620 534) and of Richard A. Dermer and Edward C. Reifenstein, III
for "Method for Determining Color Boundaries for Correcting for
Plate Misregistration in Color Printing" (EP 94 104 903.3, published as EP-A-0 618 546) filed
simultaneously herewith and assigned to the same assignee.The field to which the invention applies is the electronic
processing of graphic images to produce multi-color output using
offset or other printing methods. Images are obtained electronically
by digital scanning of photographic material and
combined with "structured graphics" to provide composed images
or pages which are then separated into monochromatic images each
corresponding to an ink to be used in the printing process.
Typically, four process color inks, cyan, magenta, yellow and
black are used, although special "spot" colors can be used
instead of or in addition to the process color inks. The
separated images can then be output to photographic films from
which printing plates are made. Alternatively, the separated
images can be used to produce engraved cylinders from which
gravure prints can be made.The layout of a page or graphic image to be printed as described
above depends upon combination of "structured graphics" according
to a pre-established graphic design. The structured
graphics are contiguous regions of color which represent a
succession of graphic objects imaged on the printing medium
(e.g. the "paper"). The objects so imaged are polygon shapes
which can be isolated from each other, can abut one another at
one or more points, can partially overlap one another, or can 
completely overlap one another. The resulting printed page or
graphic image is therefore made up of a patchwork of polygon
shapes representing the graphic objects, some of which are
"clipped" by objects imaged later in the succession.A method for determining the clipping areas of such overlapping
polygons may be found, for example, in U.S. Patent No. US-A-4,698,779
to Holden et al. Specifically, Holden et al. provides a method
for determining the coincidence of a subject area and a clip
area in a graphic display system wherein three parts lists are
generated. The lists include one for parts of the subject area
that are outside the clip area, a second for parts of the clip
area that are inside the subject area, and a third for
</DESCRIPTION>
<CLAIMS>
A method of generating a trapped graphic image from a
structured graphic image comprising the following steps:


converting said structured graphic image into graphic
objects defined by polygons;
generating a boundary map for the entire image containing a plurality of
line segments forming boundaries between adjacent ones of said graphic

objects, said boundary map being unaffected by any
trapping decisions, separation or rendering decisions

made after the boundary map is generated;
generating a trapping map for the entire image by defining trap stroke
characteristics for some or all of the line segments

making up said boundary map; and
combining said trapping map with said structured
graphic image such that said trapping map is superimposed

upon said structured graphic image when rendered
for output processing.
The method of claim 1, wherein said boundary map is generated
from said structured graphic image by the following

steps:

generating a display list of said graphic objects
according to the order in which said graphic objects

are to be imaged;
adding the graphic objects of the display list to an
object space in which the polygons defining the

graphic objects are located as they are to appear
when imaged, with each polygon in the sequence clipping

those previously placed, and being clipped by 
those following;
identifying boundaries between adjacent color regions
in said object space and collecting said boundaries

together as said boundary map, said boundary
map comprising a geometrical description of all

straight line segments making up said identified
boundaries, each line segment being defined by starting

and ending coordinates and identification of
the graphic objects between which it forms a boundary.
The method of claim 1 or 2 wherein the step of converting
said structured graphic image into graphic objects defined

by polygons further includes the step of:

converting curved lines of said structured graphic
object to a plurality of straight line segments where

the maximum error of a single straight line segment
so converted is a defined parameter which is

preset or modifiable by an operator.
The method of one of the preceding claims wherein said
trapping map is generated automatically from said boundary

map using stored criteria for the generation of
traps along boundaries between regions of different color.
The method of one of claims 1 to 3 in which said trapping
map is generated by the following steps:


generating a candidate trapping map from said boundary
map using predetermined or operator selected

criteria for the generation of traps along said
boundaries between regions of different color;
presenting data representing said candidate trapping
map for analysis by an operator;
modifying the criteria for generating traps along
the boundaries between regions of different color

within said structured graphic image based upon data
representing said candidate trapping map;
repeating above steps until satisfactory results are 
indicated by said operator; and,
generating a final trapping map using the candidate
trapping map which produces said satisfactory

results.
The method of claim 5 wherein the candidate trapping map
is displayed for viewing by said operator.
The method of claim 5 or 6 wherein said candidate trapping
map utilizes stored criteria or criteria specified

by said operator for generating traps along said boundaries
between regions of different color.
The method of claim 5 in which said trapping map is generated
for a specific combination of printing plates,

selected independently of any structured graphic image or
trapping decisions, using predetermined criteria or criteria

specified by said operator.
The method of claim 8 in which the combination of printing
plates includes the process colors cyan, magenta,

yellow and black, or includes spot colors.
An apparatus for generating a trapped graphic image from
a structured graphic image comprising:


means for converting said structured graphic image
into graphic objects defined by polygons;
means (520) for generating a boundary map for the entire image containing
a plurality of line segments forming boundaries between adjacent ones

of said graphic objects, said boundary map being 
unaffected by any trapping decisions, separation or

rendering decisions made after the boundary map is
generated;
means for generating (430) a trapping map for the entire image defining
trap stroke characteristics for some or all of the

line segments making up said boundary map; and
means for combining (460) said trapping map with
said structured graphic image such that said trapping

map is superimposed upon said structured
graphic image when rendered for output processing.
The apparatus of claim 10, further comprising:

means for generating (400) a display list of said
graphic objects according to the order in which said

graphic objects are to be imaged.
The apparatus of claims 10 or 11, further comprising:

means for presenting data (450; 2310) representing a
candidate trapping map using predetermined or operator

selected criteria for the generation of traps
along the boundaries between the regions of different

color for viewing and analysis by an operator;
and
means for selecting and modifying (450; 2312, 2314)
said criteria by an operator.
The apparatus of claim 12, further comprising:

means for storing (440) said criteria for generating
traps along said boundaries between regions of different

color.
</CLAIMS>
</TEXT>
</DOC>
