<DOC>
<DOCNO>EP-0643358</DOCNO> 
<TEXT>
<INVENTION-TITLE>
An image searching method and apparatus
</INVENTION-TITLE>
<CLASSIFICATIONS>G06T700	G06T700	G06F1730	G06F1730	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06T	G06T	G06F	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06T7	G06T7	G06F17	G06F17	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
Image searching method and apparatus capable of 
performing high quality search out of image database by 

using color information. A sample image which is used 
as a key to search, and which is made by the operator, 

is inputted by the sample image input unit 30, and the 
sample color information extraction unit 50 extracts the 

HSV color space data out of the sample image, and the 
image color information extraction unit 40 extracts the 

HSV color image data from the image database 20. 
Contribution factors deciding unit 60 decides a 

contribution factor of each component in the HSV color 
space, then the candidate image deciding unit 70 

calculates similarity, and decides the image candidates, 
then those images are displayed on the display unit 90. 

the control unit 80 controls entire image searching 
apparatus. 


</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
CANON KK
</APPLICANT-NAME>
<APPLICANT-NAME>
CANON KABUSHIKI KAISHA
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BANNAI YUICHI
</INVENTOR-NAME>
<INVENTOR-NAME>
TSUJIMURA KAZUKO
</INVENTOR-NAME>
<INVENTOR-NAME>
BANNAI, YUICHI
</INVENTOR-NAME>
<INVENTOR-NAME>
TSUJIMURA, KAZUKO
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to an image
processing method and apparatus and, more particularly,
to a method to search for an image out of an image
database, and the apparatus capable of employing the
method.As one of conventional methods to search for a
necessary image out of an image database, there is a
method that an operator makes an example of the desired
image, and that the search is performed with reference
to color information of the image. The color
information is extracted from the desired image by using
a color perception space which is composed of three
elements, namely, hue, chromaticity, and luminance
(altogether, called `the three attributes of colors',
hereinafter). Then, similarity between the extracted
color information of the desired image and color
information extracted from an image stored in the image
database by employing the same color perception space,
is examined. Thereby, the order of image candidates,
which can be the same as or which can be similar to the
desired image made by the operator, is decided based on
similarity. The image candidate which has a higher 
similarity is more likely similar to the desired image.
then the images are displayed in order of similarity.Regarding color data, each factor of the three
attributes of color differs in accordance with values of
the three attributes of the color. For instance, in a
color which has low chromaticity that is close to black
or white, and low luminance, a contribution factor of hue
which is an attribute to distinguish the difference of
color, such as red, blue, and yellow, is also low. If
the degree of the similarity is calculated on the
assumption that the contribution factors of the
attributes are the same for all the colors in spite of
the aforementioned fact that the contribution factors
actually differ, the searching quality becomes lower
since low contribution values are included in the
calculation of similarity.It is known from EP-A-0558054 to provide image
retrieval based on color classification in which images
in a database are characterised at the time of entry into
the database by the numbers of pixels having colors
corresponding to each of a set of color areas in a color
space. A search is based on specific user selected 
colors and proportions thereof.It is also known from JP-A-05158999 to store images
in a database together with a retrieval code based on
color content and to retrieve images from the database
using a code representative of a color sample.There is a need to provide an image processing
method
</DESCRIPTION>
<CLAIMS>
An image searching method for retrieving a desired
image from an image database storing images comprising

color information, the method comprising:

a step (S1;S11) of receiving input information about
a sample image for retrieving the desired image, the

information designating the colour of at least one
portion of the sample image;
a generating step (S2) of generating colour
information of the sample image, the information

comprising a plurality of colour component values (H
1
,
S
1
, V
1
) corresponding to attributes of a perceptual
colour space;
and a similarity calculation step (S3-S4, S30-S33)
of calculating a respective similarity (R
i
) between the
sample image and each image stored in the database, the

calculation step comprising a calculation of similarity
between the color component values (H
1
,S
1
,V
1
) of the
sample image and the color component values (H
2i
, S
2i
, V
2i
)
of each image (i) stored in the database;

   
characterised by
 further comprising

a contribution factor calculation step (S20-23, S26, 
S27) of calculating for each of the plurality of color

components a respective contribution factor (Rh,Rs,Ry;
C1,C2,C3) as a function of the plurality of color

components values of the sample image;
a contribution rate calculating step of calculating
(S30) for each of the plurality of colour components a

respective contribution rate (RH, RS, RV) by normalizing
(S24) the calculated contribution factors; and

   wherein the similarity calculation step calculates
the respective similarity for each image stored in the

database taking into account the corresponding
contribution rates such that the rate at which each color

component of the perceptual color space contributes to
the similarity calculation is a function of the color

component values in the sample image.
A method as claimed in claim 1 further comprising:

a displaying step (S6) of displaying images from the
database as a searching result based on the similarity

calculated at said similarity calculating step.
A method as claimed in claim 2, wherein, at said 
displaying step, the images from the database are

displayed in order of the similarity (S5,S6).
A method as claimed in any preceding claim, wherein,
at said input information receiving step, the color

information is obtained by designating a color from a
plurality of colors displayed on a display screen (S11,

Fig. 4).
A method as claimed in any preceding claim, wherein
the plurality of color components include hue,

chromaticity, and luminance.
A method as claimed in claim 5, wherein, at said
contribution factor calculation step, the contribution

factor corresponding to each color component value is
calculated based on a comparison (S21,S22) between the

plurality of color component values and respective
predetermined thresholds (T
v
,T
s
).
The method according to claim 5, wherein, at said
contribution factor calculation step, if the luminance 

(V
1
) of said color information is lower than a
predetermined threshold (T
v
), then a contribution factor
(R
v
) corresponding to the luminance is set (S21,S26) to
a higher level than the contribution factors for hue and

chromaticity respectively, and wherein if the luminance
is higher than said threshold and if the chromaticity of

the color information is higher than a respective
predetermined threshold (T
s
), then a contribution factor
(R
h
) corresponding to hue is set (S22, S23) to be a
higher level than the contribution factors for luminance

and chromaticity respectively, further wherein if the
luminance of said color information is higher than said

predetermined threshold (T
v
) and the chromaticity of said
color information is lower than the respective

predetermined threshold (T
s
), then the contribution
factor (R
s
) of the chromaticity of the color information
and the contribution factor (R
v
) of the luminance of the
color information are set (S22,S27) to respective levels

which are higher than the contribution factor for hue.
A method as claimed in claim 5, wherein, at said
contribution factor calculation step, the calculation is 

performed based on a plurality of membership functions
(100, 101, 102, 103; Figs. 7-10) which define membership

grades (C1,C2,C3) of chromaticity and luminance of the

color information.
A method as claimed in any preceding claim wherein
the step of receiving input information further comprises

receiving (S10) portion information representative of a
portion of the image to which the color information

relates and wherein the generating step uses both the
color information and the portion information to generate

the sample image.
A method as claimed in claim 9, wherein, at said
step of receiving input information, the portion

information indicates a portion representative of an
object image and wherein the portion is filled (S12) by

a color defined by the color information.
A method as claimed in claim 10 wherein the step of
receiving input information is responsive to input by an

operator by drawing said object image on a display using 
a pointing device to define said portion information.
A method as claimed in claim 10 wherein the step of
receiving input information is responsive to the input of

said portion information by operation of a scanner.
Image searching apparatus for retrieving a desired
image from a database including color information of

stored images, the apparatus comprising:

input means (30, 31) operable to input information
about a sample image for retrieving the desired image,

the information designating the colour of at least one
portion of the sample image;
generating means (50) operable to generate colour
information of the sample image, the information

comprising a plurality of colour component values (HI,
SI, VI) corresponding to attributes of a perceptual

colour space;
similarity calculation means (70) operable to
perform a calculation of a respective similarity (R
i
)
between the sample image and each image stored in the

database, the calculation comprising a calculation of 
similarity between the color component values(H
1
,S
1
,V
1
)
of the sample image and the color component values (H
2i
,
S
2i
, V
2i
) of each image (i) stored in the database;

   
characterised by
 further comprising

contribution factor calculating means (60) operable
to calculate for each of the plurality of color

components a respective contribution factor (Rh,Rs,Rv;
C1,C2,C3) as a function of the plurality of color

component values of the sample image;
contribution rate calculating means (60) operable to
calculate for each of the plurality of color components

a respective contribution rate (RH, RS, RV) by
normalizing (S24) the calculated contribution factors;

and

   wherein the similarity calculating means is operable
to calculate the similarity between the sample image and

each image stored in the database taking into account the
corresponding contribution rates such that the rate at

which each color component of the perceived color space
contributes to the similarity calculation is a function

of the color component values in the sample image. 
Apparatus as claimed in claim 13 further comprising:

a display unit (90) operable to display images from
the database as a searching result based on the

similarity calculated by said similarity calculating
means.
Apparatus as claimed in claim 14, wherein said
display unit is operable to display the images from the

database in order of the similarity.
Apparatus as claimed in any of claims 13 to 15
comprising designating means (31) operable to designate

the color information by designating a color from a
plurality of colors displayed on a display screen of said

display unit.
Apparatus as claimed in any of claims 13 to 16
wherein the plurality of color components include hue,

chromaticity, and luminance.
Apparatus as claimed in claim 17, wherein said
contribution factor calculating means is operable to 

calculate the contribution factor corresponding to each
color component of color information based on a

comparison (S21,S22) between the plurality of color
component values and respective predetermined thresholds

(T
v
,T
s
).
Apparatus as claimed in claim 17 wherein the
contribution factor calculation means is operable such

that, if the luminance (V
1
) of said color information is
lower than a predetermined threshold (T
v
), then a
contribution factor (R
v
) corresponding to the luminance
is set (S21,S26) to a higher level than the contribution

factors for hue and chromaticity respectively, and
wherein, if the luminance is higher than said threshold

and if the chromaticity of the color information is
higher than a respective predetermined threshold (T
s
),
then a contribution factor (R
h
) corresponding to hue is
set to be a higher level than the contribution factors

for luminance and chromaticity respectively (S22, S23),
further wherein, if the luminance of said color

information is higher than said predetermined threshold
(T
v
) and the chromaticity of said color information is 
lower than the respective predetermined threshold (T
s
),
then the contribution factor (R
s
) of the chromaticity of
the color information and the contribution factor (R
v
) of
the luminance of the color information are set (S22,S27)

to respective levels which are higher than the
contribution factor for hue.
Apparatus as claimed in claim 17, wherein said
contribution factor calculation means is operable to

perform calculation based on a plurality of membership
functions (100, 101, 102, 103; Figs. 7-10) which define

membership grades (C1,C2,C3) of chromaticity and
luminance of the color information.
Apparatus as claimed in any of claims 13 to 20
wherein the input means is further operable to input

portion information representative of a portion of the
image to which the color information relates and wherein

the generating means is operable to use both the color
information and the portion information to generate the

sample image. 
Apparatus as claimed in claim 21, wherein said input
means is operable such that the portion information

indicates a portion representative of an object image and
is filled by a color defined by the color information

(S10,S11).
Apparatus as claimed in claim 22 wherein the input
means comprises a pointing device (31) responsive to

input by an operator by drawing said object image on a
display using the pointing device to define said portion

information.
Apparatus as claimed in claim 22 wherein the input
means comprises a scanner operable to input said portion

information.
A computer program comprising processor
implementable instructions for controlling an image

searching apparatus to carry out all of the steps of a
method as claimed in any of claims 1 to 12.
</CLAIMS>
</TEXT>
</DOC>
