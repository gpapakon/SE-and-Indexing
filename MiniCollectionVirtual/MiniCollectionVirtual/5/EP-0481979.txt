<DOC>
<DOCNO>EP-0481979</DOCNO> 
<TEXT>
<INVENTION-TITLE>
DOCUMENT RECOGNITION AND AUTOMATIC INDEXING FOR OPTICAL CHARACTER RECOGNITION
</INVENTION-TITLE>
<CLASSIFICATIONS>G06K936	G06K920	G06F1724	G06K920	G06F1724	G06K936	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06K	G06K	G06F	G06K	G06F	G06K	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06K9	G06K9	G06F17	G06K9	G06F17	G06K9	</CLASSIFICATIONS-FOURTH>
<APPLICANTS>
<APPLICANT-NAME>
EASTMAN KODAK CO
</APPLICANT-NAME>
<APPLICANT-NAME>
EASTMAN KODAK COMPANY
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BARSKI LORI LYNN
</INVENTOR-NAME>
<INVENTOR-NAME>
GABORSKI ROGER STEPHEN
</INVENTOR-NAME>
<INVENTOR-NAME>
BARSKI, LORI, LYNN
</INVENTOR-NAME>
<INVENTOR-NAME>
GABORSKI, ROGER, STEPHEN
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
Optical character recognition systems are 
useful for automatically reading the contents of a 
document for storage in a computer memory. An image 
sensor scans the document and generates image data, 
which the optical character recognition system 
transforms into text. The data representing the 
text is then immediately stored in a computer memory 
for instant access and processing by the user. An important requirement is that the 
optical character recognition system either be able 
to distinguish between image data representing text 
characters and image data representing non-text 
things (e.g., printed lines), or else that the data 
representing printed lines or other non-text things 
be deleted from the image data before it is received 
by the optical character recognition system. When processing a plurality of different 
business forms, the optical character recognition 
system may be more efficient if it knows the 
locations of the various fields in a given business 
form containing text characters. For example, if 
the business form is a sales order form, the data 
may be used more quickly if the system already knows 
the location on the form of certain critical 
information such as the price, quantity, type, 
delivery address, etc... Knowing the location of 
the various fields on the form may also help the 
system orient the document image correctly in 
memory, or determine the boundary in the image data  
 
between one document and the next document. Thus, the optical character recognition 
system needs to know to which one of a plurality of 
known business forms a particular document 
(represented by incoming image data) corresponds if 
it is to operate at the highest efficiency. 
Therefore, for maximum efficiency, the incoming 
documents must first be grouped according to type of 
business form before they are processed by the 
optical character recognition system. As each group 
of documents is fed to the system, the user must 
inform the system as to which type of business form 
the current group corresponds. The sorting or 
grouping function may require an unacceptably large 
amount of the user's time. Thus, the problem is how to permit the 
optical character recognition system to operate at 
maximum efficiency without requiring the user to 
sort the incoming documents according to type of 
business form or to inform the system of the type of 
document about to be received. The necessity of first informing an image 
processing system of the type of form of an incoming 
document (i.e., the
</DESCRIPTION>
<CLAIMS>
A pre-processor for masking non-text 
matter from a document image for an optical character 

recognition system, said pre-processor comprising:
 
   means for storing in memory plural reference 

templates specifying spacings between pre-printed lines 
in corresponding plural pre-printed forms;
 
   means for receiving incoming video data 

comprising successive video lines representing the image 
of a document of unknown form;
 
   means for generating a sample template from 

said incoming video data, said sample template specifying 
spacings between pre-printed lines in said image of said 

document;
 
   means for determining which one of said plural 

reference templates most closely resembles said sample 
template;
 
   buffer means for storing the video data 

representing said one document;
 
   output processor means, responsive whenever 

said determining means identifies said one template, for 
fetching the video data from said buffer means and 

masking there from data representing pre-printed lines 
therein corresponding to the pre-printed line spacings 

and lengths in said one reference template, and for 
transmitting the data thus masked to said optical 

character recognition system, whereby said optical 
character recognition system is prevented from receiving 

non-text data. 
The pre-processor of Claim 1 wherein said 
plural reference templates and said sample template each 

specify the video line number of horizontal pre-printed 
lines.  

 
The pre-processor of Claim 2 wherein said 
means for generating a sample template comprise:
 
   means for generating a curve representing the 

linear density of "on" pixels in said video data as a 
function of video line number;
 
   means for locating peaks exceeding a 

predetermined threshold in said curve and noting the 
locations of said peaks. 
The pre-processor of Claim 3 wherein said 
means for generating a sample template further translates 

the noted locations of said peaks into a series of 
numbers representing spacings between successive 

horizontal lines in said image. 
The pre-processor of Claim 3 wherein said 
means for locating peaks in said curve comprise means for 

producing a differential of said curve and noting the 
locations of discontinuities in said differential of said 

curve. 
The pre-processor of Claim 1 wherein said 
means for determining which one of said plural reference 

templates most closely resembles said sample template 
comprises at least one of the following:
 
   means for finding which one of said plural 

reference templates exactly matches said sample template 
and noting the identity thereof; and
 
   means for computing a correlation between each 

of said plural reference templates and said sample 
template and noting which one of said plural reference 

templates has the highest correlation with said sample 
template. 
The pre-processor of Claim 6 wherein said  
 

means for determining include both said means for finding 
an exact match and said means for computing a 

correlation, and wherein said determining means further 
comprise:
 
   default means responsive whenever said means 

for finding fails to find an exact match for activating 
said means for computing said correlation. 
The pre-processor of Claim 1 wherein each 
of said templates comprises a pair of tables stored in 

memory, one of said tables listing spacings between 
subsequent pre-printed lines and the other of said tables 

represents the corresponding pre-printed lines lengths, 
the contents of each of said two tables being arranged in 

order of the location of corresponding pre-printed lines 
on said image. 
The pre-processor of Claim 1 wherein said 
plural reference templates stored in said means for 

storing are generated by transmitting the image data of 
the corresponding plural forms in succession to said 

means for receiving incoming video data, whereby said 
means for generating a sample template generates 

corresponding plural sample templates comprising said 
plural reference templates. 
A pre-processing method for masking non-text 
matter from a document image for an optical 

character recognition system, said method comprising:
 
   storing in memory plural reference templates 

specifying spacings between pre-printed lines in 
corresponding plural pre-printed forms;
 
   receiving incoming video data comprising 

successive video lines representing the image of a 
document of unknown form;
 
   generating a sample template from said incoming  

 
video data, said sample template specifying spacings 

between pre-printed lines in said image of said document;
 
   determining which one of said plural reference 

templates most closely resembles said sample template;
 
   storing the video data representing said one 

document;
 
   whenever said determining means identifies said 

one template, fetching the video data stored by said 
storing step and masking there from data representing pre-printed 

lines therein corresponding to the pre-printed 
line spacings and lengths in said one reference template, 

and transmitting the data thus masked to said optical 
character recognition system, whereby said optical 

character recognition system is prevented from receiving 
non-text data. 
The method of Claim 10 wherein said plural 
reference templates and said sample template each specify 

the video line number of horizontal pre-printed lines. 
The method of Claim 11 wherein said step 
of generating a sample template comprises:
 
   generating a curve representing the linear 

density of "on" pixels in said video data as a function 
of video line number;
 
   locating peaks exceeding a predetermined 

threshold in said curve and noting the locations of said 
peaks. 
The method of Claim 12 wherein said step 
of generating a sample template further translates the 

noted locations of said peaks into a series of numbers 
representing spacings between successive horizontal lines 

in said image.  
 
The method of Claim 12 wherein said step 
of locating peaks in said curve comprise producing a 

differential of said curve and noting the locations of 
discontinuities in said differential of said curve. 
The method of Claim 10 wherein said step 
of determining which one of said plural reference 

templates most closely resembles said sample template 
comprises at least one of the following:
 
   finding which one of said plural reference 

templates exactly matches said sample template and noting 
the identity thereof; and
 
   computing a correlation between each of said 

plural reference templates and said sample template and 
noting which one of said plural reference templates has 

the highest correlation with said sample template. 
The method of Claim 15 wherein said step 
of computing a correlation is performed whenever said 

step of finding fails to find an exact match. 
</CLAIMS>
</TEXT>
</DOC>
