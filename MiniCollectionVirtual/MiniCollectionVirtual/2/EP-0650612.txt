<DOC>
<DOCNO>EP-0650612</DOCNO> 
<TEXT>
<INVENTION-TITLE>
FAST INSTRUCTION DECODING IN A PIPELINE PROCESSOR
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F930	G06F938	G06F930	G06F938	G06F932	G06F932	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	G06F	G06F	G06F	G06F	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F9	G06F9	G06F9	G06F9	G06F9	G06F9	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
In a computer where instructions are fetched (17) in segments and where segments of an instruction are assembled (201) before execution is initiated, processing of instructions is accelerated by examining segments (203) of the instructions that are fetched. The information obtained from such examination is then used (206) to shorten the decoding step for the instruction.
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
ZILOG INC
</APPLICANT-NAME>
<APPLICANT-NAME>
ZILOG INCORPORATED
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
CHAN STEPHEN H
</INVENTOR-NAME>
<INVENTOR-NAME>
CHAN, STEPHEN, H.
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
This invention relates to a central processing unit [CPU]
and it has particular application to a CPU operating within a
pipeline architecture. The invention also relates to a method
of operating a CPU operating within a pipeline architecture.As will be explained the development of the invention has
been particularly concerned with accelerating processing in
cases where instructions contain opcodes having differing
numbers of bytes.The pipeline architecture has been used in the designs of
many of today's computers. The architecture resembles an
assembly line. It partitions the execution sequence of
instructions into a sequence of tasks (e.g. fetching
instructions, decoding instructions, execution, storing
results). To each of these tasks is provided a dedicated
station of resources. As instructions flow through the
pipeline, their tasks will be serviced by the stations
successively. Each instruction is followed by its next
sequential instruction which will occupy, as soon as possible,
the stations which it vacates. The time delay between the
initiation of different instructions and the completion
thereof under the pipeline architecture is therefore
compacted, and throughput of the computer is increased.An efficient station in a pipeline computer would create
a bottleneck. A bottleneck station dictates the throughput
of the computer because it dictates the flow speed of
instructions. If a 
bottleneck station can be accelerated, throughput of a
pipeline computer will be increased.A common bottleneck in pipeline computers is
the decoding of instructions with opcodes of non-uniform
lengths.Computer instructions normally have an opcode
from which signals for directing the processing of a
corresponding instruction are generated. The size of
the opcode for a computer usually depends on the width
of its data path, which in turn depends on its hardware
(arithmetic-logic unit, buses, decoder, etc.). If the
opcode is n bit long, it can be decoded into 2n
different bit combinations, and the computer would have
a set of 2n different types of instructions. Typically
in most of today's computer designs, n is an integer
multiple of eight (i.e. a byte).There are occasions, however, where the
instruction set of a computer needs to be expanded
without a corresponding expansion of its data path. One
such occasion arises when a computer must be upgraded to
provide more instructions without having to make
substantial changes to its hardware. When such
occasions arise, one or more bytes would commonly be
added to the opcode.In
</DESCRIPTION>
<CLAIMS>
A central processing unit [CPU] (12) comprising:


first means (14,17) for fetching instructions and storing
(201) t
hem, second means (15) for decoding instructions stored
by said first means (14,17), third means (16) responsive to

the decoded instructions for executing instructions,

   characterized by

fourth means (203-209) for examining, concurrently
with the fetching of an instruction by said first means

(14,17), a subset of bits in the instruction to generate a
selection signal controlling said first means to transfer a

selected portion of the instruction stored therein to said
second means.
A CPU as claimed in Claim 1 in which said first means
includes a first queuing means (201) for storing an

instruction and said fourth means includes a second queuing
means (204) for storing a signal derived from said subset of

bits of the instruction.
A CPU as claimed in Claim 2 in which said first (201) and
second (204) queuing means have equal numbers of entries.
A CPU as claimed in Claim 2 or 3 in which said fourth
means includes a decoder (203) responsive to the subset of

bits in each instruction to provide decoded signals to said
second queuing means (204).
A CPU as claimed in Claim 2, 3 or 4 in which said fourth
means comprises means (206) between said second queuing means

(204) and said first queuing means (201) to generate said
selection signal for application to said first queuing means

(201).
A CPU as claimed in any preceding claim wherein said
second means (15) is capable of decoding m bits of an n bit

opcode in an instruction, where n is greater than m, and
wherein said fourth means (14,17) is operable to examine said

subset of bits within the n bit opcode and to generate said
selection signal to select a portion of said n bit opcode that

is m bits long for transfer to said second means (15).
A CPU as claimed in any preceding claim wherein said
first means, second means and third means are organized into

a pipeline architecture. 
A method of operating a central processing unit [CPU]
(12) operating within a pipeline architecture in which the CPU

(12) has means (14,17) for fetching instructions from memory
and storing the instructions, means (15) for decoding

instructions stored by the first means, and means responsive
to a decoded instruction to execute the instruction, the

method being characterized by the steps of

examining (203) a subset of bits in an opcode of an
instruction concurrently with the fetching of the instruction,

and
generating a selection signal from the examining of said
subset of bits to select a portion of the instruction for

decoding.
A method as claimed in Claim 8 in which said subset of
bits is examined to see whether it has a predetermined value.
A method as claimed in Claim 8 in which said subset of
bits is decoded to provide values for controlling the

generation of the selection signal.
</CLAIMS>
</TEXT>
</DOC>
