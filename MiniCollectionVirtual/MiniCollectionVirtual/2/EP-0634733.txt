<DOC>
<DOCNO>EP-0634733</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Image processing
</INVENTION-TITLE>
<CLASSIFICATIONS>G06T900	A63F1300	G06T1570	A63F1300	G06T1540	G06T300	H04N5262	G06T300	G06T1300	H04N5262	G06T1570	G06T900	G06T1510	G06T1300	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06T	A63F	G06T	A63F	G06T	G06T	H04N	G06T	G06T	H04N	G06T	G06T	G06T	G06T	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06T9	A63F13	G06T15	A63F13	G06T15	G06T3	H04N5	G06T3	G06T13	H04N5	G06T15	G06T9	G06T15	G06T13	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
Moving output images are presented to a two dimensional 
display, such as a conventional television 

receiver (26). Three video sources are read from a 
compact disc, a notional front image and a notional back 

image being in the form of CD-I A and B planes. A 
notional back plane is a full frame, full video rate 

image, read from the disc as a coded MPEG data stream. 
After decoding, each pixel of each image includes 
depth data and opacity data. It is thus possible for an 

image in the notional front or notional middle plane to 
pass behind an object in the notional back plane. 
The depth and opacity data is severely compressed 
for the MPEG stream, by a process of quantisation and 

run-length encoding. 

</ABSTRACT>
<APPLICANTS>
</APPLICANTS>
<INVENTORS>
</INVENTORS>
<DESCRIPTION>
The present invention relates to a method of image
processing and image processing apparatus.In particular, the present invention relates to a
method of image processing in which moving output images
are presented as a two dimensional display, in the form
of time-separated two-dimensional frames of picture
elements (pixels), wherein said output images are
constructed from a first image and from a second image
and, over a plurality of frames, said first image
appears to move relative to a second image.The construction of images from several components,
which appear to move relative to one another, is known
in the field of computer graphics; particularly when
applied to computer games, etc. In such applications,
not only does one component appear to move relative to
the other but the movement is often under the interactive
control of an operator. Thus, the system is often
configured such that an operator has control of a
component of a displayed image, by use of a suitable
input device such as a joy-stick, tracker-ball, button
pad or keyboard, etc.While the interactive nature of such known computer
systems is impressive, the quality of the images displayed
tends to be somewhat artificial. A virtual three-dimensional
world-space may be simulated by a computer
graphics system but the number of coordinate points
which may be manipulated within this world-space in 
real-time is limited by the available processing facilities.
Most computer graphics systems will manipulate
a net of polygons for example and generate full colour
images, on a frame-by-frame basis, by a process of
rendering. Thus, it is difficult to specify the nature
of each pixel in the three dimensional world space, and
opportunities for achieving photo-realism are somewhat
limited.The manipulation of photo-realistic video images in
real time is known in the art of video-graphics. In
video-graphics, pixel values are manipulated so as to
introduce distortions, modifications and special
effects, while retaining the life-like quality of the
original image. However, such effects are achieved by a
significant amount of purpose built hardware, resulting
in machines which are expensive and very task-specific.
Furthermore, in known systems of this type, the video
image is always sheet-like; it may be mapped onto a
three dimensional object but it always remains in the
form of a skin. Thus, video sequences may be created in
which an object appears to be behind another object but
this is only an illusion created by an artist. Thus,
the machine provides an
</DESCRIPTION>
<CLAIMS>
A method of image processing, in which moving output images are presented
as a two dimensional display (26), in the form of time-separated two-dimensional frames of

pixels, wherein

said output images are constructed from a first image and from a second image; and
over a plurality of frames, said first image appears to move relative to said second
image, characterised in that:
each of said first and second images has absolute depth values (DV1, DV2, DV3) defined for
all of the pixels making up the respective images;
depth values of said first image are compared with depth values of the pixels of said
second image to determine, on a pixel-by-pixel basis, whether pixels of the first image are

in front of or behind pixels of said second image,
wherein said absolute depth values are processed at a higher resolution but stored
at a lower resolution and lower resolution values are converted to higher resolutions values

by means of a look-up table (31,32,33); and
preferential contributions are obtained from the front-most pixels of either the first
image or the second image, in order to generate an output image in which said first image

appears to move into or out from a display plane, so as to be in front of or behind
elements of said second image, in response to their relative depth values.
A method according to Claim 1, wherein said look-up table is reprogrammable
for each image frame.
A method according to Claim 1, wherein depth values are stored as an array
of values compressed by a process of two-dimensional run length encoding and combined

with temporally and spatially compressed video data.
A method according to Claim 3, wherein opacity values are supplied for each
pixel of said first and second images, and processed with said depth values to calculate an

image factor for each pixel of each image.
A method according to Claim 1, including a third video image, wherein
depth values are considered on a pixel-by-pixel basis for each corresponding pixel location

for each of said three images. 
Image processing apparatus, including means for presenting moving output
images to a two-dimensional display (26), in the form of time separated two-dimensional frames

of pixels, and means for constructing said output images from a first image and from a
second image such that over a plurality of frames, said first image appears to move relative

to said second image, characterised by:

means (21,22,24) for processing said data at a higher resolution so that said first image appears
to move into or out from a display frame, so as to be in front of or behind elements of

said second image, in response to depth values defined for said first image, with said first
and second images having absolute depth values defined for all of the pixels

making up the respective images;
means for receiving depth values (DV1,DV2,DV3) stored at a lower resolution and operable to
convert them to said higher resolution by means of look up tables (31,32,33),
means (35,36,37) for comparing depth values of said first image with the depth values of pixels
of said second image to determine, on a pixel-by-pixel basis, whether pixels of said first

image are in front of or behind pixels of said second image; and
means (23) for combining preferential contributions from the front-most pixels of either
the first image or the second image in order to generate an output image.
Apparatus according to claim 6, including means for re-programming said
look up tables on a frame-by-frame basis.
Apparatus according to Claim 6, including means for de-compressing two-dimensional
run-length encoded data defining said depth values, and
Apparatus according to Claim 6, including means for supplying opacity
values for each pixel of the video images, and

   processing means for processing said opacity values to calculate image factors for
each pixel of each input image.
Apparatus according to Claim 9, including means for decompressing and
decoding opacity values, coded by quantisation and two-dimensional run-length encoding,

an read from a storage device.
Apparatus according to Claim 9, wherein said opacity values are generated
from data defining the position of edge transitions at a definition greater than the pixel 

spacing.
Apparatus according to Claim 6, including means for generating a third video
image, wherein depth values are considered on a pixel-by-pixel basis for each pixel location

for each of said three images.
</CLAIMS>
</TEXT>
</DOC>
