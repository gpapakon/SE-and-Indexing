<DOC>
<DOCNO>EP-0631222</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Gazing point estimation device.
</INVENTION-TITLE>
<CLASSIFICATIONS>A61B3113	A61B3113	G06F300	G06F300	G06F301	G06F301	G06F3033	G06F3033	G06F3038	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>A61B	A61B	G06F	G06F	G06F	G06F	G06F	G06F	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>A61B3	A61B3	G06F3	G06F3	G06F3	G06F3	G06F3	G06F3	G06F3	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
The device described enables calibration data indispensable for 
calculation of a gazing point to be fetched and also an estimation of a 

gazing point to be determined by calculating a pupil center position 
through image-processing data obtained via a camera, increasing the 

brightness of a gazing point on a display screen according to the 
calculated values and calibration data, measuring the change in pupil 

area at the moment, establishing a correlation, thereby improving the 
operability of a gazing point estimation system. 


</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
IBM
</APPLICANT-NAME>
<APPLICANT-NAME>
INTERNATIONAL BUSINESS MACHINES CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
ETOH HIROAKI
</INVENTOR-NAME>
<INVENTOR-NAME>
HAMA TOSHIYUKI
</INVENTOR-NAME>
<INVENTOR-NAME>
MISONO SHINJI
</INVENTOR-NAME>
<INVENTOR-NAME>
ETOH, HIROAKI
</INVENTOR-NAME>
<INVENTOR-NAME>
HAMA, TOSHIYUKI
</INVENTOR-NAME>
<INVENTOR-NAME>
MISONO, SHINJI
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
This invention relates to a system for interfacing a user with a 
computer, and more particularly to a system that estimates a user's 
gazing point on a screen. One type of interface between a computer and a user who is unable 
to use his/her hands due to, for example, disability, utilises the user's 
gaze. Of interfaces of this kind, the least burdensome to users and 
highest in the degree of freedom is a non-contact system that estimates a 
user's gazing point on the screen of a display using a video camera and a 
source of infrared radiation. Examples of known non-contact man-machine 
interfaces are described in Richard A. Bolt, "Evolutionary Theory of Man-Machine 
Interfaces," Personal Media (1986), D. L. Gardener, Looking at 
Looking", in Proceedings of the PS/2 Future Symposium, A Vision of the 
Future, The Ideal 1993 Personal System, Boca Raton, FL. April 1988. In such a device, data obtained through a video camera is first 
image-processed to determine the contour of the user's eye and the 
central position of his/her pupil, and then reflected light from the 
cornea is measured by casting infrared rays on the user's eye. A gazing 
point on the screen is estimated by using the data thus obtained. However, this conventional device poses problems. One is a problem 
of calibration. Estimation of a gazing point entails obtaining data as 
to reference points (such as the four corners of the screen) in order to 
specify the absolute position of a gazing point. Such data is needed at 
the beginning of work and also each time the user's posture changes 
greatly. Moreover, inasmuch as the correlative relation between the 
movement of the eye and a change from one gazing point to another 
includes parameters dependent on each individual, calculation data 
becomes necessary for determination of such parameters. Hence, the 
conventional system requires reference point data and calculation data to 
be fetched each time there is a change from one user to another. Such 
data is usually collected by a user's gazing at two or more predetermined 
points in sequence on the screen prior to beginning work. However, this 
method is disadvantageous in that a user's flow of thought is interrupted 
because the object to be gazed at has nothing to do with the work the 
user wishes to do at the outset.  Another problem is as to how to determine the results of gazing 
point estimation. In this respect, there is no effective method for the 
system to judge whether or not a spot on the screen estimated from the 
above data
</DESCRIPTION>
<CLAIMS>
A gazing point estimation device comprising: 
   a display (1); 

   means (3) for calculating a central position of a user's pupil 
gazing on the screen of the display (1); 

   means (4) for detecting changes in the area of the user's pupil; 
   means (5) for estimating the user's gazing point on the screen 

based on calculation data obtained by the calculating means (3) and 
calibration data; and 

   means (6) for changing the brightness of the estimated gazing 
point; wherein a current pupil center position and an estimated gazing 

point are accumulated in the estimating means (5) to serve as calibration 
data for estimating the user's gazing point in response to a change in 

the area of the user's pupil being detected by the detecting means (4) 
and no change in pupil center position being detected by the calculating 

means (3) after a change in brightness. 
A device as claimed in Claim 1, wherein the estimating means 
further estimates another gazing point when said change in pupil area and 

a change in pupil center position are detected. 
A device as claimed in Claim 1, wherein the brightness changing 
means moves a pointer provided as a mouse cursor or a editing cursor on 

the screen to an estimated gazing point and increases the brightness of 
the pointer zone only. 
A device as claimed in Claim 1, wherein the brightness changing 
means increases the brightness of the display data in the position of an 

estimated gazing point on the screen. 
A computer system comprising a device as claimed in any preceding 
claim. 
A method of estimating gazing point on a display screen, the method 
including: 


a) calculating a central position of a user's pupil gazing on 
the display screen; 
b) detecting changes in the area of the user's pupil; 
c) estimating the user's gazing point on the screen based on 
calculation data obtained in step a) and calibration data; 
d) changing the brightness of the estimated gazing point; and 
e) accumulating a current pupil center position and an estimated 
gazing point to serve as calibration data for estimating the user's 

gazing point in response to a change in the area of the user's pupil 
being detected and no change in pupil center position being detected 

after a change in brightness. 
</CLAIMS>
</TEXT>
</DOC>
