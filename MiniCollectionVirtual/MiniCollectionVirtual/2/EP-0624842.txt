<DOC>
<DOCNO>EP-0624842</DOCNO> 
<TEXT>
<INVENTION-TITLE>
METHOD FOR AUTOMATED DEPLOYMENT OF A SOFTWARE PROGRAM ONTO A MULTI-PROCESSOR ARCHITECTURE.
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F946	G06F946	G06F950	G06F1516	G06F1516	G06F15177	G06F1576	G06F1582	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	G06F	G06F	G06F	G06F	G06F	G06F	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F9	G06F9	G06F9	G06F15	G06F15	G06F15	G06F15	G06F15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A method is employed for pre-assignment and 
prescheduling of tasks that enables allocation across 

multiple physical processors arranged in a variety of 
architectures. The method comprises the steps of: 

constructing a DFG of tasks to be performed to provide 
a solution for a problem; determining cost values for 

each task and the overall problem, such cost values 
taking into account a target multiprocessor 

architecture and factors such as elapsed task 
execution times. The method pre-assigns the tasks to 

logical processors and assures that inter-dependent 
tasks are executable by logical processors that are 

within required communications delay criteria of each 
other. The assigning action attempts to arrive at a 

minimal cost value for all tasks comprising the 
problem. The pre-assigned tasks are then pre-scheduled 

based upon a performance criteria and are converted to 
machine code. The machine code is then deployed to 

physical processors in the target multi-processor  
 

architecture. The deploying action maps the logical 
processors' pre-assigned programs (comprising assigned 

tasks) onto physical processors, using data regarding 
the multi-processor architecture and the current 

utilization of the physical processors in the 
architecture, all while assuring that inter-dependent 

tasks are mapped so as to fulfil interprocessor 
communication delay criteria. 
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
LORAL ROLM MIL SPEC CORP
</APPLICANT-NAME>
<APPLICANT-NAME>
LORAL/ROLM MIL-SPEC CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
ELLIOTT JON K
</INVENTOR-NAME>
<INVENTOR-NAME>
HERRING ALAN J
</INVENTOR-NAME>
<INVENTOR-NAME>
HILLER JOHN A
</INVENTOR-NAME>
<INVENTOR-NAME>
HUNT PETER D
</INVENTOR-NAME>
<INVENTOR-NAME>
MORGAN CRAIG R
</INVENTOR-NAME>
<INVENTOR-NAME>
TOBIAS RICHARD J
</INVENTOR-NAME>
<INVENTOR-NAME>
ELLIOTT, JON K.
</INVENTOR-NAME>
<INVENTOR-NAME>
HERRING, ALAN J.
</INVENTOR-NAME>
<INVENTOR-NAME>
HILLER, JOHN A.
</INVENTOR-NAME>
<INVENTOR-NAME>
HUNT, PETER D.
</INVENTOR-NAME>
<INVENTOR-NAME>
MORGAN, CRAIG R.
</INVENTOR-NAME>
<INVENTOR-NAME>
TOBIAS, RICHARD J.
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
This invention relates to multi-processor 
architectures, and more particularly, to a method and 
apparatus for automatically deploying a software 
procedure onto a multi-processor architecture to 
enable efficient and parallel runtime performance of 
the software procedure. Multi (i.e., parallel) processor architectures 
employ many interconnected processors to access large 
amounts of data and to simultaneously process a large 
number of tasks at high speed. Many multi-processors 
can execute instructions with operands that are arrays 
of data and are called vector or array processors. In 
order to obtain maximum utilization of a multiprocessor, 
as many tasks as possible need to be 
scheduled for simultaneous execution on the available 
processors. Furthermore, interrelationships between 
various tasks must be continuously taken into account 
so as to assure ready availability of input operands 
when each task is ready to run. Scheduling of a task 
must be carefully controlled or else the entire 
benefit derived from the parallel processing may be 
lost, because one processor, due to a lack of 
necessary input data, can delay a plurality of others. Data Flow Graphs (DFG's) are often used by 
scientists and engineers to enable visualization of  
 
individual procedure tasks and their 
interrelationships. A DFG is a directed graph wherein 
edges (interconnections) denote data flows and nodes 
are functions or tasks that manipulate the data. The 
execution of a task, called the firing of a node, 
occurs when enough data is available on each input 
edge of the node. Associated with an input edge is a 
property called the threshold. When the data meets or 
exceeds the threshold on each of the input edges, the 
node fires. Each time the node fires, it "consumes" 
some amount of data from each edge that serves as an 
input to the node. The amount of data the node 
consumes is less than or equal to the threshold value. 
Each time a node fires, it produces some amount of 
data and places it on its output edges. Normally, this 
data is then consumed by some set of other nodes. To aid in an understanding of terms to be used 
herein, the following definitions are provided: Primitive/Task - The task or function 
represented by a node of a DFG is a primitive. A 
primitive may be any procedure that is preprogrammed 
and available from a library of procedures, to perform 
a specific task. Node - A graphical representation of a 
primitive. While a node in a DFG is performed on a 
processor, the term node does not
</DESCRIPTION>
<CLAIMS>
A method for pre-assigning and pre-scheduling 
tasks that comprise a problem to multiple physical 

processors in a multi-processor architecture, the 
method enabling allocation of the tasks to multiple 

physical processors arranged in any of a plurality of 
target architectures, the method comprising the 

computer implemented steps of: 

(a) constructing a data flow graph (DFG) of tasks to 
be performed to solve the problem; 
(b) determining cost values for each task and the 
problem; 
(c) pre-assigning the tasks to logical processors, a 
logical processor comprising a data structure; 
(d) pre-scheduling the pre-assigned tasks based upon 
a performance criteria; 
(e) converting the tasks to machine code; and 
(f) deploying said machine code comprising each 
logical processor and its pre-assigned tasks to 

physical processors arranged in a target multiprocessor 
architecture, the deploying using data 

regarding the chosen target multiprocessor 
architecture and data indicating current u
tilization 
of one of the physical processors arranged in the 

chosen target architecture to map each logical 
 

processor and pre-assigned task machine code onto one 
of the physical processors. 
A method as claimed in claim 1, wherein each cost 
value determined in step (b) includes factors related 

to execution time for each task and the problem. 
A method as claimed in claim 1 or 2, wherein the 
pre-assigning step (c) includes, for interdependent 

tasks, determining interprocessor communications delay 
criteria for logical processors to which the 

interdependent tasks are assigned, the pre-assigning 
attempting to achieve a minimal cost value for all 

tasks comprising the problem. 
A method as claimed in claim 3, wherein the 
deploying in step (f) further assures that logical 

processors with interdependent tasks are mapped onto 
the physical processors so as to fulfil an 

interprocessor communication delay criteria determined 
in step (c). 
A method as claimed in claim 1, wherein a data 
base is provided that includes details regarding the 

chosen target architecture, the pre-assigning step (c) 
and pre-scheduling step (d) utilizing the details in 

determining which tasks, both independent and 
interdependent are to be assigned to the logical 

 
processors. 
A method as claimed in claim 5, wherein step (f) 
arrives at a determination of current utilization of 

physical processors by maintaining an availability 
record, the availability record enabling a 

determination to be made as to whether a physical 
processor is available for deployment of one of the 

logical processor and its pre-assigned tasks. 
A method as claimed in claim 6, wherein step (f), 
in deploying a first logical processor and assigned 

first task to an available physical processor, 
additionally, determines whether another physical 

processor that fulfils an interprocessor delay 
criteria is available for assignment of a second 

logical processor and assigned second task, the second 
logical processor requiring the interprocessor delay 

criteria and if not available, attempts redeployment 
of the first and/or second logical processors to 

physical processors that fulfil, together, the 
interprocessor delay criteria. 
A method as claimed in any one of claims 1 to 7, 
wherein the performance criteria defined in step (d) 

is that each task should be executed on an as soon as 
possible (ASAP) basis. 
A method as claimed in claim 8 wherein both ASAP 
and as late as possible (ALAP) times for each task are 

determined, based upon a topological sort of the DFG, 
the topological sort deriving a linear list of tasks 

each task in the linear list that precedes another 
task requiring no inputs from said another task and 

all tasks listed subsequently to said another task in 
the linear list. 
A method as claimed in claim 1, wherein step (a) 
further comprises: 

(d1) analysing the pre-schedule of the pre-assigned 
tasks to determine a quality measure of the pre-schedule 

and repeating step (b) to arrive at an 
altered pre-assignment, which altered pre-assignment 

is then subjected to a repeated rescheduling step and 
analysis of the rescheduling step to determine if the 

quality measure has been improved. 
A method as claimed in claim 10, wherein a quality 
measure is, for a logical processor, an amount of gap 

time that the logical processor must wait for inputs 
from another logical processor before a task can be 

executed on the logical processor. 
</CLAIMS>
</TEXT>
</DOC>
