<DOC>
<DOCNO>EP-0646263</DOCNO> 
<TEXT>
<INVENTION-TITLE>
COMPUTER GRAPHIC AND LIVE VIDEO SYSTEM FOR ENHANCING VISUALISATION OF BODY STRUCTURES DURING SURGERY
</INVENTION-TITLE>
<CLASSIFICATIONS>G06T1500	G06T1740	A61B1900	A61B1700	G06T1500	A61B1700	G06T1740	G06T100	A61B1900	G06T100	G06F1900	H04N1300	H04N1300	G06F1900	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06T	G06T	A61B	A61B	G06T	A61B	G06T	G06T	A61B	G06T	G06F	H04N	H04N	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06T15	G06T17	A61B19	A61B17	G06T15	A61B17	G06T17	G06T1	A61B19	G06T1	G06F19	H04N13	H04N13	G06F19	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
An interactive surgery planning and display system mixes live video of external surfaces of the patient with interactive computer generated models of internal anatomy obtained from medical diagnostic imaging data of the patient. The computer images and the live video are coordinated and displayed to a surgeon in real-time during surgery allowing the surgeon to view internal and external structures and the relation between them simultaneously, and adjust his surgery accordingly. In an alternative embodiment, a normal anatomical model is also displayed as a guide in reconstructive surgery. Another embodiment employs three-dimensional viewing.
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
GEN ELECTRIC
</APPLICANT-NAME>
<APPLICANT-NAME>
GENERAL ELECTRIC COMPANY
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
ALTOBELLI DAVID EGIDIO
</INVENTOR-NAME>
<INVENTOR-NAME>
CLINE HARVEY ELLIS
</INVENTOR-NAME>
<INVENTOR-NAME>
DARROW ROBERT DAVID
</INVENTOR-NAME>
<INVENTOR-NAME>
DUMOULIN CHARLES LUCIAN
</INVENTOR-NAME>
<INVENTOR-NAME>
KELLIHER TIMOTHY PATRICK
</INVENTOR-NAME>
<INVENTOR-NAME>
KIKINIS RON
</INVENTOR-NAME>
<INVENTOR-NAME>
LORENSEN WILLIAM EDWARD
</INVENTOR-NAME>
<INVENTOR-NAME>
NAFIS CHRISTOPHER ALLEN
</INVENTOR-NAME>
<INVENTOR-NAME>
ALTOBELLI, DAVID, EGIDIO
</INVENTOR-NAME>
<INVENTOR-NAME>
CLINE, HARVEY, ELLIS
</INVENTOR-NAME>
<INVENTOR-NAME>
DARROW, ROBERT, DAVID
</INVENTOR-NAME>
<INVENTOR-NAME>
DUMOULIN, CHARLES, LUCIAN
</INVENTOR-NAME>
<INVENTOR-NAME>
KELLIHER, TIMOTHY, PATRICK
</INVENTOR-NAME>
<INVENTOR-NAME>
KIKINIS, RON
</INVENTOR-NAME>
<INVENTOR-NAME>
LORENSEN, WILLIAM, EDWARD
</INVENTOR-NAME>
<INVENTOR-NAME>
NAFIS, CHRISTOPHER, ALLEN
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to a system for aiding a
surgeon in visualizing body structures during surgery and more
specifically to a system which displays, in real time, interactive images
of both internal and external body structures to aid in surgery.Presently, during surgery, surgeons view several static
views of the patient in the operating room. Typically these are
transparencies of magnetic resonance (MR), computer tomography
(CT), or ultrasound images. Since these images are two dimensional
static images, the surgeons must determine actual three-dimensional
(3D) location and shape of desired internal structures within the patient
from the 2D images which they are viewing. Conceptually, the
surgeon constructs a 3D model of the internal structures and correlates
these internal structures with visible external structures of the patient
where they must cut. This is often difficult because the scale and the
orientation of the 2D image may differ from what the surgeon is
seeing, and the surgeon may not be able to view both the
patient and the medical diagnostic images 
simultaneously.Another technique employed in localization of internal
structures during surgery is known as stereotactic surgery as
described in "Interactive Stereotactic Surgical System for the
Removal of Intracranial Tumors Utilizing the CO2 Laser and CT-Derived
Database" by B. A. Kall, P. J. Kelly, and S. J. Goerss, IEEE
Transactions on Biomedical Engineering, vol. BME-32, no. 2, pp 112-116,
1985; and "Comprehensive Computer-Assisted Data Collection
Treatment Planning and Interactive Surgery" by B. A. Kall, P. J
Kelly, and S. J. Goerss, Medical Imaging, vol. 767 pp. 509-514, 1987.
With this approach, a rigid mechanical frame is attached to the
patient before a CT or MR procedure. The frame and its landmarks
can be seen in the resulting images. Mechanisms on the frame
position a probe at specific location within the image. The
disadvantages of this approach are that the frame limits access to the
patient, and the images are static images which do not follow the
patient if he moves during surgery.A third technique used for localization of internal structures is
described in "A Frameless Stereotaxic Operating Microscope for
Neurosurgery" by E. M. Friets, J. W. Strohbehn, J. F. Hatch, and D.
W. Roberts, IEEE Transactions on Biomedical Engineering, vol. 36.,
no.6, pp 608-617, June 1989.Three dimensional models of anatomy can be created from
data of different medical imaging modalities as described in the
application EP-A-0549183,
</DESCRIPTION>
<CLAIMS>
A real time apparatus for augmenting a surgeon's or physician's
view of a patient comprising:-


a) medical imaging device (10) to create volumetric three
dimensional image data of internal structures of a patient (1) and to output

said volumetric three dimensional image data of internal structures;
b) an imaging device (12) to provide in real time images of visible
external structures of said patient (1);
c) a tracking device (50) coupled to both said imaging device (12)
and said patient (1) to determine the relative location data and orientation

data of said imaging device (12) with respect to said patient (1) and to
output said relative location data and orientation data;
d) a model workstation (100) to receive and store said volumetric
three dimensional image data of internal structures of a patient from said

medical imaging device (10) and to receive relative location data and
orientation data from said tracking device (50), to process said volumetric

three dimensional image data in order to segment said internal structures
in such a way to be treated as separate solid object and to create images

of said internal structures of said patient that coincide with the image
viewed from said imaging device (12) from a different location and

orientation;
e) a model cut plane input device (40) and workstation view input
device (60) to select the method of displaying said internal structures of

said patient (1) and to provide said information to said model workstation
(100);
f) a scan converter (192) to convert said created images of said
internal structures of said model workstation (100) from computer monitor

signal format to a video format and to output said created images in video
format;
g) a video mixer (194) receiving images of visible external
structures from said imaging device (12) and said created images in video 

format from said scan converter (192) to provide a desired mix of said
images and to output said mixed images;
h) a display (250) for displaying said images provided by said video
mixer (194) wherein said displayed images comprise internal structures

and related external structures simultaneously displayed.
An apparatus as claimed in claim 1, wherein the imaging device
(12) for providing real-time video images of visible external structures of

the patient comprises video camera means for providing real time video
images of exposed surfaces of the patient (1) from a camera viewpoint

being a location (x,y,z) and orientation angle (α,,) with respect to the
patient (1), and being substantially the same as the viewpoint of the

patient (1) as viewed by the surgeon or physician.
An apparatus as claimed in claim 2, wherein the video mixer comprises means
to (194) create a composite image being a desired mixture of the video

image of exposed surfaces, and the computer image of the selected
surfaces of the internal structures for most of the composite image, with a

moveable window being a region of the composite image showing
the video image, or the computer image.
An apparatus as claimed in claim 3, wherein the display (250) comprises means
to display the composite image resulting in an image of semi-transparent

exposed surfaces correctly registered with the internal structures, and a
view of the patient (1) as viewed by the surgeon or physician to allow the

surgeon or physician to locate internal structures relative to visible external
surfaces.
An apparatus as claimed in any one of claims 2 to 4, wherein the
tracking device (50)

comprises means to
measure the location (x,y,z) and orientation (α,,) of

the imaging device with respect to the patient (1), to repeatedly provide
these measurements to the workstation (100).
An apparatus as claimed in any preceding claim, wherein the
workstation (100) further comprises surgical planning means to create

segmented models of the patient's internal structures before surgery,
interactively manipulate the models to result in modifications to internal

structures, store the models and modifications and display the models and 
modifications at the proper orientation and scale to coincide with other

images being displayed.
An apparatus as claimed in any preceding claim, wherein the
workstation (100) further comprises a standard anatomy workstation means to

create normal segmented anatomical models of internal structures, and to
display the models at the proper orientation and scale to coincide with

other images being displayed for guidance
in reconstructive surgery.
An apparatus as claimed in claim 1 wherein the imaging device
(12) for providing real time images of visible external structures of the

patient (1) comprises a video camera means (12a, 12b) for providing
stereoscopic right and left real-time images of exposed surfaces of the

patient (1) viewed from a right to left location (x
1
,y
1
,z
1
)(x
2
,y
2
,z
2
) and right to
left orientation angle (α
1
,
1
,
1
) (α
2
,
2
,
2
) respectively, being substantially
the locations and orientations of the eyes of the surgeon or physician

relative to the patient (1) and the tracking means (50) comprising means to measure locations
(x
1
,y
1
,z
1
)(x
2
,y
2
,z
2
) and orientation angle (α
1
,
1
,
1
) (α
2
,
2
,
2
) of the video
camera means (12a, 12b) relative to the patient (1).
An apparatus as claimed in claim 8 further comprising a first workstation
(100a) for receiving right location (x
1
,y
1
,z
1
) and orientation
angle (α
1
,
1
,
1
) from the tracking means (50), and for receiving 3D
imaging data from the medical imaging device (10) and creating a right

computer generated image of internal structures of the patient (1) as
viewed from location (x
1
,y
1
,z
1
) and orientation angle (α
1
,
1
,
1
) and a
second workstation (100b) for receiving left location (x
2
,y
2
,z
2
)
and orientation angle (α
2
,
2
,
2
) from the tracking means (50), and for
receiving 3D imaging data from the medical imaging system (10) and

creating a left computer generated image of internal structures of the
patient (1) as viewed from locations (x
2
,y
2
,z
2
) and orientations (α
2
,
2
,
2
).
An apparatus as claimed in claim 9 wherein the video mixer further comprising
means (194) to create a plurality of composite right view images and a plurality of

composite left view images being a semi-transparent mixture of real-time
video images of exposed surfaces superimposed upon a semi-transparent 

mixture of the computer generated images of the internal structures,
respectively, for most of the composite images, with a moveable window

being a region of each composite image showing substantially only the
video image, or the computer image.
An apparatus as claimed in claim 10, wherein the display (250) comprises
stereoscopic display means for providing composite right view images

to the surgeon's or physician's right eye, and composite left view images
to the surgeon's or physician's left eye thereby simulating a 3D image

having the desired degree of visibility of internal structures correctly
registered with external structures, and a view of the patient (1) by the

surgeon or physician.
A method of augmenting a surgeon's or physician's view of a
patient comprising:-


a) acquiring volumetric three dimensional image data of internal
structures of a patient (1) and providing said volumetric three dimensional

image data of internal structures to a model workstation (100);
b) acquiring real time images of visible external structures of said
patient (1) by means of an imaging device (12);
c) determining the relative location data and orientation data of said
imaging device (12) with respect to said patient (1) and to provide said

relative location data and orientation data to said model workstation (100);
d) storing said volumetric three dimensional image data of internal
structures of a patient (1), processing said volumetric three dimensional

image data in order to segment said internal structures in such a way as to
be treated as separate solid object and creating images of said internal

structures of said patient (1) that coincide with the image viewed from the
same location and orientation as said external structures;
e) selecting the method of displaying said internal structures of said
patient and providing said information to said model workstation (100);
f) converting said created images of said internal structures of said
model workstation (100) from computer monitor signal format to a video

format and providing said created images in video format to a video mixer
(194); 
g) mixing the video images of visible external structures and said
created images in video format to provide a desired mix of said images

and providing said mixed images to a display (250);
h) displaying said mixed images wherein the displayed images
comprise internal structures and related external structures simultaneously

displayed.
A method as claimed in claim 12, wherein the step of acquiring
real time images of visible external structures of said patient (1) comprises

acquiring real-time video images of exposed surfaces of the patient (1)
viewed from a location (x,y,z) and orientation angle (α,,) with respect to

the patient (1), being substantially the location and orientation angle of the
surgeon's or physician's view
A method as claimed in claim 13, wherein the mixing of the
video images comprises mixing the real-time video images of the exposed

surfaces with the computer images to produce a composite image of a
semi-transparent image of the exposed surfaces superimposed upon a

semi-transparent image of the internal structures as viewed from the same
location and orientation for most of the composite image, and generating a

moveable window being a region of the composite image showing
only one of the video image and, or the computer image.
A method as claimed in claim 14, wherein the step of displaying
comprises displaying the composite image to provide desired visibility of

exposed structures correctly registered relative to internal structures, and
a view of the patient by the surgeon or physician to allow the surgeon or

physician to locate internal structures relative to visible external surfaces.
A method as caimed in claim 12 , further comprising the step of
creating a computer generated guide image of normal internal structures

viewed from the location (x,y,z) and orientation angle (α,,) for guidance
to reconstructive surgery; and mixing portions of the guide image

with the images produced in step g.
A method as claimed in claim 12, wherein the step of acquiring
real time images of visible external stuctures of the patient comprises

acquiring stereoscopic left and right real-time video images of exposed 
surfaces of the patient (1) viewed from a left and right locations

(x
1
,y
1
,z
1
)(x
2
,y
2
,z
2
) and left and right orientation angles (α
1
,
1
,
1
) (α
2
,
2
,
2
),
respectively relative to the patient (1).
A method as claimed in claim 17, wherein the step of
determining the relative location data and orientation data comprises

measuring the locations (x
1
,y
1
,z
1
)(x
2
,y
2
,z
2
) and orientation angles
(x
1
,y
1
,z
1
)(x
2
,y
2
,z
2
), respectively;
A method as claimed in claim 18, and further comprising
creating a left computer generated image and a right computer generated

image of internal structures from the 3D imaging data of the patient (1)
viewed from the same locations (x
1
,y
1
,z
1
)(x
2
,y
2
,z
2
) and orientation angles
(α
1
,
1
,
1
)(α
2
,
2
,
2
) as the video images of exposed surfaces, respectively;
A method as claimed in claim 19 wherein the step of mixcing
the video and created images comprises mixing a desired portion of the

real-time left video image and left computer generated image to result in a
left composite image such that a semi-transparent image of internal

structures is superimposed upon a semi-transparent image of exposed
surfaces both viewed from location (x
1
,y
1
,z
1
) and orientation (α
1
,
1
,
1
), and
mixing a desired portion of the real-time right video image and right

computer generated image to result in a right composite image such that a
semi-transparent image of exposed surfaces both viewed from location

(x
2
,y
2
,z
2
) and orientation angle (α
2
,
2
,
2
); generating a moveable window
being a region of each composite image showing only one of

the video image and, or the composite image.
A method as claimed in claim 20, further comprising alternately
providing left composite images to the surgeon's or physician's left eye,

and providing the right composite images to the surgeon's or physician's
right eye, thereby simulating a 3D image having the desired degree of

visibility of internal structures relative to external structures of the patient
(1) to allow the surgeon or physician to locate internal structures relative to

visible external surfaces. 
A method as claimed in claim 21, further comprising the step of
adjusting a scaling, location and orientation t
o the left and right real-time
images of exposed surfaces.
A method as claimed in any one of claims 12 to 22, further
comprising the step of tracing the image of internal structures on external

surfaces of the patient corresponding to the position of underlying internal
structures desired to be reached, to indicate where to make an incision.
A method as claimed in claim 12, including the steps of:

creating a computer model having identifiable surfaces of internal
structures from the 3D image data set;
rendering the 3D model to produce computer images of the internal
structures as viewed from the selected viewpoint;
selecting a relative degree of visibility of the external surfaces and
internal structures, and a region of a composite image desired to be

covered by a moveable window; and
displaying the external surfaces and internal structures in correct
registration with the selected relative degree of visibility for regions of the

composite image other than that covered by the moveable window, to
produce a relative representation of external surfaces to internal

structures, correctly registered with external surfaces as viewed and
displaying only one of the video images and, or the computer

images in the region of the moveable window.
</CLAIMS>
</TEXT>
</DOC>
