<DOC>
<DOCNO>EP-0649113</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Multifont optical character recognition using a box connectivity approach
</INVENTION-TITLE>
<CLASSIFICATIONS>G06T760	G06K964	G06K964	G06T760	G06K962	G06K962	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06T	G06K	G06K	G06T	G06K	G06K	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06T7	G06K9	G06K9	G06T7	G06K9	G06K9	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
Pattern recognition, for instance optical character 
recognition, is achieved by defining a minimal bounding 

rectangle around a pattern, dividing the pattern into a grid 
of boxes, comparing a vector derived from this partitioned 

pattern to vectors similarly derived from known patterns, 
choosing a set of Pareto non-inferior candidate patterns, and 

selecting a recognized pattern from the set of candidates. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
CANON KK
</APPLICANT-NAME>
<APPLICANT-NAME>
CANON KABUSHIKI KAISHA
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
KRTOLICA RADOVAN V
</INVENTOR-NAME>
<INVENTOR-NAME>
MALITSKY SOFYA
</INVENTOR-NAME>
<INVENTOR-NAME>
KRTOLICA, RADOVAN V.
</INVENTOR-NAME>
<INVENTOR-NAME>
MALITSKY, SOFYA
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates generally to image processing
and specifically to recognition of patterns, such as
optical characters, by partitioning a detected pattern into a
grid of boxes and comparing the connectivities and pixel
densities of such boxes to corresponding connectivities and
pixel densities from referent patterns.Numerous schemes have been proposed for pattern recognition
in the past. A great deal of research and development
has occurred, particularly in the area of optical character
recognition (OCR). See, for example, S.N. Srihari, V.
Govindaraju, J.J. Hull, R.K. Fenrich and S. Lam, "Pattern
Recognition, Character Recognition and Optical Character
Readers", Technical Report CEDAR-TR-91-1, Center for Document
Analysis and Recognition, State University of New York at
Buffalo, Buffalo, N.Y., May 1991.Known schemes for OCR vary widely in their approaches.
Some early attempts superimposed bit maps of detected images
over templates of known characters. Such schemes were extremely
sensitive to such factors as font differences, skewing,
enlargement, and reduction. Other approaches concentrated
on extracting particular features from detected characters. 
Results varied depending on the particular selection
and processing of features.U.S. Patent No. 3,846,752 to Nakano et al. discloses
character recognition using the density distribution
of a character. The frequency spectrum of the density
distribution is compared to that of density distributions
corresponding to known characters, and the known character
with the Fourier transform spectrum pattern most similar to
that of the detected character is output as the recognized
character.U.S. Patent No. 4,817,176 to Marshall et al. discloses
another pattern recognition scheme using Fourier transformation,
with various corrections for amplitude and phase differences.U.S. Patent No. 3,930,231 to Henrichon, Jr., et al. discloses
use of a multiple cell grid for detection of pattern
density and feature recognition. A vector signal is generated
for a detected character based on the presence or absence
of each recognizable feature, and this vector is compared
with vectors representing known characters.U.S. Patent No. 3,993,976 to Ginsburg discloses pattern
analysis using a transform to obtain spatial frequencies.
The spatial frequencies are filtered to extract pattern information
for determining general form, edge, texture, and
depth information of the detected pattern. U.S. Patent No. 4,513,441 to Henshaw discloses comparison
of two images by forming a
</DESCRIPTION>
<CLAIMS>
A computer-implemented process for recognizing a
pattern in an image among a se
t of known templates, the
process comprising the steps of:


extracting (503) a detected pattern from the image;
processing the detected pattern to produce a set of
matrices characterising the detected pattern;
comparing the matrices characterising the detected
pattern with corresponding sets of matrices

characterising the templates and determining (504) a
respective Hamming distance vector between the detected

pattern and each of the known templates;
choosing (505) a set of candidates from the set of
templates based on Pareto non-inferiority of the Hamming

distance vectors between the detected pattern and the
candidates; and
recognizing (507) the pattern based on the resulting
set of candidates; characterized in that;
the step of producing the matrices characterising
the pattern comprises;
partitioning the detected pattern into a grid of
boxes;
determining (501) a vertical adjacency matrix
indicating vertical connectivity of the boxes, a

horizontal adjacency matrix indicating horizontal
connectivity of the boxes and a pixel density matrix

indicating pixel density in each of the boxes; 
and wherein the comparing step comprises comparing
the matrices characterising the detected pattern with

corresponding vertical adjacency matrices, horizontal
adjacency matrices and pixel density matrices of the

respective templates.
A process as claimed in claim 1, wherein said
detected pattern is subdivided in said partitioning step

into n x n boxes.
A process as claimed in any preceding claim, wherein
the extracting step comprises scanning (502) the image

to obtain an intermediate pattern and applying (503) a
minimal bounding frame (301,401) to the intermediate

pattern.
A process as claimed in claim 3, wherein said
recognising step chooses a selected one of said templates

from said set of candidates by eliminating (510)
candidates based on geometric properties of said minimal

bounding frame.
A process as claimed in any of claims 3 and 4,
wherein said recognising step chooses (511) a selected

one of said templates from said set of candidates by
comparing probabilities of occurrence of each candidate

based on a context of the recognised pattern relative to 
adjacent recognised images.
A method as claimed in any of claims 1 to 3 wherein,
if the set of candidates obtained in the choosing step

comprises a single candidate, the recognizing step
recognizes (507) the pattern as corresponding to the

single candidate.
Apparatus for recognizing a pattern in an image
among a set of known templates, the apparatus comprising:


extracting means (102,104) for extracting a detected
pattern from the image;
a matrix processor (106) for processing the detected
pattern to produce a set of matrices characterising the

detected pattern;
a Hamming processor (108) for comparing the matrices
characterising the detected pattern with corresponding

sets of matrices characterising the templates and
determining (504) a respective Hamming distance vector

between the detected pattern and each of the known
templates;
a Pareto processor (110) for choosing a set of
candidates from the set of templates based on Pareto non-inferiority

of the Hamming distance vectors between the
detected pattern and the candidates; and
a recognition processor (206) for recognizing (507)
the pattern based on the resulting set of candidates; 

characterized in that;
the matrix processor is operable to produce the
matrices characterising the pattern by;
partitioning the detected pattern into a grid of
boxes;
determining (501) a vertical adjacency matrix
indicating vertical connectivity of the boxes, a

horizontal adjacency matrix indicating horizontal
connectivity of the boxes and a pixel density matrix

indicating pixel density in each of the boxes;
and wherein the Hamming processor comprises means
for comparing the matrices characterising the detected

pattern with corresponding vertical adjacency matrices,
horizontal adjacency matrices and pixel density matrices

of the respective templates.
Apparatus as claimed in claim 7, wherein said matrix
processor comprises means for subdividing the detected

pattern into n x n boxes.
Apparatus as claimed in any of claims 7 to 8 wherein
said extracting means comprises a scanner (102) for

scanning the image to obtain an intermediate pattern and
a framer (104) for applying a minimal bounding frame

(301,401) to the intermediate pattern.
Apparatus as claimed in claim 9, wherein said 
recognition processor is operable to choose a selected

one of said templates from said set of candidates by
eliminating (510) candidates based on geometric

properties of said minimal bounding frame.
Apparatus as claimed in any of claims 9 and 10,
wherein said recognition processor is operable to choose

a selected one of said templates from said set of
candidates by comparing probabilities of occurrence of

each candidate based on a context of the recognised
pattern relative to adjacent recognised images.
Apparatus as claimed in any of claims 7 to 9
wherein, if the set of candidates obtained in the

choosing step comprises a single candidate, the
recognition processor is operable to recognise the

pattern as corresponding to the single candidate.
</CLAIMS>
</TEXT>
</DOC>
