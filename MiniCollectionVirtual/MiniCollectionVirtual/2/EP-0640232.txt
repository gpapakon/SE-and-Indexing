<DOC>
<DOCNO>EP-0640232</DOCNO> 
<TEXT>
<INVENTION-TITLE>
METHOD FOR FUSING IMAGES AND APPARATUS THEREFOR
</INVENTION-TITLE>
<CLASSIFICATIONS>G06T300	G06T300	H04N146	G06T550	H04N718	H04N1409	H04N718	H04N146	H04N1409	H04N726	H04N726	G06T550	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06T	G06T	H04N	G06T	H04N	H04N	H04N	H04N	H04N	H04N	H04N	G06T	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06T3	G06T3	H04N1	G06T5	H04N7	H04N1	H04N7	H04N1	H04N1	H04N7	H04N7	G06T5	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A method for fusing two or more source images (In, n=1 to N) to form a composite image (Ic) with extended information content which may be color augmented and apparatus for forming the composite image from the source images is disclosed. Each source image is decomposed into a number of source images of varying resolution. The decomposed source image a are analyzed using directionally sensitive operators to generate a set of oriented basis functions (Pm, m=1 to N) characteristic of the information content of the original images. The oriented basis functions for the composite image are then selected from those of the different source images and the inverse of the decomposition performed to construct the composite image. Color augmentation provides information as to the relative weighting of the contribution of each source to the composite image.
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
SARNOFF CORP
</APPLICANT-NAME>
<APPLICANT-NAME>
SARNOFF CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BURT PETER JEFFREY
</INVENTOR-NAME>
<INVENTOR-NAME>
HINGORANI RAJESH
</INVENTOR-NAME>
<INVENTOR-NAME>
KOLCYNSKI RAYMOND
</INVENTOR-NAME>
<INVENTOR-NAME>
VAN DER WAL GOOITZEN SIEMEM
</INVENTOR-NAME>
<INVENTOR-NAME>
BURT, PETER, JEFFREY
</INVENTOR-NAME>
<INVENTOR-NAME>
HINGORANI, RAJESH
</INVENTOR-NAME>
<INVENTOR-NAME>
KOLCYNSKI, RAYMOND
</INVENTOR-NAME>
<INVENTOR-NAME>
VAN DER WAL, GOOITZEN, SIEMEM
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The invention relates to a method for fusing two or more
source images to form a composite image with extended information content
and apparatus for forming the composite image from the source images.Image fusion is a process that combines two or more source images to
form a single composite image with extended information content. Typically
images from different sensors, such as infra-red and visible cameras,
computer aided tomography (CAT) and magnetic resonance imaging (MRI)
systems, are combined to form the composite image. Multiple images of a
given scene taken with different types of sensors, such as visible and infra-red
cameras, or images taken with a given type of sensor and scene but under
different imaging condition, such as with different scene illumination or
camera focus may be combined. Image fusion is successful to the extent that:
(1) the composite image retains all useful information from the source images,
(2) the composite image does not contain any artifacts generated by the
fusion process, and (3) the composite image looks natural, so that it can be
readily interpreted through normal visual perception by humans or machines.
The term useful information as determined by the user of the composite image
determines which features of the different source images are selected for
inclusion in the composite image.The most direct approach to fusion, known in the art, is to align the
source images, then sum, or average, across images at each pixel position.
This and other pixel-based approaches often yield unsatisfactory results since
individual source features appear in the composite with reduced contrast or
appear jumbled as in a photographic double exposure.Known pattern selective image fusion tries to overcome these
deficiencies by identifying salient features in the source images and preserving
these features in the composite at full contrast. Each source image is first
decomposed into a set of primitive pattern elements. A set of pattern
elements for the composite image is then assembled by selecting salient
patterns from the primitive pattern elements of the source images. Finally,
the composite image is constructed from its set of primitive pattern elements.Burt in Multiresolution Image Processing And Analysis, V. 16, pages
20-51, 1981 (hereinafter "BURT") and Anderson et al in U.S. Patent No. 
4,692,806, incorporated herein by reference for its teachings on image
decomposition techniques, have disclosed an image decomposition technique in
which an original comparatively
</DESCRIPTION>
<CLAIMS>
A method of forming a composite image I
c
 from N source images I
n

where n = 1 to N and N is greater than one, said method comprising the steps of:


(a) decomposing each source image I
n
 into a plurality L of sets of oriented
component patterns P
n
 (m,l) using a plurality of oriented functions, where m is the
number of patterns in each of L sets for the nth source image and, l = 1 to L and

indicates the orientation of said oriented patterns;
(b) computing a saliency measure S
n
(m,l) for each oriented component pattern
P
n
(m,l);
(c) computing, from the oriented component pattern sets P
n
(m,l) and said
saliency measures S
n
(m,l) for each of said oriented component patterns, a set of
oriented component patterns P
c
(m,l) of the composite image I
c
; and
(d) constructing the composite image I
c
 from the set of computed oriented
component patterns P
c
(m,l).
The method of claim 1 further comprising the step of aligning said
source images I
n
 prior to step (a).
The method of claim 1 or 2, wherein the step (a) of decomposing each
source image l
n
 into a plurality L of sets of oriented component patterns P
n
(m,l)
comprises applying oriented functions to a source image I
n
 at each picture element of
each source image I
n
. 
The method of claim 3, wherein the said oriented functions are gradient
functions.
The method of claim 1, 2, 3 or 4, wherein the step (c) of computing the
set of oriented component patterns P
c
(m,l) of the composite image Ic comprises
selecting the oriented component patterns P
n
(m,l) having the greatest saliency for each
value of m and l.
The method of claim 5, wherein the step (c) of computing the set of
oriented component patterns P
c
(m,l) of the composite image Ic comprises selecting the
oriented component pattern P
n
(m,l) having the greatest absolute magnitude.
The method of claim 1, 2, 3 or 4, wherein the step (c) of computing the
set of oriented component patterns P
c
(m,l) of the composite image Ic comprises
computing a linear combination dependent on the saliency measures of the amplitudes

of the oriented component patterns of the source images I
n
.
The method of claim 7, wherein the linear combination of the
amplitudes of the oriented component patterns for each source image I
n
 is a weighted
average of the amplitudes of the oriented component patterns of the source images I
n
,
the weights being dependent on the saliency measures.
The method of any preceding claim, further comprising the step of
computing a match measure M
n1, n2
 (m,l) for each pair of oriented component pattern
sets P
n1
(m,l), P
n2
(m,l) corresponding to source images I
n1
 and I
n2
 to be matched and 
wherein the said step (c) of forming the set of oriented component patterns P
c
(m,l) uses
the match measures M
n1, n2
 (m,l) and the saliency measures S
n
(m,l) to form the said set
of oriented component patterns P
c
(m,l) from which the composite image I
c
 is
constructed.
The method of claim 1, wherein:

step (a) comprises decomposing each source image (I
n
) into a hierarchy of a
plurality K of images I
n
(k) of respective different resolutions where k=1 to K and then
decomposing each of the images I
n(k)
 into a plurality L of sets of oriented component
patterns P
n
(m,k,l);
step (b) comprises computing a saliency measure S
n
(m,k,l) for each oriented
component pattern P
n
(m,k,l);
step (c) comprises computing, from the oriented component pattern sets
P
n
(m,k,l) and the saliency measures S
n
(m,k,l), a set of oriented component patterns
P
c
(m,k,l) of the composite image I
c
; and
step (d) comprises constructing the composite image I
c
 from the set of oriented
component patterns P
c
(m,k,l).
The method of claim 10, wherein the step (a) of decomposing each
image I
n(k)
 into a plurality L of sets of oriented component patterns P
n
(m,k,l) comprises
applying oriented functions to a feature of each picture element of each source image

I
n
.
The method of claim 11, wherein said oriented functions are gradient
functions. 
The method of claim 10, 11 or 12, wherein the step (c) of computing the
set of oriented component patterns from the source image pattern sets P
n
(m,k,l) for
each value of m, k and l comprises selecting the oriented component pattern having the

greatest saliency.
The method of claim 13, wherein the step (c) of computing the set of
oriented component patterns from the oriented component pattern sets P
n
(m,k,l) for
each value of m, k and l comprises selecting the oriented component pattern having the

amplitude with the greatest absolute magnitude.
The method of claim 10, 11 or 12, wherein the step (c) of computing the
set of oriented component patterns from the oriented component pattern sets P
n
(m,k,l)
for each value of m, k and l comprises computing a linear combination dependent on

the saliency measures of the amplitudes of the oriented component patterns of the
source image I
n
.
The method of claim 15, wherein the linear combination of amplitudes
of the oriented component patterns for each source image I
n
 is a weighted average of
the amplitudes of the oriented component patterns of the source images I
n
, the weights
being dependent on the saliency measures.
The method of claim 4 or 12, wherein the gradient is the first derivative
of the intensity of the source image I
n
 at each picture element in first and second
orthogonal directions in each source image I
n
. 
The method of claim 17, wherein the gradient is also the first derivative
of the intensity of the source image I
n
 in third and fourth directions, in each source
image I
n
, which are orthogonal to one another and at a forty five degree angle to the
first direction.
The method of claim 8 or 16, wherein the weight assigned to a
particular oriented component pattern in each of the source images I
n
 is the weighted
root mean square of the amplitudes of the particular oriented component pattern and

other oriented component pattern within a local neighbourhood.
The method of claim 8 or 16, wherein the weight assigned to a
particular oriented component pattern in each of the source images I
n
 depends upon the
normalised saliency of the particular oriented component pattern.
The method of claim 8 or 16, wherein the weighted average of the
amplitudes of the oriented component patterns is the weighted root mean square of the

amplitudes of the particular oriented component pattern and other oriented component
patterns within a local neighbourhood.
The method of claim 1, wherein the step of decomposing each source
im
age I
n
 comprises forming two or more sets of wavelets oriented in different
directions in each source image I
n
. 
The method of claim 22 comprising first and second sets of wavelets in
first and second orthogonal directions.
The method of claim 23, wherein the step of (c) of computing oriented
component patterns P
c
(m,l) for each value of m and l comprises selecting the oriented
component pattern P
n
(m,l) having the greatest saliency.
The method of claim 1, wherein the said step (c) of computing oriented
component patterns P
c
(m,l) of the composite image I
c
 from the source image pattern sets
P
n
(m,l) for each value of m and l comprises computing a weighted average of the
amplitudes of the oriented component patterns of the source images wherein the weights

are dependent on the saliency measures; and the said step (d) constructs the composite
image I
c
 therefrom; and further comprising the steps of:

assigning amplitudes of a first of opponent colours to first component patterns in
accordance with their normalised weight contribution to said weighted average of the

amplitudes of the component patterns of the source images; and
assigning amplitudes of a second of said opponent colours to second component
patterns in accordance with their normalised weight contributions to said weighted

average of the amplitudes of the component patterns of the source images; and
augmenting said composite image I
c
 with said first and second opponent colours.
The method of claim 25, wherein said composite image is an NTSC video
image in which the Y luminance channel thereof is defined by said weighted average of

the amplitudes of the oriented component patterns of the source images I
n
, the I
chrominance channel is defined by the amplitudes of said first of said opponent colours,

and the Q chrominance channel is defined by the amplitudes of said second of said
opponent colours. 
Apparatus for forming a composite image I
c
 from a plurality of N source
images I
n
, where n = 1 to N and N is greater than one, the apparatus comprising:

means for decomposing each source image I
n
 into a plurality of L of sets of
oriented component patterns P
n
(m,l), using a plurality of oriental functions where m is
the number of patterns in each of the l sets for the nth source image; and l = 1 to L and

indicates the orientation of said oriented patterns;
means for computing a saliency measure S
n
(m,l) for each oriented component
pattern P
n
(m,l) connected to the decomposing means;
means for computing from the oriented component pattern sets P
n
(m,l) and the
said saliency measures S
n
(m,l) for each of said oriented component patterns, a set of
oriented component patterns P
c
(m,l) of the composite image I
c
; and
means for constructing the composite image I
c
 from the set of computed oriented
component patterns P
c
(m,l).
The apparatus of claim 27, wherein: the decomposing means decomposes
each source image I
n
 into a hierarchy of a plurality K of images I
n
(k) of respective
different resolutions where k=1 to K and then decomposes each of the images I
n
(k) into a
plurality L of sets of oriented component patterns P
n
(m,k,l);

   the saliency computing means computes a saliency measure S
n
(m,k,l) for each
oriented component pattern P
n
(m,k,l);

   the pattern set computing means forms a set of oriented component patterns
Pc(m,k,l) from the oriented component pattern sets Pn(m,k,l) and the saliency measures

Sn(m,k,l); and

   the constructing means constructs the composite image from the set of oriented
component patterns P
c
(m,k,l). 
The apparatus of claim 27 or 28, wherein the means for decomposing
each source image I
n
 comprises a means for performing a plurality of different gradient
operations on each of the source images I
n
.
The apparatus of claim 29, wherein the means for constructing the
composite image I
c
 performs the same gradient operations on each set of oriented
component patterns as were performed by the decomposing means.
The apparatus of claim 27, wherein the means for computing a saliency
measure S
n
(m,l) of a component pattern (P
n
(m,l) computes a weighted function of the
amplitude D
n
(m,l) of the component pattern.
The apparatus of claim 29, wherein the means for computing a saliency
measure S
n
(m,l) for each component pattern P
n
(m,l) comprises means for calculating a
weighted root mean square of the amplitude D
n
(m,l) of each oriented component pattern.
The apparatus of claim 31 or 32, wherein the pattern set computing means
computes the amplitude D
c
(m,l) of a combined oriented component pattern (P
c
(m,l) as a
weighted average of the pattern for each orientation, wherein the weights are dependent

on the saliency measures (S
n
(m,l).
Apparatus according to claim 27, for forming a composite image I
c
 from
at least first and second monochrome source images I
n1
 and I
n2
, wherein the means for
computing a set of oriented component patterns P
c
(m,l) of the composite image I
c
 
computes a weighted average of the amplitudes of the oriented component patterns of the

source images wherein the weights are dependent on the saliency measures, and

   the constructing means forms a composite image therefrom and further
comprising

   first means for assigning amplitudes of a first of opponent colours to first
component patterns in accordance with their normalised weight contribution to said

weighted average of the amplitudes of the component patterns of the source images; and

   second means for assigning amplitudes of a second of said opponent colours to
second component patterns in accordance with their normalised weight contributions to

said weighted average of the amplitudes of the component patterns of the source images;
and

   augmenting said composite image I
c
 with said first and second opponent colours.
The apparatus of claim 34, wherein said colour composite image is an
NTSC video image in which said augmenting means derives the Y luminance channel

thereof from the monochrome composite image, the I chrominance channel from the
output of said first means, and the Q chrominance channel from the output of the second

means.
The apparatus of claim 34 or 35, wherein:

said first means includes a means responsive to the normalised weights of a first
selected group of said given different resolution component patterns of a said source

images for deriving a first weighting image for said first of said opponent colours; and
said second means includes a means responsive to the normalised weights of a
second selected group of said source images for deriving a second weighting image for

said second of said opponent colours.
</CLAIMS>
</TEXT>
</DOC>
