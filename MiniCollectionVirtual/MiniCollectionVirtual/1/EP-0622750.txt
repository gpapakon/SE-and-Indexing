<DOC>
<DOCNO>EP-0622750</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Pattern recognition
</INVENTION-TITLE>
<CLASSIFICATIONS>G06T760	G06K962	G06K962	G06T120	G06K964	G06K966	G06K936	G06K936	G06T760	G06T140	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06T	G06K	G06K	G06T	G06K	G06K	G06K	G06K	G06T	G06T	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06T7	G06K9	G06K9	G06T1	G06K9	G06K9	G06K9	G06K9	G06T7	G06T1	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
Pattern recognition, for instance optical character recognition, is achieved by 
training a neural network, scanning an image, segmenting the image to detect a pattern, 

preprocessing the detected pattern, and applying the preprocessed detected pattern to the 
trained neural network. The preprocessing includes determining a centroid of the 

pattern and centrally positioning the centroid in a frame containing the pattern. The 
training of the neural network includes randomly displacing template patterns within 

frames before applying the template patterns to the neural network. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
CANON KK
</APPLICANT-NAME>
<APPLICANT-NAME>
CANON KABUSHIKI KAISHA
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
AVI-ITZHAK HADAR I
</INVENTOR-NAME>
<INVENTOR-NAME>
GARLAND HARRY T
</INVENTOR-NAME>
<INVENTOR-NAME>
THAN A DIEP
</INVENTOR-NAME>
<INVENTOR-NAME>
AVI-ITZHAK,HADAR I.
</INVENTOR-NAME>
<INVENTOR-NAME>
GARLAND,HARRY T.
</INVENTOR-NAME>
<INVENTOR-NAME>
THAN A DIEP
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates generally to image processing and specifically to
recognition of patterns, such as optical characters, by applying detected patterns to a
neural network trained to recognize such patterns as corresponding to one of a set of
pattern templates.Numerous schemes have been proposed for pattern recognition in the past. A
great deal of research and development has occurred, particularly in the area of optical
character recognition (OCR). See, for example, S.N. Srihari, V. Govindaraju, J.J.
Hull, R.K. Fenrich and S. Lam, "Pattern Recognition, Character Recognition and
Optical Character Readers", Technical Report CEDAR-TR-91-1, Center for Document
Analysis and Recognition, State University of New York at Buffalo, Buffalo, N.Y.,
May 1991.Known schemes for OCR vary widely in their approaches. Some early attempts
superimposed bit maps of detected images over templates of known characters. Such
schemes were extremely sensitive to such factors as font differences, skewing,
enlargement, and reduction. Other approaches concentrated on extracting particular
features from detected characters. Results varied depending on the particular selection
and processing of features.U.S. Patent No. 3,846,752 to Nakano et al. discloses character recognition
apparatus using the density distribution of a character. The frequency spectrum of the
density distribution is compared to that of density distributions corresponding to known
characters, and the known character with the Fourier transform spectrum pattern most
similar to that of the detected character is output as the recognized character.U.S. Patent No. 4,817,176 to Marshall et al. discloses another pattern
recognition scheme using Fourier transformation, with various corrections for
amplitude and phase differences. U.S. Patent No. 3,930,231 to Henrichon, Jr., et al. discloses use of a multiple
cell grid for detection of pattern density and feature recognition. A vector signal is
generated for a detected character based on the presence or absence of each recognizable
feature, and this vector is compared with vectors representing known characters.U.S. Patent No. 3,993,976 to Ginsburg discloses pattern analysis using a
transform to obtain spatial frequencies. The spatial frequencies are filtered to extract
pattern information for determining general form, edge, texture, and depth information
of the detected pattern.U.S. Patent No. 4,513,441 to Henshaw discloses comparison of two images by
forming a composite overlay of the images and examining phase
</DESCRIPTION>
<CLAIMS>
A method of recognizing a pattern in an image as
corresponding to one of a set of predetermined template

patterns comprising the steps of:

inputting (601) image data including the pattern to
be recognized;
detecting (602) said pattern by segmenting the data
to obtain a detected pattern;
preprocessing (604 to 610) the detected pattern to
produce a preprocessed detected pattern;
applying (611) the preprocessed detected pattern as
input to a neural network (108) trained for recognizing

said predetermined template patterns; and
recognizing said preprocessed detected pattern by
operation of said neural network to output an output

signal representative of one of said predetermined
template patterns to which the detected pattern

corresponds;

   characterised in that said detected pattern is
represented by a map of pixels each having a multi-bit

pixel value and in that the step of preprocessing
comprises the substeps of:


(a) determining (604) complements of each of said
pixel values;
(b) selecting (605) as a noise value a minimum of
said complements;
(c) subtracting (606) from each of said complements 
said noise value; and
(d) selectively replacing (607) said complements
with a baseline value in response to said complements not

exceeding a predetermined threshold value.
A method as claimed in claim 1, wherein the step of
preprocessing further comprises filtering pixel values

by selectively assigning a predetermined filtered pixel
value to a subset of said pixels responsive to said

values of said pixels in said subset not exceeding a
threshold value.
A method as claimed in any preceding claim, wherein
the step of segmenting includes defining (608) a frame

around said detected pattern and wherein the step of
preprocessing further comprises:


(a) determining (609) a centroid of said detected
pattern; and
(b) positioning (610) said detected pattern within
said frame such that said centroid is centrally located

with respect to said frame.
A method as claimed in any preceding claim wherein
said inputting step comprises scanning an image using an

optical scanner (102).
A method as claimed in any preceding claim 
comprising a step of training said neural network, said

training step comprising the substeps of:

   inputting (502) image data comprising at plurality
of template images representative of said predetermined

template patterns and, for each template image
corresponding to a respective one of the template

patterns,

(a) defining (507) a frame around said template
image;
(b) determining (508) a centroid of said template
image;
(c) positioning (509) said one template image
within said frame such that said centroid is centrally

located with respect to said frame;
(d) randomly displacing (510), subsequent to
substep (c), said one template image within said frame;

and
(e) applying (512) said randomly displaced template
image to said neural network.
Apparatus (100) for recognizing a pattern in an
image as corresponding to one of a set of predetermined

template patterns, the apparatus comprising:

input means (102) operable to input image data
including the pattern to be recognized;
detecting means (104) operable to detect said
pattern by segmenting the data to obtain a detected 

pattern;
preprocessing means (106) operable to preprocess the
detected pattern to produce a preprocessed detected

pattern; and
a neural network (108) trained for recognizing said
predetermined template patterns and operable to recognize

said preprocessed detected pattern by outputting an
output signal representative of one of said predetermined

template patterns to which the detected pattern
corresponds;

   characterised in that the detected pattern is
represented by a map of pixels each having a multi-bit

pixel value and in that preprocessing means comprises:

(a) determining means (604) operable to determine
complements of each of said pixel values;
(b) selecting means (605) operable to select as a
noise value a minimum of said complements;
(c) subtracting means (606) operable to subtract
from each of said complements said noise value; and
(d) replacing means (607) operable to selectively
replace said complements with a baseline value in

response to said complements not exceeding a
predetermined threshold value.
Apparatus as claimed in claim 6, wherein the
preprocessing means further comprises filtering means

(204) operable to filter pixel values by selectively 
assigning a predetermined filtered pixel value to a

subset of said pixels responsive to said values of said
pixels in said subset not exceeding a threshold value.
Apparatus as claimed in any of claims 6 and 7,
wherein the segmenting means includes defining means

(608) operable to define a frame around said detected
pattern and wherein the preprocessing means further

comprises:

(a) determining means (206) operable to determine
a centroid of said detected pattern; and
(b) positioning means (206) operable to position
said detected pattern within said frame such that said

centroid is centrally located with respect to said frame.
Apparatus as claimed in any of claims 6 to 8 wherein
said inputting means comprises an optical scanner (102).
Apparatus as claimed in any of claims 6 to 9,
wherein said neural network comprises:


a first layer (261 to 280) of neurons adapted to
accept as input said preprocessed pattern signal and to

produce therefrom a set of intermediate signals;
a second layer (301 to 394) of neurons adapted to
accept as input said intermediate signals and to produce

therefrom a set of template merits; and
comparator means (395) for determining a maximum of 
said template merits and producing said output signal in

response thereto.
Apparatus as claimed in claim 10, wherein said
preprocessed pattern signal comprises 3000 of said

multibit values; wherein said first layer of neurons
comprises 20 neurons; and wherein said second layer of

neurons comprises 94 neurons.
Apparatus as claimed in claim 10, wherein said
second layer of neurons (301-394) comprises the same

number of neurons as the number of said known template
patterns.
Apparatus as claimed in any of claims 6 to 12,
wherein said preprocessing means (106) comprises

eliminating means (202,204) operable to eliminate noise
from said image signal.
Apparatus as claimed in claim 8 comprising dithering
means (208) operable during training of the neural

network to randomly displace the position of a template
image within said frame.
</CLAIMS>
</TEXT>
</DOC>
