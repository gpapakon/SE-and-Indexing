<DOC>
<DOCNO>EP-0619911</DOCNO> 
<TEXT>
<INVENTION-TITLE>
CHILDREN'S SPEECH TRAINING AID
</INVENTION-TITLE>
<CLASSIFICATIONS>G10L1500	G10L1500	G09B1904	G10L1502	G10L1526	G09B1904	G10L1514	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G10L	G10L	G09B	G10L	G10L	G09B	G10L	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G10L15	G10L15	G09B19	G10L15	G10L15	G09B19	G10L15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A children's speech training aid compares a child's speech with models of speech, stored as sub-word acoustic models, and a general speech model to give an indication of whether or not the child has spoken correctly. An indication of how well the word has been pronounced may also be given. An adult operator enters the word to be tested into the training aid which then forms a model of that word from the stored sub-word speech models. The stored acoustic models are formed by first recording a plurality of words by a plurality of children from a given list of single words. These recordings are then processed off-line to give a basic acoustic model of an acceptable or correct sound for each phoneme in the context of the pre- and proceeding phonemes. The acoustic models are Hidden Markov Models. The limits of acceptable prononciation applied to different words and children may be adjusted by variable penalty values applied in association with the general speech acoustic model. The training aid generates accumulated word costs for each child's utterance and uses these costs to indicate correctness of pronunciation.
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
SECR DEFENCE BRIT
</APPLICANT-NAME>
<APPLICANT-NAME>
SECRETARY OF STATE FOR DEFENCE IN HER BRITANNIC MAJESTY'S GOV. OF THE UNITED KINGDOM OF GREAT BRITAIN AND NORTHERN IRELAND
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
RUSSELL MARTIN JAMES
</INVENTOR-NAME>
<INVENTOR-NAME>
SERIES ROBERT WILLIAM
</INVENTOR-NAME>
<INVENTOR-NAME>
WALLACE JULIE LYNNE
</INVENTOR-NAME>
<INVENTOR-NAME>
RUSSELL, MARTIN JAMES
</INVENTOR-NAME>
<INVENTOR-NAME>
SERIES, ROBERT WILLIAM
</INVENTOR-NAME>
<INVENTOR-NAME>
WALLACE, JULIE LYNNE
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
This invention concerns a childrens speech training aid. Such an aid is 
useful in comparing a child's pronunciation with a desired value to give 
an indication of correct pronunciation. This indication may then be 
used by an operator, eg a teacher or therapist etc, to identify children 
in need of speech therapy or by a child to change pronunciation until 
acceptable. There are a number of speech recognisers of differing complexity and 
accuracy, see for example EP-A-0 360 909 which discloses an apparatus according to the preamble of claim 1. Most identify a single word out of a stored set of words, and 
if that word is identified, activate a further step, eg operate a 
switch. Many speech recognisers require extensive training by the 
operator and operate with a few set words. When asked to speak a single 
word many children make additional sounds such as uumm or er, and vary 
the time taken to speak. Additionally, in a classroom environment there 
are various non speech background noises, and possibly a teachers voice 
reading out words for a non reader. This makes speech recognition more 
difficult, because the non speech sounds themselves have to be 
recognised and dismissed as superfluous. Many available speech 
recognisers will give a match even when only part of a desired word is 
spoken. Thus for example the word "county" might be recognised as 
"cow", "count", or "tea", or correctly as "county".  
 Each word in a spoken language can be broken down into a set of about 40 
phonemes, ie 40 different sounds, that can be use alone or combined 
together to pronounce each word. Some phonemes are context insensitive, 
others are context sensitive, ie they sound different according to the 
pre- and proceeding phonemes combinations. The convention adopted to 
describe these phonemes is described for example by J Wells et al, in a 
book chapter Specification of SAM phonetic alphabet (SAMPA), included 
in: P Winski, W J Barry &A Fourien (Ed), Support available from SAM 
project for other ESPRIT speech and language work, The SAM Project, Dept 
of Phonetics, University College, London. The present invention is concerned with the correctness of a complete 
spoken word against a desired standard in the midst of non speech or 
noise sounds. According to the present invention a child's speech training aid 
compares a child's speech with that speech as generated by stored 
acoustic models and general non speech sounds to give an indication of 
whether or not the child has spoken correctly. According to this
</DESCRIPTION>
<CLAIMS>
A speech training aid comprising; a store (Fig 1) for storing a set of reference 
words; a microphone (Fig 12) for receiving a word spoken by a trainee; and means 

(Figs 1,4) for comparing the spoken word with the set of reference words and 
indicating (Figs 2,10) whether or not the spoken word is recognised as one in the set of 

reference words;
 
CHARACTERISED BY: 


an acoustic model store (Fig 6) for storing acoustic models of speech sounds 
representing the processed results of speech by numerous persons; 
a dictionary (Fig 5) for storing a list of words together with information to construct 
acoustic models of these words from the acoustic model store (Fig 6); 
a network generator (Fig 7) for generating an acoustic model of a required word 
together with an acoustic model of general speech sounds; 
input means (Figs 8, 9, 10) for requesting the generation of an acoustic model of the 
required word; 
means for processing (Figs 13, 14) the trainee's utterances into a form suitable for 
comparison with acoustic models of speech; a speech pattern matcher (Fig 14) for 

comparing the processed trainees utterances with the acoustic models of the required 
word and general speech; and 
means for indicating (Figs 2, 10) whether or not the trainee's utterances are the 
required word. 
The training aid of claim 1 wherein the acoustic models of speech sounds 
include acoustic models of phonemes.  

 
The training aid of claim 1 wherein the acoustic models of speech sounds 
include acoustic models of context sensitive phonemes. 
The training aid of claim 1 wherein the acoustic models are Hidden Markov 
Models. (Figs 4, 5, 6, 7) 
The training aid of claim 1 wherein the trainee's utterances are sampled 
(Figs 16, 2) and processed (Figs 3a, 3b) into an N-plurality of channels to provide an 

N-dimensional feature vector in successive time slot periods forming a sequence of 
feature vectors. 
The training aid of claim 5 wherein the speech pattern matcher (Figs 4, 1) 
computes the relative probabilities of the sequence of feature vectors being the same as 

either the acoustic word model or the acoustic general speech model (Fig 4). 
The training aid of claim 1 wherein the speech pattern matcher (Figs 4, 1) 
operates continually and the required word is recognised within continual speech. 
The training aid of claim 1 wherein the network generator (Fig 7) generates 
acoustic models of a plurality of words (Figs 7, 17) and the speech pattern matcher 

(Figs 4 1) operates to recognise the required plurality of words within continual 
speech. 
The training aid of claim 1 wherein the means for indicating includes means 
for indicating the accuracy of pronunciation of that required word. 
The training aid of claim 1 wherein the speech pattern matcher (Fig 4) 
computes the accumulated cost difference between the beginning and end of a 

recognised trainee spoken word (Figs 8, 9, 10). 
The training aid of claim 10 wherein the accumulated cost difference is used to 
give an indication of the accuracy of a trainee spoken word. (Figs 10, 11, 13).  

 
The training aid of claim 1 and further including a variable penalty control 
(Figs 4, 14) arranged to cooperate with the acoustic model of general speech in 

forming an adjustable standard for the indication of accuracy of a spoken word. 
The training aid of claim 12 wherein the value of penalty (Figs 4,10) is 
changed in accordance with set values associated with different required words. 
The training aid of claim 13 wherein the set penalty values may be varied by 
an operator to suit individual trainees. 
The speech training aid of claim 1 wherein the input means includes a 
keyboard (Fig 9) for entering required words into the training aid for each testing 

session. 
The speech training aid of claim 1 including means (Figs 2, 10) for prompting 
a trainee to speak the required word. 
The speech training aid of claim 16 wherein the means for prompting includes 
a speech synthesiser and loudspeaker (Fig 2). 
The speech training aid of claim 16 wherein the means for prompting includes 
a video monitor (Fig 10) with screen for display of messages. 
The speech training aid of claim 1 including means for recording (Figs 1, 10) 
the results of a session of a trainee's speech, indicating words requested, words 

spoken correctly, and how correctly spoken. 
The speech training aid of claim 1 wherein the acoustic word model (Fig 14) is 
a series of sub-word models and general speech models, and the speech pattem 

matcher (Fig 4) gives an indication of the correctness of utterance of the required 
word.  

 
The speech training aid of claim 1 wherein the acoustic word model (Fig 4) 
includes an additional acoustic model prior (Fig 15) to the acoustic word model so 

that stuttering in a trainee's utterances may be separately processed. 
</CLAIMS>
</TEXT>
</DOC>
