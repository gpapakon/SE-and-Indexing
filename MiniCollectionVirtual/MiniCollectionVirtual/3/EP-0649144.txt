<DOC>
<DOCNO>EP-0649144</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Automatic indexing of audio using speech recognition
</INVENTION-TITLE>
<CLASSIFICATIONS>G10L1500	G11B27022	G11B27028	G03B3100	H04N591	G10L1526	G11B2728	G06F1730	G10L1522	G11B2710	G11B2728	G06F1730	G03B3100	G11B2710	G10L1500	G10L1518	H04N591	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G10L	G11B	G11B	G03B	H04N	G10L	G11B	G06F	G10L	G11B	G11B	G06F	G03B	G11B	G10L	G10L	H04N	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G10L15	G11B27	G11B27	G03B31	H04N5	G10L15	G11B27	G06F17	G10L15	G11B27	G11B27	G06F17	G03B31	G11B27	G10L15	G10L15	H04N5	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A method of automatically aligning a written transcript 
with speech in video and audio clips. The disclosed 

technique involves as a basic component an automatic 
speech recognizer. The automatic speech recognizer 

decodes speech (recorded on a tape) and produces a file 
with a decoded text. This decoded text is then matched 

with the original written transcript via identification 
of similar words or clusters of words. The results of 

this matching is an alignment of the speech with the 
original transcript. The method can be used (a) to 

create indexing of video clips, (b) for "teleprompting" 
(i.e. showing the next portion of text when someone is 

reading from a television screen), or (c) to enhance 
editing of a text that was dictated to a stenographer or 

recorded on a tape for its subsequent textual reproduction 
by a typist. 


</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
IBM
</APPLICANT-NAME>
<APPLICANT-NAME>
INTERNATIONAL BUSINESS MACHINES
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
ELLOZY HAMED A
</INVENTOR-NAME>
<INVENTOR-NAME>
KANEVSKY DIMITRI
</INVENTOR-NAME>
<INVENTOR-NAME>
KIM MICHELLE Y
</INVENTOR-NAME>
<INVENTOR-NAME>
NAHAMOO DAVID
</INVENTOR-NAME>
<INVENTOR-NAME>
PICHENY MICHAEL A
</INVENTOR-NAME>
<INVENTOR-NAME>
ZADROZNY WLODEK W
</INVENTOR-NAME>
<INVENTOR-NAME>
ELLOZY, HAMED A.
</INVENTOR-NAME>
<INVENTOR-NAME>
KANEVSKY, DIMITRI
</INVENTOR-NAME>
<INVENTOR-NAME>
KIM, MICHELLE Y.
</INVENTOR-NAME>
<INVENTOR-NAME>
NAHAMOO, DAVID
</INVENTOR-NAME>
<INVENTOR-NAME>
PICHENY, MICHAEL A.
</INVENTOR-NAME>
<INVENTOR-NAME>
ZADROZNY, WLODEK W.
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
This invention relates generally to a system for indexing
of audio or audio-video recordings and textual data, for
example aligning texts that are stored in computer files
with corresponding data that are stored on audio-video media,
such as audio tape, video tape, or video disk. The typical
problem in this area can be formulated as follows.Consider an audio-video recording and its written transcript.
To index the video, it is necessary to know when
words appearing on the transcript were spoken. To find an
appropriate part of the recording, we need a text-speech
index containing data pairs for each word in the transcript.
Each data pair consists of a word in the transcript
and the f-number describing the position of the word
on the tape. Each data pair can be represented as (word,
f-number).We will use the term "word" to refer both to single words
such as "dog", "step", or "house", and to phrases such as
"United States of America", "production of wheat", etc.Indexing an audio-video recording by text enhances one's
ability to search for a segment of the audio recording. It
is often faster to manually or automatically search for a
segment of text than it is to search for a segment of audio
recording. When the desired text segment is found, the
corresponding audio recording can be played back.Indexing an audio recording by text also enhances one's
ability to edit the audio recording. By moving or deleting
words in the text, the corresponding audio segments can be
moved or deleted. If there is maintained a vocabulary of 
stored words and stored audio segments corresponding to the
words, then when words are inserted in the text, the corresponding
audio segments can be inserted in the audio
recording.Two example applications where it is necessary to align
speech with a corresponding written transcript are (1) providing
subtitles for movies, and (2) fast retrieval of
audio-video data recorded at trial from a stenographic
transcript by an appellate court or a deliberating jury.A conventional approach to align recorded speech with its
written transcript is to play back the audio data, and manually
select the corresponding textual segment. This
process is time consuming and expensive.Other work deals with relationships (or synchronization) of
speech with other data (e.g. facial movements) that are
time aligned. For example U.S. Patent No. 5,136,655
(Bronson) discloses the indexing of different data (words
and animated pictures). There, the files with aligned
words and pictures were obtained by a simultaneous
</DESCRIPTION>
<CLAIMS>
An apparatus for indexing an audio recording
comprising:


an acoustic recorder (70) for storing an ordered series of
acoustic information signal units representing sounds

generated from spoken words, said acoustic recorder
having a plurality of recording locations, each

recording location storing at least one acoustic information
signal unit ;
a speech recognizer (72) for generating an ordered series of
recognized words having a high conditional probability

of occurrence given the occurrence of the sounds represented
by the acoustic information signals, each recognized

word corresponding to at least one acoustic
information signal unit, each recognized word having a

context of at least one preceding or following recognized
word;
a text storage device (74) for storing an ordered series of
index words, said ordered series of index words comprising

a visual representation of at least some of the
spoken words represented by the acoustic information

signal units, each index word having a context of at
least one preceding or following index word; and
means (76) for comparing the ordered series of recognized
words with the ordered series of index words to pair

recognized words and index words which are the same word
and which have matching contexts, and for tagging each

paired index word with the recording location of the
acoustic information signal unit corresponding to the

recognized word paired with the index word.
An apparatus as claimed in Claim 1,

characterized in that the speech recognizer aligns each
recognized word with at least one acoustic information

signal unit.
An apparatus as claimed in Claim 1 or 2,

characterized in that:

each recognized word which is not paired with an index
word has a nearest preceding paired recognized word in

the ordered series of recognized words, and has a
nearest following paired recognized word in the ordered

series of recognized words;
the context of a target recognized word comprises the
number of other recognized words preceding the target

recognized word and following the nearest preceding
paired recognized word in the ordered series of recognized

words;
the context of a target index word comprises the number
of other index words preceding the target index word and

following the nearest preceding paired index word in in
the ordered series of index words; and
the context of a recognized word matches the context of
an index word if the context of the recognized word is

within a selected threshold value of the context of the
index word.
A method of indexing an audio recording comprising:

storing an ordered series of acoustic information signal
units representing sounds generated from spoken words,

said acoustic recorder having a plurality of recording
locations, each recording location storing at least one

acoustic information signal unit; 
generating an ordered series of recognized words having
a high conditional probability of occurrence given the

occurrence of the sounds represented by the acoustic
information signals, each recognized word corresponding

to at least one acoustic information signal unit, each
recognized word having a context of at least one preceding

or following recognized word;
storing an ordered series of index words, said ordered
series of index words comprising a visual representation

of at least some of the spoken words represented by the
acoustic information signal units, each index word

having a context of at least one preceding or following
index word;
comparing the ordered series of recognized words with
the ordered series of index words to pair recognized

words and index words which are the same word and which
have matching contexts; and
tagging each paired index word with the recording
location of the acoustic information signal unit corresponding

to the recognized word paired with the index
word.
A method as claimed in
claim 4, characterized in that:


each recognized word comprises a series of one or more
characters;
each index word comprises a series of one or more characters;
and
a recognized word is the same as an index word when both
words comprise the same series of characters.
A method as claimed in any one of the
preceding claims, characterized in that:


the context of a target recognized word comprises the
number of other recognized words preceding the target

recognized word in the ordered series of recognized
words;
the context of a target index word comprises the number
of other index words preceding the target index word in

the ordered series of index words; and
the context of a recognized word matches the context of
an index word if the context of the recognized word is

within a selected threshold value of the context of the
index word.
A method as claimed in any one of the
preceding claims, characterized in that:


each index word which is not paired with a recognized
word has a nearest preceding paired index word in the

ordered series of index words, and has a nearest following
paired index word in the ordered series of index

words; and
the step of tagging comprises tagging a non-paired index
word with a recording location between the recording

location of the nearest preceding paired index word and
the recording location of the nearest following paired

index word.
A method as claimed in any one of the
preceding claims, further comprising the step of

aligning each recognized word with at least one acoustic
information signal unit. 
A method as claimed in any of the
preceding claims, characterized in that:


each recognized word which is not paired with an index
word has a nearest preceding paired recognized word in

the ordered series of recognized words, and has a
nearest following paired recognized word in the ordered

series of recognized words;
the context of a target recognized word comprises the
number of other recognized words preceding the target

recognized word and following the nearest preceding
paired recognized word in the ordered series of recognized

words;
the context of a target index word comprises the number
of other index words preceding the target index word and

following the nearest preceding paired index word in in
the ordered series of index words; and
the context of a recognized word matches the context of
an index word if the context of the recognized word is

within a selected threshold value of the context of the
index word.
</CLAIMS>
</TEXT>
</DOC>
