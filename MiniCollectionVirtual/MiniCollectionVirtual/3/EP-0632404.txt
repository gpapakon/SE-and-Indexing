<DOC>
<DOCNO>EP-0632404</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Pattern recognition by generating and using zonal features and anti-features
</INVENTION-TITLE>
<CLASSIFICATIONS>G06K962	G06K968	G06T700	G06K968	G06K964	G06K964	G06K962	G06T700	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06K	G06K	G06T	G06K	G06K	G06K	G06K	G06T	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06K9	G06K9	G06T7	G06K9	G06K9	G06K9	G06K9	G06T7	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A system for pattern recognition and a system for generating 
feature masks being used in the pattern recognition process is 

described which utilizes beside pieces covering a master and 
sample pattern also pieces not covering the area of the master 

and sample pattern. Thus, there are formed zonal features and 
anti-features having positive and negative feature factor 

values as well as incorporating different weighting factors. 
This system allows a fully automatic feature generation 

technique and allows training of new character classes in a 
very short time. For each meaning class the different shaped 

classes are generated by statistical means and the weighted 
zonal positive features are derived. Besides this in parallel 

there are weighted anti-features trained which increase the 
accuracy of classification substantially. The system of the 

present invention implements a classifier of high accuracy for 
recognition of for example characters with low print quality 

according to banking requirements. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
IBM
</APPLICANT-NAME>
<APPLICANT-NAME>
INTERNATIONAL BUSINESS MACHINES CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
MAIER UDO
</INVENTOR-NAME>
<INVENTOR-NAME>
RUPPERT WERNER
</INVENTOR-NAME>
<INVENTOR-NAME>
MAIER, UDO
</INVENTOR-NAME>
<INVENTOR-NAME>
RUPPERT. WERNER
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention pertains to a system for pattern 
recognition and a system for generating feature masks being 
used in the pattern recognition process. The recognition of pattern, for example in the form of printed 
or written text by optical means is existing as long as 
digital image processing exists. Generally speaking, pattern 
recognition means the classification of a given unknown 
pattern, for example a text pattern, consisting of characters 
and numbers, into one of a number of standard classes, i. e. 
characters in the ASCII code table. This recognition process is usually done in different steps as 
explained in the following in general terms: 
The image of a document is scanned, for example in vertical 
scans when it passes under a read-head. As read-head e.g. a 
charged coupled device (CCD) array can be used. 
The raw image is captured at a resolution of, for example 
240 PELS/inch (picture element/per inch). Each PEL in the raw 
image might be an eight bit quantization of the intensity of 
the picture element measured by the CCD array. 
In a next step a thresholding process is applied to the PELS 
of the raw image. This thresholding process might be a dynamic 
one or a fixed thresholding value can be used. In the 
thresholding process the intensity of each PEL is clipped to 
either black or white for generating a binary black/white 
image. 
The generated black/white video image is input to a 
segmentation or framing process in the next step. In the 
segmentation process characters inside a trackband are 
identified and the characters or generally speaking the 
patterns are registered into a frame.  
 The next performed step is called feature extraction. The 
feature extraction process uses information about the 
character font or generally speaking information about the 
different forms and shapes of the specific set of patterns. 
These features are Boolean expressions of characters or 
pattern fragments. In the document readers IBM 3890/XP, 3891/XP and 3892/XP which 
are widely used and known for character recognition especially 
in the banking area, all features are designed manually to 
allow high discrimination capability between the character 
classes of the used font. For example, there are necessary 96 
features to do recognition of the OCR A font. For the also 
well known OCR B font there are 102 features necessary. It is an extreme disadvantage of this manual mode that 
additional fonts require a new feature design development 
cycle, training runs and fine tuning of the
</DESCRIPTION>
<CLAIMS>
A method for pattern recognition, comprising the step of:
 
comparing a pattern (S1, S2, S3) with feature 

masks (f3, f8, f-), each of said feature masks (f3, f8, 
f-) representing a specific character ("3", "8", "-"),
 
characterized in that 


each of said feature masks (f3, f8, f-) comprises zonal 
features (42, 43), representing the character itself, and anti-features (41, 44, 45), representing its background, and 
information about more than one character, namely 
information about all characters ("3", "8", "-") in the set of characters to be recognised, is 

utilized for the generation of said zonal features (42, 43) and anti-features 
(41, 44, 45) of each of said feature masks (f3, f8, f-). 
The method for pattern recognition according to claim 1, 
wherein
 
said feature masks (f3, f8, f-) are generated comprising 

the steps of: 

a) adding up, on a pixel basis, m
i
 patterns, with i = 1, 
2, ..., n, for each of the n character classes 

obtained from normalized binary pattern images of 
a representative training character set including 

bad, normal and good samples of said character, 

resulting in a sum pattern mask for each of said 
n characters with values between 0 and m
i
 for each 
pixel, representing a respective character i,  

 
said sum pattern mask being subjected to a 
thresholding process using a value C to 

generate a black/white binary pattern 
representation, 

whereby C is between 0 and m
i
, setting all pixel 
values 
>
 C to 1, else to 0, resulting for each 
i of said n characters in an ideal character 

mask K
i
 (i = 1, 2, ..., n), 
b) calculating for each i of said n characters one 
feature mask f
i
 (i = 1, 2, ..., n) by 


multiplying, on a pixel basis, said ideal 
character mask K
i
 (i = 1, 2, ..., n) by (n + 1), 
and 
subtracting, on a pixel basis, the sum of all 
n existing ideal character masks 

K
i
 (i = 1, 2, ..., n) (K3, K8, K-), 
said calculation following the formula: 

The method for pattern recognition according to claim 2, 
wherein
 
said generation of feature masks (f3, f8, f-) is 

performed automatically, particularly is performed 
concurrently with normal pattern recognition operation. 
The method for pattern recognition according to claim 2 
or 3, further comprising the step of: 


calculating a normalization factor R
i
 (i = 1, 2, ..., n) 
for each i of said n characters,  

 
said normalization factor R
i
 (R3, R8, R-) being the 
sum of all pixel values of a matrix, 
said matrix being the result of a multiplication, on 
a pixel basis, of f
i
 x K
i
 with v columns and u rows, 
said calculation following the formula: 

The method for pattern recognition according to claim 4, 
further comprising the step of: 


multiplying, on a pixel basis, each sample pattern image 
matrix S
k
 (S1, S2, 53) with all feature masks f
i
 (f3, f8, 
f-) divided by said corresponding normalization factor 

R
i
 (R3, R8, R-), 
resulting in a determination value D
i
 (i = 1, 2, ..., n) 
for each i of said n characters corresponding to said 

sample pattern image matrix S
k
 (S1, S2, S3), wherein 

said sample pattern image matrix S
k
 (S1, S2, S3) 
is normalized after scanning in equal manner as 

said binary pattern images of said representative 
training character set during training and 

generating phase, and 
k is a sample sequence number, 
said multiplication following the formula: 

D
i
=
S
k
×
f
i
R
i
. 
The method for pattern recognition according to claim 5, 
wherein
 
said determination value D
i
 (D3, D8, D-) has an absolute 
maximum value of "1", said absolute maximum value "1" 

being associated to a perfect sample pattern, whereas 
normally said determination value D
i
 being lower than "1" 
or even negative. 
The method for pattern recognition according to claim 5 
or 6, wherein
 
deciding which character is closest to said sample 

pattern image matrix S
k
 (S1, S2, S3) is made dependent on 
said value of D
i
 (D3, D8, D-), whereby 

character i, corresponding to feature mask f
i
 having 
a relative maximum value D
i,(max, rel)
 within i = 1, 2, 
..., n, is taken as the most likely character, 
i. e., S
k
 (S1, S2, S3) is recognized as 
character i ("3", "8", "-"), respectively if: 


i → S
k
 if D
i
 = S
k
 x f
i
/R
i
 
   has a relative maximum D
i,(max, rel)
 
within i = 1, 2, ..., n. 
The method for pattern recognition according to any one 
of the preceding claims, wherein 


said patterns are characters and/or numbers and 
said patterns are part of a font and said font is 
preferably a standarized font and/or an image pattern as 

logos, pictograms and textures. 
The method for pattern recognition according to any one 
of the preceding claims, wherein
 
said patterns are normalized capital handprint characters 

and/or numbers. 
A system for pattern recognition, comprising:
 
means for comparing a pattern (S1, S2, S3) with 

feature masks (f3, f8, f-), each of said feature 
masks (f3, f8, f-) representing a specific 

character ("3", "8", "-"),
 
characterized in that 


each of said feature masks (f3, f8, f-) comprises zonal 
features (42, 43), representing the character itself, and anti-features (41, 44, 45), representing its background, and 
said system for pattern recognition further comprises 
means for generating said zonal features (42, 43) and 

anti-features (41, 44, 45) of said feature masks (f3, f8, 
f-), which utilize information about more than one 

character, namely information about all 
characters ("3", "8", "-") in the set of characters to be recognised, 

for the generation of each of said feature masks (f3, f8, f-). 
The system for pattern recognition according to claim 10, 
wherein
 
said means for generating said feature masks (f3, f8, f-) 

comprise: 

a) means for adding up, on a pixel basis, m
i
 patterns, 
with i = 1, 2, ..., n, for each of the n character 

classes obtained from normalized binary pattern 
images of a representative training character set 

including bad, normal and good samples of said 
character,
  
 

resulting in a sum pattern mask for each of said 
n characters with values between 0 and m
i
 for each 
pixel, representing a respective character i,
 
   said sum pattern mask being subjected to a 

thresholding process using a value C to 
generate a black/white binary pattern 

representation, 
whereby C is between 0 and m
i
, setting all pixel 
values 
>
 C to 1, else to 0, resulting for each 
i of said n characters in an ideal character 

mask K
i
 (i = 1, 2, ..., n), 
b) means for calculating for each i of said 
n characters one feature mask f
i
 (i = 1, 2, ..., n), 
including: 


means for multiplying, on a pixel basis, said 
ideal character mask K
i
 (i = 1, 2, ..., n) by 
(n + 1), and 
means for subtracting, on a pixel basis, the 
sum of all n existing ideal character masks 

K
i
 (i = 1, 2, ..., n) (K3, K8, K-), 
said calculation following the formula: 

The system for pattern recognition according to claim 11, 
wherein
 
said generation of feature masks (f3, f8, f-) is 

performed automatically, particularly is performed 
concurrently with normal pattern recognition operation.  

 
The system for pattern recognition according to claim 11 
or 12, further comprising:
 
means for calculating a normalization factor R
i
 (i = 1, 2, 
...,
 n) for each i of said n characters, 

said normalization factor R
i
 (R3, R8, R-) being the 
sum of all pixel values of a matrix, 
said matrix being the result of a multiplication, on 
a pixel basis, of f
i
 x K
i
 with v columns and u rows, 
said calculation following the formula: 

The system for pattern recognition according to claim 13, 
further comprising: 


means for multiplying, on a pixel basis, each sample 
pattern image matrix S
k
 (S1, 52, S3) with all feature 
masks f
i
 (f3, f8, f-) divided by said corresponding 
normalization factor R
i
 (R3, R8, R-), 
resulting in a determination value D
i
 (i = 1, 2, ..., n) 
for each i of said n characters corresponding to said 

sample pattern image matrix S
k
 (S1, S2, S3), wherein 

said sample pattern image matrix S
k
 (S1, S2, S3) 
is normalized after scanning in equal manner as 

said binary pattern images of said representative 
training character set during training and 

generating phase, and 
k is a sample sequence number,  
 
said multiplication following the formula: 

D
i
=
S
k
×
f
i
R
i
. 
The system for pattern recognition according to claim 14, 
wherein
 
said determination value D
i
 (D3, D8, D-) has an absolute 
maximum value of "1", said absolute maximum value "1" 

being associated to a perfect sample pattern, whereas 
normally said determination value D
i
 being lower than "1" 
or even negative. 
The system for pattern recognition according to claim 14 
or 15, having
 
means for deciding which character is closest to said 

sample pattern image matrix S
k
 (S1, S2, S3), said decision 
being made dependent on said value of D
i
 (D3, D8, D-), 
whereby 


character i, corresponding to feature mask f
i
 having 
a relative maximum value D
i,(max, rel)
 within i = 1, 2, 
..., n, is taken as the most likelihood character, 
i. e., S
k
 (S1, S2, S3) is recognized as 
character i ("3", "8", "-"), respectively if: 


i → S
k
 if D
i
 = S
k
 x f
i
/R
i
 
   has a relative maximum D
i,(max, rel)
 
within i = 1, 2, ..., n, 
The system for pattern recognition according to any one 
of claims 10 to 16, wherein 


said patterns are characters and/or numbers and  
 
said patterns are part of a font and said font is 
preferably a standardized font and/or an image pattern as 

logos, pictograms and textures. 
The system for pattern recognition according to any one 
of claims 10 to 17, wherein
 
said patterns are normalized capital handprint characters 

and/or numbers. 
The system for pattern recognition according to any one 
of claims 10 to 18, wherein
 
a neural network is used for generating ideal character 

masks K
i
 (K3, K8, K-) as well as for calculating said 
feature masks f
i
 (f3, f8, f-). 
</CLAIMS>
</TEXT>
</DOC>
