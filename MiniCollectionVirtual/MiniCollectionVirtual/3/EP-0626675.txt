<DOC>
<DOCNO>EP-0626675</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Excitation synchronous time encoding vocoder and method.
</INVENTION-TITLE>
<CLASSIFICATIONS>G10L1100	G10L1104	G10L1106	G10L1900	G10L1900	G10L1904	G10L1906	G10L1908	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G10L	G10L	G10L	G10L	G10L	G10L	G10L	G10L	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G10L11	G10L11	G10L11	G10L19	G10L19	G10L19	G10L19	G10L19	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A method for excitation synchronous time encoding of 
speech signals. The method includes steps of providing an input 

speech signal (11), processing (12, 14, 17, 19, 22) the input 
speech signal (11) to characterize qualities including linear 

predictive coding (LPC) coefficients, epoch length and voicing and 
characterizing (24') the input speech signals (11) on a single 

epoch time domain basis when the input speech signals (11) 
comprise voiced speech to provide a parameterized voiced 

excitation function (39). The method further includes steps of 
characterizing (24) the input speech signals (11) for at least a 

portion of a frame when the input speech signals (11) comprise 
unvoiced speech to provide a parameterized unvoiced excitation 

function (25) and encoding (41) a composite excitation function 
including the parameterized unvoiced excitation function (25) 

and the parameterized voiced excitation function (39) to provide 
a digital output signal (42) representing the input speech signal 

(11). 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
MOTOROLA INC
</APPLICANT-NAME>
<APPLICANT-NAME>
MOTOROLA INC.
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BERGSTROM CHAD SCOTT
</INVENTOR-NAME>
<INVENTOR-NAME>
FETTE BRUCE ALAN
</INVENTOR-NAME>
<INVENTOR-NAME>
YOU SEAN SUNGSOO
</INVENTOR-NAME>
<INVENTOR-NAME>
BERGSTROM, CHAD SCOTT
</INVENTOR-NAME>
<INVENTOR-NAME>
FETTE, BRUCE ALAN
</INVENTOR-NAME>
<INVENTOR-NAME>
YOU, SEAN SUNGSOO
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
This application is related to co-pending E.P.O. Patent Application 
Serial No. 92306479.4, filed on July 15 of 1992 and Serial No. 
          , entitled "Pitch Epoch Synchronous Linear 
Predictive Coding Vocoder And Method", filed on an even date 
herewith, which are assigned to the same assignee as the present 
application. This invention relates in general to the field of digitally 
encoded human speech, in particular to coding and decoding 
techniques and more particularly to high fidelity techniques for 
digitally encoding speech, for transmitting digitally encoded high 
fidelity speech signals with reduced bandwidth requirements 
and for synthesizing high fidelity speech signals from digital 
codes. Digital encoding of speech signals and/or decoding of 
digital signals to provide intelligible speech signals are important 
for many electronic products providing secure communications 
capabilities, communications via digital links or speech output 
signals derived from computer instructions. Many digital voice systems suffer from poor perceptual 
quality in the synthesized speech. Insufficient characterization 
of input speech basis elements, bandwidth limitations and 
subsequent reconstruction of synthesized speech signals from 
encoded digital representations all contribute to perceptual 
degradation of synthesized speech quality. Moreover, some 
information carrying capacity is lost; the nuances, intonations  
 
and emphases imparted by the speaker carry subtle but 
significant messages lost in varying degrees through corruption 
in en- and subsequent de-coding of speech signals transmitted in 
digital form. In particular, auto-regressive linear predictive coding 
(LPC) techniques comprise a system transfer function having all 
poles and no zeroes. These prior art coding techniques and 
especially those utilizing linear predictive coding analysis tend to 
neglect all resonance contributions from the nasal cavities (which 
essentially provide the "zeroes" in the transfer function 
describing the human speech apparatus) and result in 
reproduced speech having an artificially "tinny" or "nasal" 
quality. Standard techniques for digitally encoding and decoding 
speech generally utilize signal processing analysis techniques 
having substantial computational complexity. Further, digital 
signals resultant therefrom require significant bandwidth in 
realizing high quality real-time communication. What are needed are apparatus and methods for rapidly 
and accurately characterizing speech signals in a
</DESCRIPTION>
<CLAIMS>
A method for excitation synchronous time encoding 
of speech signals, said method comprising steps of: 

   providing an input speech signal (11); 
   processing (12, 14, 17, 19, 22) the input speech signal (11) 

to characterize qualities including linear predictive coding 
coefficients, epoch length and voicing; and, when input speech 

(11) comprises voiced speech: 
   characterizing (24') the input speech (11) on a single-epoch 

basis to provide single-epoch speech parameters; 
and 

   encoding (41) the single-epoch speech parameters to 
provide digital signals representing voiced speech. 
A method as claimed in claim 1, wherein 
characterizing (24') the input speech (11) on a single-epoch basis 

further comprises steps of: 
   determining (27) epoch excitation positions within, and a 

frame of excitation data from, a frame of speech data; 
   performing (29) excitation synchronous linear predictive 

coding (LPC) to provide synchronous LPC coefficients, the 
synchronous LPC coefficients corresponding to the epoch 

excitation positions from said determining step (27); and 
   selecting (31) an interpolation excitation target from within 

the frame of excitation data based on minimum envelope error 
to provide a target excitation function, wherein the target 

excitation function comprises single-epoch speech parameters 
including the synchronous LPC coefficients. 
A method as claimed in claim 1, including, when 
input speech (11) comprises unvoiced speech, steps of: 

   dividing (24) unvoiced speech into a series of contiguous 
regions;

 
   determining (24) root-mean-square (RMS) amplitudes for 

each of the contiguous regions; and 
   encoding (41) the RMS amplitudes to provide digital signals 

representing unvoiced speech. 
A method for excitation synchronous time decoding 
of digital signals to provide speech signals, said method 

comprising steps of: 
   providing an input digital signal (44) representing speech; 

   determining (46) when the input digital signal (44) 
represents voiced speech, and, when the input digital signal (44) 

represents voiced speech, performing steps of: 
   interpolating (57) linear predictive coding 

parameters; 
   reconstructing (59) a voiced excitation function; and 

   synthesizing (62) speech from the reconstructed 
voiced excitation function by providing the reconstructed 

voiced excitation function to a lattice synthesis filter. 
An apparatus for excitation synchronous time 
encoding of speech signals, said apparatus comprising: 

   a frame synchronous linear predictive coding (LPC) device 
(15) having an input (11) and an output, said input (11) for 

accepting input speech signals, said output for providing a first 
group of LPC coefficients describing a first portion of said input 

speech signal and an excitation waveform describing a second 
portion of said input speech signal; 

   an autocorrelator (15) coupled to said frame synchronous 
LPC device (15), said autocorrelator (15) for estimating an epoch 

length of said excitation waveform; 
   a pitch filter (15) having an input coupled to said 

autocorrelator (15) and having an output signal comprising a 
multiplicity of coefficients describing characteristics of said 

excitation waveform; 
   frame voicing decision means (15) coupled to an output of 

said pitch filter (15), an output of said correlator (15) and said 
output of said frame synchronous LPC device (15), said frame 

 
voicing decision means (15) for determining whether a frame is 

voiced or unvoiced; 
   means (15) for computing representative excitation levels 

in a series of contiguous time slots coupled to said frame voicing 
decision means (15) and operating when said frame voicing 

decision means (15) determines that said series of contiguous 
time slots is unvoiced; and 

   encoding means (15) coupled to said means (15) for 
computing representative excitation levels, said encoding means 

(15) for providing an encoded digital signal corresponding to said 
excitation waveform. 
An apparatus for excitation synchronous time 
decoding of digital signals to provide speech signals, said 

apparatus comprising: 
   an input (44) for receiving digital signals representing 

encoded speech; 
   encoding means (45) coupled to said input (44), said 

encoding means (45) for providing quantized signals from said 
digital signals; 

   frame voicing decision means (45) coupled to said encoding 
means (45), said frame voicing decision means (45) for 

determining when said quantized signals represent voiced 
speech and when said quantized signals represent unvoiced 

speech; 
   means (45) for interpolating between contiguous signal 

levels representative of unvoiced excitation coupled to said 
frame voicing decision means (45); 

   a random noise generator (45) coupled to said interpolating 
means (45), said random noise generator (45) for providing noise 

signals modulated to a level determined by said interpolating 
means (45); and 

   lattice synthesis filter means (45) coupled to said random 
noise generator (45) for synthesizing unvoiced speech from said 

modulated noise signals. 
A communications apparatus including:
 

   an input (78) for receiving input speech signals; 
   a speech digitizer (15) coupled to said input (78) for 

digitally encoding said input speech signals; 
   an output (79) for transmitting said digitally encoded input 

speech signals, said output (79) coupled to said speech digitizer 
(15); 

   a digital input (83) for receiving digitally encoded speech 
signals; 

   speech synthesizer means (45) coupled to said digital input 
(83) for synthesizing speech signals from said digitally encoded 

speech signals, wherein said speech synthesizer means (45) 
further comprises: 

   frame voicing decision means (45) coupled to vector 
quantizer codebooks (45), said frame voicing decision 

means (45) for determining when quantized signals from 
said vector quantizer codebooks (45) represent voiced 

speech and when said quantized signals represent 
unvoiced speech; 

   means (45) for interpolating between contiguous 
signal levels representative of unvoiced excitation coupled 

to said frame voicing decision means (45); and 
   a random noise generator (45) coupled to said 

interpolating means (45), said random noise generator (45) 
for providing noise signals modulated to a level 

determined by said interpolating means (45); and 
   output means (84) coupled to said random noise generator 

(45) for synthesizing unvoiced speech from said modulated noise 
signals. 
A method for excitation synchronous time encoding 
of speech signals, said method comprising steps of: 

   providing an input signal (11); 
   processing (12, 14, 17, 19, 22) the input speech signal (11) 

to characterize qualities including linear predictive coding 
coefficients, epoch length and voicing; 

   characterizing (24') the input speech signals (11) on a 
single epoch time domain basis when the input speech signals 

 
(11) comprise voiced speech to provide a parameterized 

excitation function (39); 
   determining (27) epoch excitation positions within a frame 

of excitation when the input speech signals (11) comprise voiced 
speech; 

   determining (27) epoch lengths for each epoch within the 
frame of parameterized excitation function; 

   averaging (27') the epoch lengths to provide fractional 
pitch; and 

   encoding (41) the parameterized excitation function and 
the fractional pitch to provide a dig
ital output signal (42) 
representing the input speech signal (11). 
A method for excitation synchronous time encoding 
of speech signals, said method comprising steps of: 

   providing an input speech signal (11); 
   processing (12, 14, 17, 19, 22) the input speech signal (11) 

to characterize qualities including linear predictive coding (LPC) 
coefficients, epoch length and voicing; 

   characterizing (24') the input speech signals (11) on a 
single epoch time domain basis when the input speech signals 

(11) comprise voiced speech to provide a parameterized voiced 
excitation function (39); 

   characterizing (24) the input speech signals (11) for at 
least a portion of a frame when the input speech signals (11) 

comprise unvoiced speech to provide a parameterized unvoiced 
excitation function (25); and 

   encoding (41) a composite excitation function including the 
parameterized unvoiced excitation function (25) and the 

parameterized voiced excitation function (39) to provide a digital 
output signal (42) representing the input speech signal (11). 
A method for digitally encoding speech signals 
characterized on a single epoch basis, including steps of 

determining (27') and digitally encoding (41) fractional pitch. 
</CLAIMS>
</TEXT>
</DOC>
