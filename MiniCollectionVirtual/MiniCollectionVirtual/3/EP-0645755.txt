<DOC>
<DOCNO>EP-0645755</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Speech coding apparatus and method using classification rules
</INVENTION-TITLE>
<CLASSIFICATIONS>H04B1404	G10L1502	H04B1404	H03M730	G10L1902	G10L1900	G10L1900	G10L1500	H03M730	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>H04B	G10L	H04B	H03M	G10L	G10L	G10L	G10L	H03M	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>H04B14	G10L15	H04B14	H03M7	G10L19	G10L19	G10L19	G10L15	H03M7	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A speech coding apparatus and method uses classification rules to 
code an utterance while consuming fewer computing resources. The 

value of at least one feature of an utterance is measured during 
each of a series of successive time intervals to produce a series 

of feature vector signals representing the feature values. 
Classification rules map each feature vector signal from a set of 

all possible feature vector signals to exactly one of at least two 
different classes of prototype vector signals. Each class 

contains a plurality of prototype vector signals. According to 
the classification rules, a first feature vector signal is mapped 

to a first class of prototype vector signals. The closeness of 
the feature value of the first feature vector signal is compared 

to the parameter values of only the prototype vector signals in 
th
e first class of prototype vector signals to obtain prototype 
match scores for the first feature vector signal and each 

prototype vector signal in the first class. At least the 
identification value of at least the prototype vector signal 

having the best prototype match score is output as a coded 
utterance representation signal of the first feature vector 

signal. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
IBM
</APPLICANT-NAME>
<APPLICANT-NAME>
INTERNATIONAL BUSINESS MACHINES
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
EPSTEIN MARK EDWARD
</INVENTOR-NAME>
<INVENTOR-NAME>
GOPALAKRISHNAN PONANI S
</INVENTOR-NAME>
<INVENTOR-NAME>
NAHAMOO DAVID
</INVENTOR-NAME>
<INVENTOR-NAME>
PICHENY MICHAEL ALAN
</INVENTOR-NAME>
<INVENTOR-NAME>
SEDIVY JAN
</INVENTOR-NAME>
<INVENTOR-NAME>
EPSTEIN, MARK EDWARD
</INVENTOR-NAME>
<INVENTOR-NAME>
GOPALAKRISHNAN, PONANI S.
</INVENTOR-NAME>
<INVENTOR-NAME>
NAHAMOO, DAVID
</INVENTOR-NAME>
<INVENTOR-NAME>
PICHENY, MICHAEL ALAN
</INVENTOR-NAME>
<INVENTOR-NAME>
SEDIVY, JAN
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The invention relates to speech coding, such as for computerized
speech recognition systems.In computerized speech recognition systems, an acoustic processor
measures the value of at least one feature of an utterance during
each of a series of successive time intervals to produce a series
of feature vector signals representing the feature values. For
example, each feature may be the amplitude of the utterance in
each of twenty different frequency bands during each of series of
10-millisecond time intervals. A twenty-dimension acoustic
feature vector represents the feature values of the utterance for
each time interval.In discrete parameter speech recognition systems, a vector
quantizer replaces each continuous parameter feature vector with
a discrete label from a finite set of labels. Each label
identifies one or more prototype vectors having one or more
parameter values. The vector quantizer compares the feature
values of each feature vector to the parameter values of each
prototype vector to determine the best matched prototype vector 
for each feature vector. The feature vector is then replaced with
the label identifying the best-matched prototype vector.For example, for prototype vectors representing points in an
acoustic space, each feature vector may be labeled with the
identity of the prototype vector having the smallest Euclidean
distance to the feature vector. For prototype vectors
representing Gaussian distributions in an acoustic space, each
feature vector may be labeled with the identity of the prototype
vector having the highest likelihood of yielding the feature
vector.For large numbers of prototype vectors (for example, a few
thousand), comparing each feature vector to each prototype vector
consumes significant processing resources by requiring many
time-consuming computations. It has been proposed to conduct the search for the best-matched
prototype vector along a binary tree, the lowest-level plane of
which contains the prototype vectors. If the successive planes of
the tree are numbered from 1 to L, only 2xL comparisons are
required, that is to say two comparisons in each plane, instead of
2L comparisons in the case of a full search with the same number of
prototype vectors. While such a system is relatively low cost, its
performance in identifying the best-matched prototype vector is
often unacceptably poor. On the basis of the same concept of a
search along a binary tree, EP-A-0138061 proposes the improvement
consisting in starting the search along the tree in a plane lower
than the
</DESCRIPTION>
<CLAIMS>
A speech coding apparatus comprising:

means (10) for measuring the value of at least one feature of
an utterance during each of a series of successive time intervals

to produce a series of feature vector signals representing the
feature values;
means (12) for storing a plurality of prototype vector
signals, each prototype vector signal having at least one

parameter value and having an identification value, at least two
prototype vector signals having different identification values;

characterised in that it further comprises:
classification rules means (14) for storing classification
rules mapping each feature vector signal from a set of all

possible feature vector signals to exactly one of at least two
different classes (C0 - C7) of prototype vector signals, each

class containing a plurality of prototype vector signals;
classifier means (16) for mapping, by the classification
rules, a first feature vector signal to a first class of prototype

vector signals;
means (18) for comparing the closeness of the feature value
of the first feature vector signal to the parameter values of only

the prototype vector signals in the first class of prototype
vector signals to obtain prototype match scores for the first

feature vector signal and each prototype vector signal in the
first class; and 
means (20) for outputting at least the identification value
of at least the prototype vector signal having the best prototype

match score as a coded utterance representation signal of the
first feature vector signal.
A speech coding apparatus as claimed in claim 1, characterised
in that each class (C0 - C7) of prototype vector signals is at

least partially different from other classes of prototype vector
signals and at least some of the prototype vector signals are

contained in more than one class of prototype vector signals.
A speech coding apparatus as claimed in claim 1 or claim 2,

characterised in that each class i of prototype vector signals
contains less than 1/N
i
 times the total number of prototype vector
signals in all classes, where 5≤ N
i
 ≤ 150.
A speech coding apparatus as claimed in any one of claims 1 to
3, characterised in that the average number of prototype vector

signals in a class of prototype vector signals is approximately
equal to 1/10 times the total number of prototype vector signals

in all classes.
A speech coding apparatus as claimed in any one of claims 1 to
4, characterised in that:


the classification rules comprise at least first and second
sets of classification rules;
the first set of classification rules map each feature vector
signal from a set of all possible feature vector signals to 

exactly one of at least two disjoint subsets (22, 24) of feature vector
signals; and
the second set of classification rules map each feature
vector signal in a subset of feature vector signals to exactly one

of at least two different classes of prototype vector signals.
A speech coding apparatus as claimed in Claim 5, characterized
in that the classifier means (16) maps, by the first set of

classification rules, the first feature vector signal to a first
subset (22, 24) of feature vector signals.
A speech coding apparatus as claimed in Claim 6, characterized
in that the classifier means (16) maps, by the second set of

classification rules, the first feature vector signal from the
first subset (22, 24) of feature vector signals to the first class of

prototype vector signals.
A speech coding apparatus as claimed in Claim 6, characterized
in that:


the second set of classification rules comprises at least
third and fourth sets of classification rules;
the third set of classification rules map each feature vector
signal from a subset (22, 24) of feature vector signals to exactly one of

at least two disjoint sub-subsets (26, 28; 30, 32) of feature vector signals; and 
the fourth set of classification rules map each feature
vector signal in a sub-subset of feature vector signals to exactly

one of at least two different classes of prototype vector signals.
A speech coding apparatus as claimed in Claim 8, characterized
in that the classifier means (16) maps, by the third set of

classification rules, the first feature vector signal from the
first subset of feature vector signals to a first sub-subset of

feature vector signals.
A speech coding apparatus as claimed in Claim 9, characterized
in that the classifier means (16) maps, by the fourth set of

classification rules, the first feature vector signal from the
first sub-subset of feature vector signals to the first class of

prototype vector signals.
A speech coding apparatus as claimed in Claim 10,
characterized in that the classification rules comprise:


at least one scalar function mapping the feature values of a
feature vector signal to a scalar value; and
at least one rule mapping feature vector signals whose scalar
function is less than a threshold to the first subset of feature

vector signals, and mapping feature vector signals whose scalar
function is greater than the threshold to a second subset of

feature vector signals different from the first subset.
A speech coding apparatus as claimed in Claim 11,
characterized in that:


the measuring means (10) measures the values of at least two
features of an utterance during each of a series of successive

time intervals to produce a series of feature vector signals
representing the feature values; and
the scalar function of a feature vector signal comprises the
value of only a single feature of the feature vector signal.
A speech coding apparatus as claimed in Claim 12,
characterized in that the measuring means (10) comprises a microphone (34).
A speech coding apparatus as claimed in Claim 13,
characterized in that the measuring means (10) comprises a spectrum

analyzer (40) for measuring the amplitudes of the utterance in two or
more frequency bands during each of a series of successive time

intervals.
A speech coding method comprising the steps of:

measuring (10) the value of at least one feature of an utterance
during each of a series of successive time intervals to produce a

series of feature vector signals representing the feature values;
storing (12) a plurality of prototype vector signals, each
prototype vector signal having at least one parameter vector and

having an identification value, at least two prototype vector
signals having different identification values;
 
characterised in that it further comprises the steps of:
storing (14) classification rules mapping each feature
vector from a set of all possible feature vector to exactly one

of at least two different classes (C0 - C7) of prototype vector
signals, each class containing a plurality of prototype vector

signals ;
mapping (16), by the classification rules, a first feature
vector signal to a first class of prototype vector signals ;
comparing (18) the closeness of the feature vector of the
first feature vector signal to the parameter vectors of only the

prototype vector signals in the first class of prototype vector
signals to obtain prototype match scores for the first feature

vector signal and each prototype vector signal in the first
class ; and
outputting (20) at least the identification value of at
least the prototype vector signal having the best prototype

match score as a coded utterance representation signal of the
first feature vector signal.
A speech coding method as claimed in claim 15,
characterised in that each class (C0 - C7) of prototype vector

signals is at least partially different from other classes of
prototype vector signals and at least some prototype vector

signals are contained in more than one class of prototype vector
signals.
A speech coding method according to claim 15 or claim 16,
characterised in that each class i of prototype vector signals

contains less than 1/N
i
 times the total number of prototype
vector signals in all classes, where 5 ≤ N
i
 ≤ 150. 
A speech coding method as claimed in Claim 17, characterized
in that the average number of prototype vector signals in a class

of prototype vector signals is approximately equal to  1 / 10
 times

the total number of prototype vector signals in all classes.
A speech coding method as claimed in Claim 17, characterized
in that:


the classification rules comprise at least first and second
sets of classification rules;
the first set of classification rules map each feature vector
signal from a set of all possible feature vector signals to

exactly one of at least two disjoint subsets (22, 24) of feature vector
signals; and
the second set of classification rules map each feature
vector signal in a subset of feature vector signals to exactly one

of at least two different classes of prototype vector signals.
A speech coding method as claimed in Claim 19, characterized
in that the step of mapping (16) comprises mapping, by the first set

of classification rules, the first feature vector signal to a
first subset of feature vector signals.
A speech coding method as claimed in Claim 20, characterized
in that the step of mapping (16) comprises mapping, by by the second

set of classification rules, the first feature vector signal from 
the first subset of feature vector signals to the first class of

prototype vector signals.
A speech coding method as claimed in Claim 20, characterized
in that:


the second set of classification rules comprises at least
third and fourth sets of classification rules;
the third set of classification rules map each feature vector
signal from a subset (22, 24) of feature vector signals to exactly one of

at least two disjoint sub-subsets (26, 28; 30, 32) of feature vector signals; and
the fourth set of classification rules map each feature
vector signal in a sub-subset of feature vector signals to exactly

one of at least two different classes of prototype vector signals.
A speech coding method as claimed in Claim 22, characterized
in that the step of mapping (16) comprises mapping by the third set of

classification rules, the first feature vector signal from the
first subset of feature vector signals to a first sub-subset of

feature vectors signals.
A speech coding method as claimed in Claim 23, characterized
in that the step of mapping (16) comprises mapping, by the fourth set of

classification rules, the first feature vector signal from the
first sub-subset of feature vector signals to the first class of

prototype vector signals. 
A speech coding method as claimed in Claim 24, characterized
in that the classification rules comprise:


at least one scalar function mapping the feature values of a
feature vector signal to a scalar value; and
at least one rule mapping feature vector signals whose scalar
function is less than a threshold to the first subset of feature

vector signals, and mapping feature vector signals whose scalar
function is greater than the threshold to a second subset of

feature vector signals different from the first subset.
A speech coding method as claimed in Claim 25, characterized
in that:


the step of measuring (10) comprises measuring the values of at
least two features of an utterance during each of a series of

successive time intervals to produce a series of feature vector
signals representing the feature values; and
the scalar function of a feature vector signal comprises the
value of only a single feature of the feature vector signal.
A speech coding method as claimed in Claim 26, characterized
in that the step of measuring (10) comprises measuring the amplitudes

of the utterance in two or more frequency bands during each of a
series of successive time intervals.
</CLAIMS>
</TEXT>
</DOC>
