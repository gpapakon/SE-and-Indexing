<DOC>
<DOCNO>EP-0632370</DOCNO> 
<TEXT>
<INVENTION-TITLE>
A hardware arrangement of expanding data processing time in the pipeline stages of a microcomputer system and a method thereof
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F938	G06F948	G06F946	G06F938	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	G06F	G06F	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F9	G06F9	G06F9	G06F9	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A pipelined data processing arrangement, which has a 
plurality of stages coupled in series, is disclosed. A 

fist stage successively issues a plurality of 
instructions. The first stage includes a register which 

is able to terminate operation thereof while holding 
information. A second stage is coupled to the first 

stage and decodes the instructions successively applied 
thereto from the first stage. The second stage includes 

a register which is able to terminate operation thereof 
while holding information immediately before the 

termination. A third stage coupled to the second stage 
and processes data under the control of the instruction 

applied thereto from the second stage. The third stage 
includes latching means which is not able to hold 

information over two time slots. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
NIPPON ELECTRIC CO
</APPLICANT-NAME>
<APPLICANT-NAME>
NEC CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
SUZUKI KAZUMASA
</INVENTOR-NAME>
<INVENTOR-NAME>
SUZUKI, KAZUMASA
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates generally to
improvements in pipelining in a microcomputer system and
more specifically to a pipelined arrangement and a method
of increasing a data processing time in certain
stages of pipelining which is provided with instruction
interrupt functions.Pipelining is a hardware technique for achieving
higher performance by breaking a complex, time-consuming
function into a series of simpler, shorter operations,
each of which can then be executed in an assembly-line
fashion with simultaneous computations on different sets
of data.A time duration for data processing in each stage of
a pipelined data processing system, is limited by delay
induced by a pipeline register in each stage. The
pipeline register is configured such as to temporarily
store an instruction and/or data in response to an
interrupt request which is issued in the case of a
resource or data competition or conflict.Before turning to the present invention it is deemed
preferable to briefly discuss a known pipelined
arrangement with reference to Figs. 1-6.Fig. 1 is a block diagram of a pipelined data
processing system which includes five stages 1-5
in this particular case and to which the present invention
is applicable. However, it
should be noted that the present invention is in no way
limited to such an arrangement.Throughout the instant disclosure, hardware
arrangements which are deemed irrelevant to the present 
invention will be omitted merely for the sake of brevity.As shown in Fig. 1, the stage 1 includes a selector
10, a pipeline register 12, an instruction memory 14, and
an adder 16. The stage 1 is to successively read out
instructions previously stored in the instruction memory
14. The selector 10 is supplied with three inputs 18a-18c
and selects one among them under the control of
selector control signals RESET and INT. The control
sinal RESET is to initially reset the selector 10, while
the other control signal INT is applied to the selector 10 from
an instruction decoder 20 of the stage 2 if an
instruction interrupt occurs as will be discussed below.Prior to initiating the operation of the pipelined
arrangement of Fig. 1, an instruction set is retrieved
from a main memory by way of an instruction bus (neither
shown) and is then stored in the memory 14. In the case
where an instruction interrupt does not occur, the
selector 10 selects the input 18b (viz., output of the
adder 16). A loop consisting of the blocks 10, 12 and 16
exhibits an address counter.The stage 2 is provided to decode the
</DESCRIPTION>
<CLAIMS>
A pipelined data processing arrangement having a plurality of stages (1-5)
which are coupled in series and each of which includes temporary storage means,

comprising:

a first stage (1) for successively issuing a plurality of instructions in synchronism
with time slots, said first stage (1) including first storage means (10, 12, 14) which comprises selectors (10(1)-10(n)) and flip-flops (12(1)-12(n)) and

which, in response to occurrence of an interrupt request, retains therein an
instruction applied thereto over one or more time slots which follow a time slot

wherein said interrupt request has been issued;
a second stage (2) coupled to decode each of said instructions applied thereto
from said first stage (1), said second stage (2) issuing said interrupt request if a

pipelined operation should be interrupted, said second stage (2) including second
storage means (22, 24, 26) which comprises selectors (22(1)-22(n) and flip-flops (24(1)-24(n) and which, in response to said interrupt request, retains

therein a decoded instruction over one or more time slots which follow said time
slot wherein said interrupt request has been issued;
characterized by

   a plurality of data processing stages (3-5) which follow said second stage (2),
each of said data processing stages (3-5) including a first dynamic latch (72, 76, 80) for

holding a data processing instruction applied from a stage preceded thereby only
during a time slot for which said data processing instruction is applied thereto.
A pipelined data processing arrangement as claimed in claim 1, wherein
each of said data processing stages (3-5) further includes a second dynamic latch
 (70, 74, 78)
for holding data applied from a stage preceded thereby only during a time slot for

which said data is applied thereto. 
A pipelined data processing arrangement as claimed in claim 1, wherein
said first dynamic latch (72, 76, 80) is a transistor which takes a form of MOSFET (Metal

Oxide Semiconductor Field Effect Transistor).
A pipelined data processing arrangement as claimed in claim 2, wherein
said second dynamic latch (70, 74, 78) is a transistor which takes a form of MOSFET.
A pipelined data processing arrangement as claimed in claim 1, wherein
said first dynamic latch (72, 76, 80) is a combination of a p-channel MOSFET and an n-channel

coupled in parallel.
A pipelined data processing arrangement as claimed in claim 2, wherein
said second dynamic latch (70, 74, 78) is a combination of a p-channel MOSFET and an n-channel

coupled in parallel. 
A method of reducing delay in data processing in a pipelined
arrangement having a plurality of stages (1-5) which are coupled in series.

comprising the steps of:

(a) successively issuing a plurality of instructions in synchronism with time
slots at a first stage (1);
(b) responding to occurrence of an interrupt request and retaining, at first
storage means (10, 12, 14) which comprises selectors (10(1)-10(n) and flip-flops (12(1)-12(n) included in said first stage (1), an instruction applied

thereto over one or more time slots which follow a time slot wherein said interrupt
request has been issued;
(c) decoding each of said instructions at a second stage (2) which, in
addition to the instruction decoding, issues said interrupt request if pipelined

operation should be interrupted;
(d) responding to said interrupt request and retaining, at second storage
means (22, 24, 26) which comprises selectors (22(1)-22(n) and flip-flops (24(1)-24(n) and included in said second stage (2), a decoded instruction over one

or more time slots which follow said time slot wherein said interrupt request has been
issued; and 
characterized by
(e) successively data processing at a plurality of data processing stages (3-5),
coupled to said second stage (2), in a manner which holds, at a first dynamic latch

(72, 76, 80) included in each of said data processing stages, a
data processing instruction and data, both of which are applied from a previous stage,

only during a time slot for which said data processing instruction is applied thereto.
</CLAIMS>
</TEXT>
</DOC>
