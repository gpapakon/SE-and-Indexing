<DOC>
<DOCNO>EP-0621555</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Method and apparatus for automatic character type classification of european script documents.
</INVENTION-TITLE>
<CLASSIFICATIONS>G06K962	G06K962	G06K968	G06K968	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06K	G06K	G06K	G06K	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06K9	G06K9	G06K9	G06K9	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
An automatic abstract character coding system automatically generates abstract 
coded characters (Figs. 5,6) from the text image of a document (100;Fig. 2) when the gross 

script-type is known to be, or is determined to be, a European type script. A connected 
component generating means (28) generates connected components from the pixels 

comprising the text image. A spatial feature determining means (30) generates a character cell 
(Fig. 4) surrounding one or more aligned connected component. A character-type classifying 

means (32) converts the character cell to one of a plurality of abstract character codes (Fig. 5). 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
XEROX CORP
</APPLICANT-NAME>
<APPLICANT-NAME>
XEROX CORP
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
SPITZ A LAWRENCE
</INVENTOR-NAME>
<INVENTOR-NAME>
SPITZ A LAWRENCE
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to a method and apparatus for automatic document 
recognition and, more particularly, to a method for automatically converting character cells of 
a document to abstract character codes and word tokens. Optical character recognition and the use of optical character recognition to convert 
scanned image data into text data suitable for use in a digital computer is well known. In 
addition, methods for converting scanned image data into text data and the types of errors 
such methods generate are well known. However, the selection of a proper method for error 
correction is highly dependent upon the language of the document. Conventionally, the 
methods for optical character recognition and for error correction in optical character 
recognition systems have been provided on the assumption that the language used in the 
document is known in advance. An optical character recognition system can be implemented 
with the character recognition and error resolution methods for a plurality of languages. However, it has heretofore not been possible to have the optical character 
recognition system automatically determine the language of the document. Rather, as each 
document is provided to the optical character recognition system, some indication of the 
particular language of the document must be provided to the optical character recognition 
system. This has been accomplished by either having the operator input data concerning the 
language and script of the document to the optical character recognition system, or by having 
the document provided with special markings which indicate the language of the document. It is therefore an object of the present invention to provide an optical character 
recognition system having automated script and language recognition capabilities. It is also an object of the present invention to determine the character type 
classification of the characters of a European script-type document. It is a further object of the present invention to generate word tokens based on the 
character-type classification. The present invention provides an automatic character classifying system according 
to claim 1 of the appended claims. The present invention further provides a method for automatically generating a 
plurality of abstract coded characters from a text portion, according to claim 5 of the appended 
claims. The invention further provides a method for automatically converting a character cell 
of a text portion of an image of a document into an abstract
</DESCRIPTION>
<CLAIMS>
An automatic character classifying system for generating a plurality of abstract coded 
characters (Fig. 5) from a text portion (104) of an image of a document, comprising: 

   input means (24) for inputting a digital data signal representative of the text portion, 
the digital data signal comprising a plurality of signal portions, each signal portion 

corresponding to one of the plurality of pixels; 
   connected component generating means (28) for generating a plurality of connected 

components from the plurality of signal portions; 
   spatial feature determining means (30) for determining spatial features of the text 

portion and for generating a plurality of character cells from the plurality of signal portions, 
each character cell comprising at least one connected component; and 

   classifying means (32) for converting each of the plurality of character cells into one 
of a plurality of abstract coded characters. 
The system of claim 1, wherein the classifying means (32) includes means for 
converting the character cells based on at least one of the number of connected components in 

the character cell, the horizontal extent of at least one connected component in the character 
cell, the vertical extent of at least one connected component in the character cell, the top 

position of at least one connected component in the character cell, and the bottom position of 
at least one connected component in the character cell. 
The automatic character classifying system of claim 1, wherein the classifying means 
(32) comprises: 

   counting means (320) for determining the number of connected components in a 
current one of the character cells; 

   top position locating means (322) for locating a top position of at least one 
connected component in the character cell; 

   bottom position locating means (324) for locating a bottom position of at least one 
connected component in the character cell; 

   connected component sizing means (326) for determining at least one of a height 
and a width of at least one connected component in the character cell; 

   spatial feature storing means (328) for storing at least one of the determined spatial 
features of a current line of the text portion corresponding to the current character cell; and 

   comparing means (330) for comparing at least one of the top position and the 
bottom position of at least one connected component with the stored spatial features and for 

comparing connected component height to connected component width. 
The system of claim 1, 2 or 3, wherein (1) the stored spatial features comprise at least 
one of a baseline position for the current line and an x-line position of the current line, or (2) 

the at least one determined spatial feature comprise at least one of interword spaces and 
intraword spaces. 
A method for automatically generating a plurality of abstract coded characters (Fig. 
5) from a text portion (104) of an image of a document, comprising the steps of: 

   inputting a digital data signal representative of the text portion, the digital data 
signal comprising a plurality of signal portions, each signal portion corresponding to one of the 

plurality of pixels; 
   generating a plurality of connected components from the plurality of signal 

portions; 
   
determining spatial features of the text portion; 
   generating a plurality of character cells from the plurality of signal portions, each 

character cell comprising at least one connected component; and 
   converting each of the plurality of character cells into one of a plurality of abstract 

character codes. 
The method of claim 5, wherein the step of converting converts the character cells 
into the abstract character code based on at least one of the number of connected components 

in the character cell, the horizontal extent of at least one connected component in the 
character cell, the vertical extent of at least one connected component in the character cell, the 

top position of at least one connected component in the character cell, and the bottom 
position of at least one connected component in the character cell. 
The method of claim 5 or 6, wherein the step of converting comprises at least one of 
the steps of: 

   determining a number of connected components in a current one of the character 
cells; 

   locating a top position of at least one connected component in the character cell; 
   locating a bottom position of at least one connected component in the character cell; 

   determining at least one of a height and a width of at least one connected 
component in the character cell; 

   comparing at least one of the top position and the bottom position of at least one 
connected component with the determined spatial features; and 

   comparing connected component height to connected component width. 
The method of claim 7, wherein (1) the determined spatial features comprise at least 
one of a baseline position for the current line and an x-line position of the current line, or (2) 

the at least one determined spatial feature comprise at least one of interword spaces and 
intraword spaces. 
A method for automatically converting a character cell (Fig. 4) of a text portion (104) 
of an image of a document into an abstract character code (Fig. 5), comprising the steps of: 

   determining spatial features of the character cell; 
   determining a number of connected components in the character cell; 

   locating a top position of at least one connected component in the character cell; 
   locating a bottom position of at least one connected component in the character cell; 

and 
   comparing at least one of the top position and the bottom position of at least one 

connected component with the determined spatial features. 
The method of claim 9, further comprising the steps of: 
   determining at least one of a height and a width of at least one connected 

component in the character cell; and 
   comparing connected component height to connected component width. 
</CLAIMS>
</TEXT>
</DOC>
