<DOC>
<DOCNO>EP-0612035</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Neural net for the comparison of image pattern features
</INVENTION-TITLE>
<CLASSIFICATIONS>G06K900	G06K900	G07C900	G07C900	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06K	G06K	G07C	G07C	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06K9	G06K9	G07C9	G07C9	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
This invention describes a technology to improve the 
feature based comparison of images. The images are captured 

and their significant features are extracted. For a comparison 
only the feature values have to be compared instead 

of the images themselves. This leads to a significant 
reduction of storage space and calculation time needed. 

Including also the individual variation ranges of the 
feature values and using a specialized neural net for 

classification, the reliability of the comparison can be 
improved greatly. 


</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
IBM
</APPLICANT-NAME>
<APPLICANT-NAME>
INTERNATIONAL BUSINESS MACHINES CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
RINDTORFF KLAUS
</INVENTOR-NAME>
<INVENTOR-NAME>
RUDOLPH VOLKER DR
</INVENTOR-NAME>
<INVENTOR-NAME>
RINDTORFF, KLAUS
</INVENTOR-NAME>
<INVENTOR-NAME>
RUDOLPH, VOLKER, DR.
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The invention relates to a multi-layer neural net as laid down
in the preamble of claim 1.There are two general principles for comparison of handwriting
and signatures, the dynamic and the static comparison. For a
dynamic verification, like the biometrics based verification
in the IBM Transaction Security System, the originator must be
physically present. The static approach can be used also in
environments where an image of a signature or handwriting must
be checked without the physically present originator, for
example cheque processing.A simple image comparison matches the two given images on a
picture element basis. This may include a sizing and rotation
operation to compensate differences in image resolutions and
skews. In this case it is very hard to compensate variations
in the geometry of the image contents itself without
adulterating it. A simple feature comparison will be achieved
by comparing the sample features against the reference
features and calculating the difference between them. The
identification of a measurement is the main problem in that
case.An example of a technique based on the extraction and
comparison of significant features and starting point of 
the present invention is the one described in EP-A-0 483 391.
The feature extraction leads to a significant reduction of
storage space and calculation time needed.For the image capture process a scanner or a touch- sensitive
device can be used. From the binary representation of the
rastered image, the actual features are computed and combined
to a vector of feature values, called a feature set. For a
comparison of two images only the two feature sets are
compared. The image information is not needed any longer.To compare two feature sets, each feature is compared and
weighted separately. To find good weightings for this
comparison is extremely difficult. For that, an artificial
neural net approach can be used. The arithmetic differences
between each two corresponding features from all features of
the feature sets is calculated and fed into the neural net.
There they are weighted internally and an output is calculated
which gives a value to be interpreted as the probability
whether the two images match. A well trained neural net will
be able to classify not only images used during training but
also those which are presented the first time at all. Using a
state of the art artificial neural network, like the
multi-layer perceptron, to compare two sample images,
recognition rates up to 95 percent have been achieved.It is an object of
</DESCRIPTION>
<CLAIMS>
Multi-layer neural net for comparing features from a
sample image (II, III) and a stored master reference (Ia,

Ib, Ic), comprising:

an image input for capturing said sample image (II, III);
and
a store for storing said master reference (Ia, Ib, Ic);
characterized by

an input layer of said net wherein input to each node in
said layer includes a feature value from said sample

image to be verified, a feature value from said stored
master reference, and a feature range value from said

stored master reference; and wherein each
node in said input layer is arranged to output a distance value for the

sample image feature value wherein said distance value is
calculated from said triple input to each node.
Multi-layer neural net as in claim 1, 
characterized in
that
 said distance value is computed by a function having
its extremum for two equal feature values.
Multi-layer neural net as in claim 2, 
characterized in
that
 said function is computed according to the formula

1
1 + 
abs (S-R)
V
 
wherein


abs is the absolute value of S-R,
S is the feature value from the sample image,
R is the feature value from the stored master reference,
and
V is the feature range value from the stored master
reference.
Multi-layer neural net as in claim 1, 
characterized in
that
 features are contained in two classes representing
values from geometric and stylistic information in the

image.
</CLAIMS>
</TEXT>
</DOC>
