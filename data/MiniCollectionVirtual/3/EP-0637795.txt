<DOC>
<DOCNO>EP-0637795</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Gestural indicators for selecting graphic objects
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F3033	G06K922	G06F3033	G06F3048	G06F314	G06F314	G06K922	G06F3048	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	G06K	G06F	G06F	G06F	G06F	G06K	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F3	G06K9	G06F3	G06F3	G06F3	G06F3	G06K9	G06F3	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A graphical imaging system, wherein the rough location, size and shape of objects in 
the image is summarized by a first characteristic descriptor, representing a parametric "pose" 

computed for each object (32). Next, a second characteristic descriptor, i.e. a "gesture 
matching" function, is provided in order to select the single object, or else the set of objects, 

that best comports with the user's selection gesture. When most closely matched, these key 
characteristic descriptors permit a simple and natural user gesture (30) to distinguish among a 

large set of graphic objects that may overlap spatially. User gestures can be simple slashes 
passing through the object, or quick, coarse approximations of objects' shapes. 


</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
XEROX CORP
</APPLICANT-NAME>
<APPLICANT-NAME>
XEROX CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BECKER CRAIG DAVID
</INVENTOR-NAME>
<INVENTOR-NAME>
MORAN THOMAS PATRICK
</INVENTOR-NAME>
<INVENTOR-NAME>
SAUND ERIC
</INVENTOR-NAME>
<INVENTOR-NAME>
BECKER, CRAIG DAVID
</INVENTOR-NAME>
<INVENTOR-NAME>
MORAN, THOMAS PATRICK
</INVENTOR-NAME>
<INVENTOR-NAME>
SAUND, ERIC
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
This invention pertains to a display editing system enabling users to edit images,
especially images of text, graphic diagrams, and freehand drawings. Typically, the image being
edited is displayed to the user on a computer screen or other imaging device, and the user
performs operations by typing strokes at a keyboard and/or by making gestures and pressing
buttons using one or more pointing devices such as a mouse or stylus.Among the most important user operations are those enabling the user to select an
object or objects in the image to which further operations subsequently will be applied, e.g.
move object, delete object, change object size, etc. The object(s) selectable may include any
combination of the following: single characters, single words, lines or paragraphs of alpha
numeric text such as found in an image of a page of text; graphic symbols, arrowheads, and
geometric figures including lines, circles, and rectangles such as found in graphic drawings; and
contiguous isolated strokes, stroke fragments bounded by corners, and stroke fragments
bounded by junctions such as found in freehand sketches. The issue of determining which
visible items in an image may be made available as selectable image objects is the subject of our
copending application based on U.S. Serial No. 08/101,647. In that case, a graphic editing
application program maintains a set of selectable image objects during the course of an image
editing session. This invention relates to enabling the user from time to time to select for
further processing one or more of these objects as conveniently as possible.An important problem faced by any user-interactive image editing tool is therefore
the determination of which object or objects in the image are intended by the user to be
indicated by a given set of keystroke and/or stylus gesture commands. Keystrokes are capable
of specifying symbolic labels or identities unambiguously, but they are an awkward and
unnatural interface for the inherently spatial information contained in a displayed image.
Conversely, gestures made with a pointing device are convenient for specifying spatial
information in the form of locations on an imaging surface, but can lead to ambiguous
specification of the object(s) the user intends to select when several objects occupy the same
region of the image. Stylus-based selection can be done, for example only, by the following
means: (1) having the user touch the stylus or press a mouse button at a single point in the
image whereafter the program selects the
</DESCRIPTION>
<CLAIMS>
A method of selecting a graphical object (32, 36, 40, 42, 46, 48, 52, 98) in a
display system, which object is most closely related to a selection gesture (30, 34,

38, 41, 44, 50, 96) performed in relation to the display (10), comprising the step of
inputting (120) a selection gesture,
characterized in that
 the method further comprises the steps of:

creating (122) a characteristic descriptor (92) for said input gesture,
selecting (126) from a collection (124) of stored objects the object or objects most
closely proximate to said input gesture,
retrieving (128) characteristic descriptors (92) representative of said selected
objects (104), and
comparing (130) the two sets of descriptors for choosing the object corresponding
most closely to the selection gesture.
The method of claim 1, further characterized by the step of creating said
characteristic descriptor of an object by:


determining, with respect to a fixed location, the X-Y location of said object,
determining the orientation of said object,
determining a function of the length of said object, 
determining the aspect ratio of said object, and
generating, from said foregoing determinations, said characteristic descriptor of
the object.
The method of claim 1 or 2, characterized in that creating said characteristic
descriptor of the gesture comprises, with respect to a fixed location:


determining the X-Y location of said gesture,
determining the orientation of said gesture,
determining the function of the length of said gesture,
determining the aspect ratio of said gesture, and
generating, from said foregoing determinations, said characteristic descriptor of
the gesture.
The method of one of claims 1 to 3, characterized in that:

selection is done for editing,
the objects may be overlapping,
the method comprises the step of entering a plurality of image objects on the
display surface, and
the method comprises the step of storing said characteristic descriptor.
The method of one of claims 1 to 4, characterized by the steps of:

selecting a set of objects corresponding to said gesture, 
calculating a difference factor between each said object and said gesture, and
selecting that one of said first characteristic descriptors which represents the least
difference factor between one of said objects and said gesture.
The method of one of claims 1 to 5, further characterized by the step of selecting
a path formed of a collection of primitive objects suitably related to each other of

an image, from a plurality of paths formed of line segments, said step of selecting
a path comprising:


entering said plurality of primitive objects on the display surface,
generating a path list corresponding to a plurality of incomplete paths
representing a sequence of primitive objects;
comparing said entered selection gesture curve with partial curves of said path
list, and
choosing at least one of said paths which most closely corresponds to said
entered selection gesture curve.
The method of claim 6, characterized in that said primitive objects comprise a
sequence of primitive line segments approximately linked together, said primitive

line segments each having no crossing, junctions or sharp corners.
The method of claim 6 or 7, characterized in that said step of choosing comprises
adding a chosen path to a list of paths until the final line of paths represents the

best of all chosen paths.
A display editing system for selecting a graphical object (32, 36, 42, 46, 48, 52,
98) being most closely related to a selection gesture (30, 34, 38, 41, 44, 50, 96),

comprising:

display means (10); 
means for inputting a selection gesture;
means for creating a characteristic descriptor (92) for said input gesture;
means for selecting from a collection of stored objects the object or objects most
closely proximate to said input gesture;
means for retrieving characteristic descriptors representative of said selected
objects; and
means for comparing the two sets of descriptors for choosing the object
corresponding most closely to the selection gesture.
The system of claim 9, arranged for performing the method according to one of
claims 1 to 8.
</CLAIMS>
</TEXT>
</DOC>
