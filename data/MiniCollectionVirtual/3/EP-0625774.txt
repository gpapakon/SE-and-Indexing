<DOC>
<DOCNO>EP-0625774</DOCNO> 
<TEXT>
<INVENTION-TITLE>
A method and an apparatus for speech detection
</INVENTION-TITLE>
<CLASSIFICATIONS>G10L1504	G10L1106	G10L1102	G10L1100	G10L1500	G10L1506	G10L1500	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G10L	G10L	G10L	G10L	G10L	G10L	G10L	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G10L15	G10L11	G10L11	G10L11	G10L15	G10L15	G10L15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
The speech detection apparatus of the present 
invention comprises: a reference model maker for extracting 

a plurality of parameters for a speech detection 
from training data, and making a reference model 

based on the parameters; a parameter extractor for 
extracting the plurality of parameters from each frame 

of an input audio signal; and a decision device for 
deciding whether the audio signal is speech or not, by 

comparing the parameters extracted from the input audio 
signal with the reference model. The reference model 

maker makes the reference model for each phonemes. The 
decision device includes: a similarity computing unit 

for comparing the parameters extracted from each frame 
of the input audio signal with the reference model, and 

computing a similarity of the frame with respect to the 
reference model; a phoneme decision unit for deciding a 

phoneme of each frame of the input audio signal based 
on the similarity computed for each phoneme; and a 

final decision unit for deciding whether a specific 
period of the input audio signal inclu
ding a plurality 
of frames is speech or not based on the result of the 

phoneme decision. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
MATSUSHITA ELECTRIC IND CO LTD
</APPLICANT-NAME>
<APPLICANT-NAME>
MATSUSHITA ELECTRIC INDUSTRIAL CO., LTD.
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
NAKATO YOSHIHISA
</INVENTOR-NAME>
<INVENTOR-NAME>
NORIMATSU TAKESHI
</INVENTOR-NAME>
<INVENTOR-NAME>
NAKATO, YOSHIHISA
</INVENTOR-NAME>
<INVENTOR-NAME>
NORIMATSU, TAKESHI
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to a speech
detection apparatus for deciding whether an input
signal is speech or nonspeech, under a noisy condition
in a real life environment which includes speech with
various stationary and/or nonstationary noises. More
particularly, the present invention relates to a speech
detection method and a speech detection apparatus, used
for detecting speech period, in a video conference
system, an audio reproduction system of television or
audio equipment, a speech recognition device or the
like.Recently, digital signal processing techniques
have been widely used in various fields of
electrical equipment. For example, in the field of
data transmission equipment, a technique and a device
for transmitting image data, as well as speech data,
whereby performing a communication with a sense of
presence are now under development. Videophone and
video conference systems are typical examples of applications
of such techniques, wherein a TV screen plays
an important role. Especially, a video conference
system in which many people may have conversations
requires a technique for correctly responding to the
voice of a speaker and properly changing the TV screen
so as to display the current speaker.Furthermore, in the audio reproduction system
of a television or audio equipment, techniques are 
under development for adding a reverberation and/or a
reflection to a reproduced sound so that a listener may
enjoy a sense of presence. When a broad-band signal or
a stereo signal of musical sound or the like is reproduced,
artificial sounds such as a reverberation sound
or a reflection sound may added to the signal so as to
result in a desirable effect. However, when a speech
signal or a monaural signal is reproduced, these artificial
sounds do not necessarily get an intended effect.
In some cases, an articulation score of the
signal may be degraded. Accordingly, in order to
perform an effective audio reproduction by adding the
artificial sounds only to nonspeech signals such as a
music signal, it is necessary to determine whether the
input audio signal is a speech signal or a nonspeech
signal.Moreover, in the system for performing a
speech recognition or the like, in a case where a noise
which is not speech is input and erroneously judged as
speech, it may cause an erroneous recognition. Accordingly,
such a system requires a speech detection apparatus
capable of correctly deciding whether an input
signal is a speech signal or not.The speech detection is performed mainly
based on a power of the
</DESCRIPTION>
<CLAIMS>
An apparatus for speech detection comprising:

reference model making means (12) for extracting a plurality of parameters for a
speech detection from training data, and making a reference model based on the

parameters;
parameter extracting means (11) for extracting the plurality of
parameters from each frame of an input audio signal; and
decision means (13, 14, 15) for deciding whether the audio signal is
speech or not, by comparing the parameters extracted from the input audio signal with

the reference model, wherein
the reference model making means (12) makes the reference model for
each phoneme, and
the decision means (13, 14, 15) comprises:

similarity computing means (13) for comparing the parameters extracted
from each frame of the input audio signal with the reference model, and computing a

similarity of the frame with respect to the reference model;
phoneme decision means (14) for deciding a phoneme of each frame of
the input audio signal based on the similarity computed for each phoneme; and
final decision means (15) for deciding whether a specific period of the
input audio signal including a plurality of frames is speech or not based on the result of

the phoneme decision.
An apparatus according to claim 1, wherein the reference model making means (12)
makes a reference pattern by calculating a mean value and a covariance matrix of the

plurality of parameters for each phoneme.
An apparatus according to claim 1 or 2, wherein the plurality of parameters are
selected from the group consisting of the first and higher order auto-correlation

coefficients, the first and higher order PARCOR coefficients, the first and higher order
melcepstrum coefficients, and the first and higher order LSP coefficients.
An apparatus according to one of the preceding claims, wherein the parameter
extracting means (11) comprises auto-correlation coefficient calculator means for

deriving autocorrelation coefficients of a plurality of orders and a cepstrum coefficient
calculator means for deriving cepstrum coefficients of a plurality of orders.
An apparatus according to claim 4, wherein the auto-correlation coefficient
calculator means (11b) calculates the first and seventh auto-correlation coefficients, and

the cepstrum coefficient calculator means (11c) calculates the first and third cepstrum
coefficients.
An apparatus according to one of the preceding claims, wherein the similarity is a
statistical distance between the parameters extracted from the input audio signal and the

reference model.
An apparatus according to claim 6, wherein the statistical distance is log likelihood.
An apparatus according to one of the preceding claims, wherein the phoneme
decision means (14) computes averaged likelihood by averaging the log likelihood of

each frame computed by the likelihood computing means with respect to a plurality of
successive frames including a target frame for phoneme detection, and detect a

phoneme based on the averaged likelihood. 
An apparatus according to one of the preceding claims, wherein the parameter
extracting means (11) further comprises a power calculating means (11a) for computing

a power for each frame, and wherein the specific period of the audio signal is a period

having a power equal to or greater than a predetermined value.
An apparatus according to one of the preceding claims, wherein the phoneme is a
vowel, and wherein the final decision means (15) comprising:


counting means for counting the number of frames detected to be a
vowel by the phoneme decision means (14) in the specific period,
computing means for computing the ratio of the number counted by the
counting means to the number of the total frames included in the specific period, and
judging means for deciding whether the specific period of the input
signal is speech or not based on the ratio computed by the computing means.
An apparatus according to one of claims 1 to 9, wherein the phoneme is a
consonant, and wherein the final decision means (15) comprising:


counting means for counting the number of frames detected to be a
consonant by the phoneme decision means (14) in the specific period,
computing means for computing the ratio of the number counted by the
counting means to the number of the total frames included in the specific period, and
judging means for deciding whether the specific period of the input
signal is speech or not based on the ratio computed by the computing means.
An apparatus according to one of the preceding claims, wherein the final decision
means comprises:


classification means for classifying the phonemes decided by the
phoneme decision means into first and second phoneme groups;
counting means for counting a first number of frames classified into the
first phoneme group and a second number of frames classified into the second

phoneme group in the specific period of the input audio signal; 
computing means for computing a first ratio of the first number with
respect to the number of frames included in the specific period and a second ratio of the

second number with respect to the number of frames included in the specific period;
and
judging means for judging whether the specific period is speech or not
using fuzzy reasoning based on the first ratio and the second ratio.
A method for speech detection comprising the steps of:

(a) extracting a plurality of parameters for a speech detection from training
data and making a reference model based on the parameters,
(b) extracting the plurality of parameters from each frame of an input audio
signal,
(c) deciding whether the input audio signal is speech or not, by comparing
the parameters extracted from the input audio signal with the reference

model, wherein

   steps (a) and (b) are performed for each phoneme, respectively, and
step (c) comprises the steps of:


(d) comparing the parameters extracted from each frame of the input audio
signal with the reference model and computing a similarity of each frame

with respect to the reference model,
(e) deciding a phoneme of each frame of the input audio signal based on the
similarity computed for each phoneme, and
(f) deciding whether a specific period of the input audio signal including a
plurality of frames is speech or not based on the result of the phoneme

decision in step (e).
A method according to claim 13, wherein step (a) comprises the step of making a
reference pattern by calculating a mean value and a covariance matrix of the plurality

of parameters. 
A method according to claim 13 or 14, wherein the parameters used in the steps are
selected from the group consisting of the first and higher order auto-correlation

coefficients, the first and higher order PARCOR coefficients, the first and higher
order melcepstrum coefficients, and the first and higher order LSP coefficients.
A method according to one of claims 13 to 15, wherein step (b) comprises the
steps of deriving auto-correlation coefficients of a plurality of orders and deriving

cepstrum coefficients of a plurality of orders.
A method according to claim 16, wherein in step (b), the first and seventh auto-correlation
coefficients and the first and third cepstrum coefficients are derived.
A method according to one of claims 13 to 17, wherein in step (d), the similarity is
a statistical distance between the parameters extracted from the input audio signal and

the reference model.
A method according to claim 18, wherein the statistical distance is log likelihood.
A method according to one of claims 13 to 19, wherein step (e) comprises the steps
of computing an averaged likelihood by averaging the log likelihood of each frame

computed in step (d) with respect to a plurality of successive frames including a target
frame for phoneme detection, and detecting a phoneme based on the averaged

likelihood.
A method according to one of claims 13 to 20, wherein step (b) comprises the step
of computing a power for each frame, and wherein

   step (f) comprises the steps of:

comparing the power of each frame with a predetermined value, and
identifying a period of the input audio signal based on the number of
frames having the power equal to or higher than a predetermined value as the

specific period of the input audio signal.
A method according to one of claims 13 to 21, wherein step (e) comprises the step
of (e1) deciding a vowel of each frame of the input audio signal, and wherein step (f)

comprises the steps of:

(f1) counting the number of frames detected to be a vowel in step (e1) in
the specific period of the input audio signal,
(f2) computing the ratio of the number counted in step (f1) to the number
of the total frames included in the specific period of the input audio signal, and
(f3) judging whether the specific period of the input signal is speech or
not based an the ratio computed in step (f2).
A method according to one of claims 13 to 22, wherein step (e) comprises the step
of (e1) deciding a consonant of each frame of the input audio signal, and wherein step

(f) comprises the steps of:

(f1) counting the number of frames detected to be a consonant in step (e1)
in the specific period of the input audio signal,
(f2) computing the ratio of the number counted in step (f1) to the number
of the total frames included in the specific period of the input audio signal, and
(f3) judging whether the specific period of the input signal is speech or
not based an the ratio computed in step (f2).
A method according to one of claims 13 to 23, wherein step (f) comprises the steps
of:


(g) classifying the phonemes decided in step (e) into first and second
phoneme groups,
(h1) counting a first number of frames classified into the first phoneme
group,
(h2) counting a second number of frames classified into the second
phoneme group in the specific period
 of the input audio signal,
(i1) computing a first ratio of the first number with respect to the number
of frames included in the specific period, 
(i2) computing a second ratio of the second number with respect to the
number of frames included in the specific period, and
(j) judging whether the specific period is speech or not using fuzzy
reasoning based on the first ratio and the second ratio.
</CLAIMS>
</TEXT>
</DOC>
