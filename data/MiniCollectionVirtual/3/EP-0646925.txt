<DOC>
<DOCNO>EP-0646925</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Fully scalable memory apparatus
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F1200	G11C800	G11C812	G06F1200	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	G11C	G11C	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F12	G11C8	G11C8	G06F12	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A memory is partitioned into rows and columns of memory blocks 
comprised of latches, sense amplifiers, and logic circuitry that form independent 

pipelines through which flow a) input addresses for memory access requests and b) 
data to be written into a specific memory cell within a memory block. The memory 

allows multiple data access requests in consecutive clock cycles to be pipelined in 
the rows and columns of memory blocks such that the memory clock speed is equal 

to the clock speed of a single memory block, independently of the memory size. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
AT 
&
 T CORP
</APPLICANT-NAME>
<APPLICANT-NAME>
AT
&
T CORP.
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
DICKINSON ALEXANDER G
</INVENTOR-NAME>
<INVENTOR-NAME>
NICOL CHRISTOPHER JOHN
</INVENTOR-NAME>
<INVENTOR-NAME>
DICKINSON, ALEXANDER G.
</INVENTOR-NAME>
<INVENTOR-NAME>
NICOL, CHRISTOPHER JOHN
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
This invention relates to memories. More specifically, this invention
relates to fully scalable memories.Traditionally, VLSI memories have been designed to allow quick access
to, and modification of, data stored in the memories, within a single memory cycle.
A corollary of that design strategy is to set a lower bound on memory cycle time for
a given memory size within the limitations of a particular technology (CMOS,
GaAs). A consequence of that design strategy is that increases in memory size result
in a proportional increase in cycle time caused by an increased capacitance of bit
lines and word lines. Thus, memory designers had to balance the benefits of greater
memory size against the disadvantages of slower access time.Efforts to increase memory size without increasing access time have led
memory designers to partition a memory into small modules called "blocks" that
allow shorter word lines and bit lines per block, thereby improving both access time
and memory throughput. In these new designs, communication to and from the
blocks of memory are established via a bus that is used to broadcast input addresses
and data to all blocks, and to transmit data retrieved from a selected block to the chip
output pins. Although these techniques have resulted in faster and higher throughput,
the size of memories using these techniques is limited. Specifically, a point of
diminishing return is reached when propagation delay through the bus (whose length
increases with an increasing number of blocks) and other interconnect delays
outweigh the reduced time required to access a block.EP-A-0471932 discloses a virtual multi-port RAM implemented as a
pipelined semiconductor memory chip segmented into a plurality of sub-arrays. Each of
the sub-arrays includes circuitry providing local self-timed reset and precharge
functions independent of the other sub-arrays.This invention, as defined by claim 1, is directed to memories which allow multiple data access
requests in consecutive clock cycles to be pipelined in a two dimensional array of
address and data distribution so that a constant memory access frequency can be
achieved independently of memory size.In a specific example of the invention, a memory is divided into blocks
arranged in an array of N rows and M columns of blocks. Latches, sense amplifiers,
and other logic circuitry associated with the blocks of the array allow creation of two
independent pipelines through which flow systolically a) input addresses for memory
access requests and b) data to be written into a
</DESCRIPTION>
<CLAIMS>
A memory, said memory including an array partitioned into rows (M) and
columns (N) of memory blocks, each one of said memory blocks being partitioned into a

plurality of rows (J) and columns (K) of memory cells; means for decoding addresses
(101) of said memory blocks into separate block column, block row, cell column, and cell

row address signals; and means for addressing (M, N, J, K) memory cells within said array
using said block and said cell address signals

CHARACTERIZED IN THAT

the memory further comprises:

   means for pipelining (101, 104, 102, M, N, J, K) through said blocks of said array
a plurality of memory access requests in consecutive clock cycles using said decoding

(101) and addressing means (M, N, J, K) to provide memory cell access, whereby said
memory operates at a clock speed equal to a single memory block clock speed.
The memory of claim 1 wherein said pipelining means include means for
propagating a) said block column, and said cell column address signals through the

columns of said array and b) said block row and said cell row address signals through the
rows of the array, said block and said cell address signals being propagated one block per

clock cycle to permit simultaneous arrival of said row and column address signals at a
desired memory block identified by said block row and block column address signals.
The memory of claim 1 wherein address signals and data are propagated
through data paths formed by latches, sense amplifiers and logic circuitry associated

with said blocks.
The memory of claim 1 further comprising means for retrieving data from a
selected memory cell.
The memory of claim 4 wherein said retrieving means includes means for
recognizing a small voltage swing read by a sense amplifier associated with said block of

the selected memory cell.
The memory of claim 4 firther comprising means for sending data retrieved
from at least one memory cell through said blocks ofthe array, one block per cycle, until 

the retrieved data reaches an output path of the memory such that pipelined memory
access requests are processed in a first-in first-out order.
The memory of claim 1 further comprising a content addressable memory which
stores addresses of detective subsections in the memory and maps the addresses of the

defective subsections to different addresses of operative subsections in said memory.
The memory claim 1 wherein each block in said array comprises:
latches which store in addition to data, valid row and column addresses of memory cells

within the block; control logic circuitry which receives input from said latches and
generate control signals to a) propagate received input data and b) write received input

data to a particular memory cell; and sense amplifiers which receive a column address as
input from one of said latches and transfer the address to a vertically adjacent block.
The memory of claim 1 further comprising means for writing input data to a
selected memory cell when input data are propagated with address signals of the selected

memory cell.
The memory of claim 1 wherein said writing means further includes means for
applying full voltage swings on a selected bit line ofthe selected memory cell.
</CLAIMS>
</TEXT>
</DOC>
