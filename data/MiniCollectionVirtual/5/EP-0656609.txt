<DOC>
<DOCNO>EP-0656609</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Image processing
</INVENTION-TITLE>
<CLASSIFICATIONS>G06T1500	G06T1520	G06T1510	G06T1500	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06T	G06T	G06T	G06T	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06T15	G06T15	G06T15	G06T15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
Texture mapping or video mapping is performed in such a way as 
to obtain perspectively correct images. In order to minimise 

computational overheads, a technique for deriving texture coordinate 
values (U,V) at each pixel of an image (A), based on the inverse of the 

depth coordinate (z) at that pixel is described. In order to avoid aliasing 
the technique is extended by the determination of texture gradient 

values (dU/dX, dU/dY, dV/dX, dV,dY) in the vertical and horizontal 
directions. 


</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
KONINKL PHILIPS ELECTRONICS NV
</APPLICANT-NAME>
<APPLICANT-NAME>
PHILIPS ELECTRONICS UK LTD
</APPLICANT-NAME>
<APPLICANT-NAME>
KONINKLIJKE PHILIPS ELECTRONICS N.V.
</APPLICANT-NAME>
<APPLICANT-NAME>
PHILIPS ELECTRONICS UK LIMITED
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
MORRIS JEREMY STUART
</INVENTOR-NAME>
<INVENTOR-NAME>
MORRIS, JEREMY STUART
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to a method of image processing and an
image processing apparatus.In particular, the present invention relates to rendering a two
dimensional image from three dimensional image data, wherein a
polygon defined in three dimensional space is projected into two
dimensional space and pixel values from a two dimensional image are
mapped onto pixel positions within said projected two dimensional
polygon.Computer graphics systems are known in which two dimensional
video images or two dimensional textures appear wrapped around a
solid three dimensional object. A three dimensional object is
represented as three dimensional image data, in which the vertices of
polyhedra are defined as three dimensional co-ordinate locations within
a virtual three dimensional world, commonly referred to as world-space.
The object is viewed by producing a two dimensional projection from
the three dimensional data, so as to produce a still two-dimensional
image, or a sequence of images, which may be recorded onto
photographic film or a video carrying medium.The position of objects, along with viewing position and
orientation, may be adjusted within the three dimensional world-space,
resulting in a sequence of projections being calculated. These
projections may be calculated on a frame-by-frame basis, possibly in
real time, thereby facilitating the creation of a virtual interactive
environment.In order to effect the rendering of three dimensional objects, each
surface of a polyhedron may be considered individually, thereby
reducing the object to a net of polygons. Thus, it is possible to project
the object on a polygon-by-polygon basis and to calculate lighting 
values for each polygon, so that displayable pixel values may be
determined for the pixel positions which lie within the projected polygon
boundaries.In addition to identifying solid colours for each polygon surface, it
is also possible to map an existing video frame onto the polygon
surfaces, so that it appears as if a flat two dimensional image has been
wrapped around the three dimensional object. The video frame may
consist of a single image, thereby creating the effect of a texture being
mapped onto the three dimensional object. Alternatively, the video
image may consist of a video sequence, thereby creating the effect of
a moving video image being wrapped around the solid object.In the three dimensional world-space, polygons have orientations
in the x,y and the z dimensions. However, once projected onto a two
dimensional plane, the polygons
</DESCRIPTION>
<CLAIMS>
An image processing method for rendering a two dimensional
image from three dimensional image data, wherein a polygon defined in three

dimensional space is projected into two dimensional space and pixel values
from a two dimensional image are mapped onto pixels within said projected

two dimension polygon, characterised by the steps of:

providing stored values of the coordinates (X, Y) of the projected two
dimensional polygon, together with depth (z) and mapping image coordinate

values (U, V) for each vertex;
determining the inverse (1/z) of the depth value and the product (U/z,
V/z) thereof with respective mapping image coordinate values (U, V) at each

of the vertices of the projected two dimensional polygon; and
interpolating therefrom to determine pixel values along edges of the
projected polygon and along scan lines therebetween.
A method according to Claim 1, in which the projected two
dimensional image is divided into a plurality of triangles, and the steps of

value determination and interpolation are carried out for each of the triangles

in turn.
A method according to Claim 2, in which the triangles are
processed in the order of the greatest to the least depth coordinate value.
A method according to Claim, in which the image is divided such
that each of the plurality of triangles has an edge extending parallel to an axis

of the two dimensional space.
A method according to Claim 1, comprising the further step of
deriving texture gradient values as the rate of change of one or more texture

coordinates in either or both axis directions of the two dimensional space
within the image.
A method according to Claim 5, comprising the step of selecting
one from a pluralitv of available resolution levels in dependence on one or

more derived texture gradient values.
A method according to Claim 1, wherein the step of interpolation
comprises linear interpolation. 
Image processing apparatus arranged to render a two dimensional
image from three dimensional image data, such that a polygon defined in

three dimensional space is projected into two dimensional space and pixel
values from a two dimensional image are mapped onto pixels within the

projected polygon characterised by:

first storage means arranged to store the coordinates of the vertices (X,
Y) of the polygon projected into two dimensional space, together with depth

(z) and mapping image coordinate values (U, V) for each vertex;
calculation means arranged to derive the inverse (1/z) of the depth value
and the respective products (U/z, V/z) thereof with the mapping image

coordinate values for the vertices;
second storage means arranged to receive and store the derived values
from the calculation means; and
processing means coupled to said first and second storage means and
arranged to interpolate the derived values from the second storage means to

determine pixel values along edges of the projected polygon and along scan
lines therebetween.
Apparatus according to Claim 8, operable to successively map a
plurality of polygonal images, including means for determining which of a

plurality of such images has the greatest depth coordinate value and mapping
that image first.
Apparatus according to Claim 8, wherein said processing means is
operable to determine, for each pixel and from the depth coordinate value and

information stored in said first and second memory means, a texture gradient
value as the rate of change of a texture coordinate in an axis direction of the

two dimensional space within the image.
</CLAIMS>
</TEXT>
</DOC>
