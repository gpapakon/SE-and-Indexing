<DOC>
<DOCNO>EP-0654749</DOCNO> 
<TEXT>
<INVENTION-TITLE>
An image processing method and apparatus
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F301	G06T120	G06F301	G06T100	G06T120	G06T100	G06K900	G06K900	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	G06T	G06F	G06T	G06T	G06T	G06K	G06K	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F3	G06T1	G06F3	G06T1	G06T1	G06T1	G06K9	G06K9	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A real time output containing data relating to states of 
facial parts is generated. A facial area detection unit 

(11) has monitoring (51-57) and determining (59-61) 
processing circuits operating in a pipelining manner to 

determine position of the facial area. The monitoring 
circuits (51-57) monitor pixel value frequency using 3D 

histogram and backprojection processing. The generating 
facial area signal has masks applied by a unit (12) which 

supplies data to mouth area and eye area detection units 
(14,15). Each of these operate on similar principles to 

the facial area detection unit (11). 

</ABSTRACT>
<APPLICANTS>
</APPLICANTS>
<INVENTORS>
</INVENTORS>
<DESCRIPTION>
The invention relates to image processing, and more
particularly to processing of images are of facial
expressions.European Patent Specification No. EP 474,307A2 (Philips)
describes a system having means for receiving facial image
data and processing means for processing this data. In more
detail, this specification describes a method of tracking
an object such as a face. An initial template of the face
is formed and a mask outlining the face is extracted. The
mask is then divided into a number of sub-templates which
are not associated with specific features of the subject.
Each successive frame is searched to determine matches.
While this method appears to be effective for tracking an
overall object such as a face, it does not provide the
necessary data relating to state (location, orientation,
open/closed status etc.) of parts of the face and other
parts such as fingertips. Accordingly, it would appear to
have limited applicability and not to be suitable to such
tasks as automatic generation of sign language data and
generation of displays to assist in understanding and
communicating sign language.It is known to provide an image processing apparatus
comprising receiving means for facial image data, and
processing means for processing the facial image data in
which said receiving means comprises means for receiving at
least one colour facial image data stream in digital format
and in which said processing means comprises a plurality of
image data processing circuits interconnected for
processing the image data in a pipelining manner to provide
a real time output, the circuits comprising means 
for monitoring colour values in the image data to identify
image data pixels representing facial parts, and means for
determining states of the facial parts by monitoring
positional coordinates of the identified pixels and an
output device for outputting the determined facial part
state data in real time.A typical example of this is described in various
publications and in particular in Proceedings CVPR '85:
IEEE Computer Society Conference on Computer Vision and
Pattern Recognition, San Francisco, CA, USA, 19-23 June
1985, 1985, Silver Spring, MD, USA, IEEE Comput. Soc.
Press, USA, pp 40-47, Petajan E D 'Automatic Lipreading to
enhance speech recognition'. However, there would be
considerable computational, operational difficulties
carrying out imaging processing according to the disclosure
of this document. While this document does not disclose
the processing of colour images, the use of colour
information for
</DESCRIPTION>
<CLAIMS>
An image processing apparatus (1) comprising
receiving means for facial image data, and

processing means (3) for processing the facial
image data; in which said receiving means (10)

comprises means for receiving at least one colour
facial image data stream in digital format; and in

which said processing means (3) comprises:-

a plurality of image data processing circuits
(11-15) interconnected for processing the

image data in a pipelining manner to provide a
real time output, the circuits comprising :-


means (51-57) for monitoring colour
values in the image data to identify

image data pixels representing facial
parts, and
means (59-61) for determining states of
the facial parts by monitoring

positional coordinates of the identified
pixels; and the apparatus (1) further

comprises:-
an output device (6) for outputting the
determined facial part state data in

real time;

   
characterised in that

said means (51 to 57) for monitoring
colour values carries out three-dimensional 

colour histogram matching using a variable
bucket size to group similar colours into single boxes to

generate the three-dimensional colour histogram and to
monitor frequency of occurrence of pixel values in the

image data;

and in which there is a back projection means for comparing
at least one bucket representing facial parts of a template

histogram generated off-line with the corresponding bucket of
a generated histogram of the image data;

whereby the bucket of the image data is more likely to
represent a facial part the closer the ratio between the two

buckets is to 1.
An apparatus as claimed in claim 1 wherein then determining
means further comprises a counter (60) for determining the area

of the facial part or parts.
An apparatus as claimed in claim 1 further comprising means (10)
for normalising the received colour facial image data stream.
An apparatus as claimed in claim 1 wherein the processing
circuits comprise :-


a facial area detection unit (11) comprising circuits for
carrying out facial area detection operations on the

image data; and
a facial part detection unit (14, 15) connected to said
facial area detection unit and comprising processing

circuits for determining states of a facial part within
the detected facial area using the image data and an

output signal from said facial area detection unit.
An apparatus as claimed in claim 4 further
comprising a mask generating unit (12) connected

between the facial area and facial part detection
units.
An apparatus as claimed in claim 4 comprising two
facial part detection units, namely :-


a mouth area detection unit (14); and
an eye area detection unit (15).
An apparatus as claimed in claim 6 wherein the
apparatus further comprises a mask generating unit

(12) connected between the facial area detection
unit (11) and the facial part detection units, (14,

15) said mask generating unit (12) comprising means
for generating an eyes mask signal and a mouth mask

signal.
An apparatus as claimed in claim 6 wherein the
mouth area and eye area detection units (14, 15)

are connected in the apparatus to operate on the
same image data in parallel.
An apparatus as claimed in claim 1, wherein the
apparatus further comprises means (61) for carrying

out a consistency check to validate determined
positional data.
An apparatus as claimed in claims 4 to 9 wherein
each processing unit comprises means (61) for

carrying out a consistency check on positional data
which it generates. 
An apparatus as claimed in claim 9 wherein the
consistency check means comprises a processor (61)

programmed to compare the positional data with
reference positional data.
An apparatus as claimed in claim 1 wherein the
monitoring means comprises means (55, 56, 57) for

carrying out binary erosion and binary dilation
steps to generate image data in which noise is

reduced and the subject area is recovered.
An apparatus as claimed in claim 1 further
comprising image data processing circuits (13) for

determining location of a coloured fingertip
represented in the input image data.
An apparatus as claimed in claim 1 comprising image
processing circuits (11-15) for facial area and

separate image processing circuits (13) for
coloured fingertips, said circuits being connected

to process the input image data in parallel.
An apparatus as claimed in claim 13 further
comprising a result processor (5) comprising means

for receiving facial part and coloured fingertip
positional data to generate an output signal

representing proximity of a coloured fingertip to
facial parts for assistance in communication of

sign language. 
An apparatus as claimed in claim 1 further
comprising a video device (2) for generating the

image data stream.
An apparatus as claimed in claim 16, wherein the
video device is a camera (2) having an analog to

digital converter.
An apparatus as claimed in claim 16 wherein the
video device is a camera (2), and the camera is

mounted on a frame (7) adjacent a light source (8)
so that it is directed upwardly at an angle so that

the face of a person seated next to the frame is
within the field of view.
A method of processing facial image data in an
image processing apparatus comprising circuits

interconnected for processing the facial image
data, the method comprising the steps of:


receiving (20) a digital colour image data
stream;
monitoring (22) colour values in the image
data to identify image data pixels

representing facial parts;
determining (22) states of the facial parts by
monitoring positional coordinates of the

identified pixels, said monitoring and
determining steps being carried out by

processing circuits interconnected for
processing the image data in a pipelining

manner; and
outputting (38) in real time a signal 
representing the determined facial part state

data;
characterised in that
 the method further comprising
the steps of:


grouping similar colours into single boxes of
variable bucket size;
generating a three-dimensional colour
histogram from boxes to monitor frequency of

occurrence of pixel values in each box;
comparing the generated histogram with a

template histogram off-line;
calculating the ratio of at least one bucket
of the template histogram with a bucket of the

generated histogram;
determining whether the bucket of the
generated histogram represents a facial part

from the ratio.
A method as claimed in claim 19, wherein the
monitoring and determining steps are carried out to

initially identify facial area (22) and position,
and subsequently to identify facial parts and

determine states of the facial parts.
A method as claimed in claim 19 in which the
additional steps are performed of dividing the

number of pixels in the corresponding boxes of one
of the histograms and the template histogram by the

other, the divisor always being the lowest number
to provide a new ratio histogram.
</CLAIMS>
</TEXT>
</DOC>
