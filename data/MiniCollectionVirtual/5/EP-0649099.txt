<DOC>
<DOCNO>EP-0649099</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Neural cellular automaton and optimizer employing the same
</INVENTION-TITLE>
<CLASSIFICATIONS>G06N310	G06N300	G06F1518	G06F1518	G06N300	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06N	G06N	G06F	G06F	G06N	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06N3	G06N3	G06F15	G06F15	G06N3	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A cellular automaton part (1) is provided with 
cellular automata (2a, 2b, 2c) each including a plurality 

of cells (3). Each cell (3) is provided with a growth 
period state deriving circuit (4) for growing a cell 

column and a stable period state deriving circuit (5) for 
stabilizing the cell column. An input/output part (6) 

carries out input/output (7, 9a, 9b, 9c) in/from the 
cellular automata (2a, 2b, 2c) in relation to a target 

problem, and outputs the same also to an evaluation part 
(8). The evaluation part (8) operates the degrees of 

application of the cellular automata (2a, 2b, 2c) with 
respect to the target problem, so that an evaluation 

reflecting part (11) decides next initial states of the 
cellular automata (2a, 2b, 2c) and operations of the 

growth period and stable period state deriving circuits 
(4, 5) on the basis of evaluation values (10) of the 

evaluation part (8). 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
ATR HUMAN INF PROCESSING
</APPLICANT-NAME>
<APPLICANT-NAME>
ATR HUMAN INFORMATION PROCESSING RESEARCH LABORATORIES
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
DE GARIS HUGO
</INVENTOR-NAME>
<INVENTOR-NAME>
HEMMI HITOSHI
</INVENTOR-NAME>
<INVENTOR-NAME>
DE GARIS, HUGO
</INVENTOR-NAME>
<INVENTOR-NAME>
HEMMI, HITOSHI
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to a neuronic cellular
automaton and an optimizer employing the same. More
specifically, it relates to a neuronic cellular automaton
formed by a simply produced repeating structure, which can
flexibly change the number of neurons, presence/absence of
connections between the neurons and connection weights in
response to problems, and an optimizer employing the same.The technique of information processing employing an
artificial neural network has been developed in recent
years. The artificial neural network (hereinafter simply
referred to as a neural network) is formed by connecting a
number of neurons which are units for carrying out simple
and uniform information processing, in simulation of a
cerebral neural network.Figs. 16 and 17 illustrate hierarchical and
interconnecting neural networks, which are examples of
conventional neural networks respectively.The hierarchical neural network shown in Fig. 16
includes a first layer 31, a second layer 33 and a third 
layer 35, which include neurons 32a, 32b and 32c, neurons
34a to 34h and a neuron 36 respectively. Each of the
neurons 32a, 32b and 32c provided in the first layer 31 is
connected with the respective ones of the neurons 34a to
34h provided in the second layer 33. Each of the neurons
34a to 34h provided in the second layer 33 is connected
with the neuron 36 provided in the third layer 35.Referring to Fig. 16, numeral 37 denotes connections
increasing outputs when inputted signals are large,
numeral 38 denotes connections suppressing outputs when
inputted signals are large, and symbols w1' to w8, denote
connection weights between the neurons 34a to 34h provided
in the second layer 33 and the neuron 36 provided in the
third layer 35.Due to the aforementioned structure, respective
signals x1, x2 and x3 which are received in the neurons
32a, 32b and 32c of the first layer 31 are inputted in the
neuron 36 of the third layer 35 through the neurons 34a to
34h of the second layer 33, to be converted to a signal y
and outputted from the neuron 36. The hierarchical neural
network shown in Fig. 16 is employed as a learning
mechanism with exercises, for example.On the other hand, the interconnecting neural network
shown in Fig. 17 is formed by interconnecting neurons 40a,
40b and 40c comprising functions f1, f2, ..., fn 
respectively. This interconnection is so made that an
output of the neuron 40a comprising the function f1 is
inputted in respective ones of the neurons including the
neuron 40a itself, for example. The functions
</DESCRIPTION>
<CLAIMS>
A cellular automaton (2a, 2b, 2c) provided with a plurality
of cells (3) being so interconnected with each other that

said cells (3) may receive as input signals indicating states of surrounding cells (3),

characterized in that each cell (3) includes growth period
state deriving means (4) for progressing state propagation

signals in said cells (3) by developing cell columns with reference to a prescribed rule, said rule or state deriving principle being so provided that a next state of a cell is derived from its current state and from states of surrounding cells,
said state propagation signals having respective heads (21)

holding the loci of the progress of said cells (3) as signal propagation
paths and stopping progress of those of said state propagation

signals having heads (21) colliding with each other, and each said cells (3) also including stable
period state deriving means (5) adding new signals to starting

points of said signal propagation paths for propagating said
loci of progress toward head sides as propagated loci of progress,

and changing other state propagation signals by head
signals of said propagated loci of progress, said stable period state deriving means (5) thereby stabilizing

said cellular automaton. 
The cellular automaton in accordance with
claim 1, wherein said growth period state deriving means (4) includes:


progress means for progressing said state propagation
signals while propagating straightly forward, deflecting or

branching the same from starting points of
prescribed cells (3),
holding means for holding signal loci of said state
propagation signals being progressed by said progress

means, as signal propagation paths, and
stop means for stopping progress of those of said
state propagation signals having heads (21) colliding with a

signal propagation path of itself or other signals, being held by said holding means.
The cellular automaton in accordance with
claim 1 or 2, wherein said growth period state deriving means (4) includes:


propagation means for adding new signals to said
cells (3) in said signal propagation paths as formed, thereby

propagating signal loci of said state propagation signals,
and
change means for changing other state propagation
signals by heads (21) of said state propagation signals being

propagated by said propagation means.
The cellular automaton in accordance with
one of claims 1 to 3, wherein


said growth period state deriving means and said stable period state deriving means (5) are provided in the interior
or the exterior of each said cell (3) in said cellular

automaton (2a,2b,2c).
An optimizer employing a neuronic cellular
automaton (2a,2b,2c) having a plurality of cells (3) being interconnected

with each other, said optimizer comprising:

a cellular automaton part (1) being provided with
neuronic cellular automata (2a,2b,2c);
growth period state deriving means (4) for progressing
state propagation signals in said cells (3) by developing cell columns with reference to a prescribed rule, said rule or state deriving principle being so provided that a next state of a cell is derived from its current state and from states of surrounding cells from starting points of

prescribed cells of said neuronic cellular automata (2a,2b,2c) 
provided in said cellular automaton part said state propagation signals having respective heads (21), for holding loci of

progress thereof as signal propagation paths, form
colliding head cells of said signal propagation paths as

operation parts, and for stopping progress of those of said
state propagation signals having their heads colliding,

thereby growing said neuronic cellular automaton (2a,2b,2c);
stable period state deriving means (5) adding new signals
to said starting points of said signal propagation

paths for propagating said loci of progress toward head
sides and changing other state propagation signals by head

signals of propagated loci of progress in said
operation parts, said stable period state deriving means (5) thereby stabilizing said neuronic

cellular automaton (2a,2b,2c);
an input/output part (6) outputting a target problem (7) to
said neuronic cellular automata (2a,2b,2c) of said cellular

automaton part (1) and receiving an output result (9a,9b,9c) of said
neuronic cellular automata (2a,2b,2c) being responsive thereto;
an evaluation part (8) comparing said target problem (7) with
said output result (9a,9b,9c) of said neuronic cellular automata (2a,2b,2c) for

calculating an evaluation value (10) being a degree of
application of said neuronic cellular automata (2a,2b,2c) to said

target problem (7); and
an evaluation value reflecting part (11) for deciding a
next initial state of said neuronic cellular automata (2a,2b,2c) in

said cellular automaton part (1) and next operations of said 
growth and stable period state deriving means (4,5) on the basis

of said evaluation value (10) being calculated in said
evaluation part (8) and inputting respective signals (12)

indicating the same in said neuronic cellular automata (2a,2b,2c),
in said growth period state deriving means (4) and in said stable

period state deriving means (5).
An optimizer in accordance with claim 5, wherein

said cellular automaton part (1) has a plurality of said
neuronic cellular automata (2a,2b,2c), said evaluation value

reflecting part (11) employing a genetic algorithm as said prescribed rule.
A cellular automaton provided with a plurality of cells (3)
being so interconnected with each other that signals indicating

states of nearby cells (3) can be inputted into respective said
cells (3) as input signals in accordance with claim 1, said automaton comprising:


cell columns transferring state signals indicating a state of a
surrounding cell (3), and arbitrarily formed as signal propagation

paths; and
a state deriving component arbitrarily forming collisions of
said cells (3) of said signal propagation paths responsive to

said prescribed rule.
</CLAIMS>
</TEXT>
</DOC>
