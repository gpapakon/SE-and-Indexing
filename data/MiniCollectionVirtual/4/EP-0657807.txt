<DOC>
<DOCNO>EP-0657807</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Method and system for efficient instruction execution in a data processing system having multiple prefetch units.
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F938	G06F938	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F9	G06F9	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
In a data processing system, a plurality of prefetch elements are 
provided for prefetching instructions from a group of memory arrays 

coupled to each prefetch element. A plurality of instruction words are 
sequentially stored in each group of memory arrays coupled to each 

prefetch element. In response to a selected prefetch element receiving a 
prefetch token, the selected prefetch element sequentially recalls 

instruction words from the group of memory arrays coupled to the selected 
prefetch element. Thereafter, the selected prefetch element transfers 

the sequence of instruction words to a central processing unit at a rate 
of one instruction word per cycle time. In response to a forthcoming 

conditional branch instruction, a plurality of prefetch elements may 
initiate instruction fetching so that the proper instruction may be 

executed during the cycle time immediately following the conditional 
branch instruction. By coupling a group of memory banks to each prefetch 

element, and limiting the location of branch instructions to the last 
memory bank in the group of memory banks, the number of prefetch elements 

required to implement a data processing system having substantially 
similar performance to the prior art architecture is reduced. In an 

alternative embodiment, video memories are utilized to store instruction 
words, and provide such instruction words to the CPU at the rate of one 

instruction word per cycle time. 

 
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
IBM
</APPLICANT-NAME>
<APPLICANT-NAME>
INTERNATIONAL BUSINESS MACHINES CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BRETERNITZ JR MAURICIO DR
</INVENTOR-NAME>
<INVENTOR-NAME>
BRETERNITZ JR., MAURICIO, DR.
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
Recently, a new data processing system architecture, called of ring 
of prefetch elements (ROPE) has been disclosed in an article entitled 
"Getting High Performance With Slow Memory," by Kevin Karplus and 
Alexandru Nicolau, published in COMPCON, May, 1986, at pages 248-253. 
The purpose of the architecture is to provide a data processing system 
capable of sustaining an instruction execution rate of one instruction 
per cycle time, even during the execution of multiway branch 
instructions. Such a data processing system may be useful for processing 
real-time video and multimedia presentations. This ROPE architecture is 
illustrated as prior art in Figure 1. As illustrated, ROPE architecture 20 includes "M" number of 
prefetch elements 22, 24, 26, and 28, for fetching instructions from an 
associated memory bank. The determination of the number of prefetch 
elements (i.e., the number "M") required for a particular application of 
the ROPE architecture is discussed below in greater detail. Memory banks 
30-36 are each associated with one prefetch element 22-28, respectively, 
and are utilized for storing instructions only. Separate data memory 
banks may be provided for storing program variables or other temporary or 
variable data. An advantage of this ROPE architecture is that memory 
banks 30-36 may be implemented by memory devices which require a 
relatively long period of time to fetch data when compared to the cycle 
time of the CPU which receives the instructions. As utilized herein, 
"cycle time" means the minimum duration between two successive 
instruction requests by the CPU. Once prefetch elements 22-28 fetch instructions from memory banks 
30-36, such instructions are placed on instruction bus 38 at an 
appropriate time determined by logic circuits within prefetch elements 
22-28 and control signals on control bus 40. Instruction bus 38 is 
coupled to data path 42, which is part of CPU 44. Control bus 40 
receives control information 46, which may include condition bits and the 
instruction pointer, from CPU 44. Instructions stored within memory banks 30-36 may be very large. 
In some implementations, the instruction word may be 512 bits wide, and 
include a plurality of fields. One of such fields contains an 
instruction to be executed by CPU 44. Other fields in the instruction  
 
word may contain instructions addressed to one of prefetch elements 22-28, 
such as a command to initiate a prefetch. In operation, ROPE architecture 20 is capable of supplying data 
path 42 with one
</DESCRIPTION>
<CLAIMS>
A method for executing instructions in a central processing unit of 
a data processing system, the method comprising the steps of: 

   providing M prefetch elements for prefetching instructions; 
   coupling a group of N memory banks to each one of the M prefetch 

elements; 
   sequentially storing a plurality of instruction words in each group 

of N memory banks; 
   in response to a selected prefetch element receiving a prefetch 

token, sequentially fetching the plurality of instruction words from the 
group of N memory banks utilizing the selected prefetch element; and 

   sequentially executing the fetched plurality of instruction words 
utilizing the central processing unit in the data processing system. 
A method as claimed in claim 1 wherein, during the step of 
sequentially storing a plurality of instruction words in each group of N 

memory banks, a sequence of N instruction words is sequentially stored in 
each group of N memory banks. 
A method as claimed in claim 1 wherein, during the step of coupling 
a group of N memory banks to each one of the M prefetch elements, a group 

of N memory banks is coupled to each one of the M prefetch elements 
wherein each one of the group of N memory banks has a serial output 

coupled to the one of the M prefetch elements for serially transferring 
selected bits to the one of the M prefetch elements. 
A method as claimed in claim 3 wherein, during the step of coupling 
a group of N memory banks to each one of the M prefetch elements wherein 

each one of the group of N memory banks has a serial output coupled to 
the one of the M prefetch elements for serially transferring selected 

bits to the one of the M prefetch elements, a group of N video memories 
is coupled to each one of the M prefetch elements for serially 

transferring selected bits to the one of the M prefetch elements. 
A method as claimed in claim 3 wherein, during the step of 
sequentially storing a plurality of instruction words in each group of N 

memory banks, a plurality of N-bit instruction words are sequentially 
stored in each group of N memory banks wherein each bit of an N-bit 

instruction word is stored in a corresponding one of the N memory banks. 
A method as claimed in claim 3 wherein, during the step of 
sequentially fetching the plurality of instruction words from the group 

of N memory banks utilizing the selected prefetch element, selected bits 
comprising the plurality of N-bit instruction words are contemporaneously 

and serially fetched from the group of N memory banks utilizing the 
selected prefetch element. 
A system for executing instructions in a central processing unit of 
a data processing system comprising: 

   a central processing unit for executing instructions; 
   a plurality of memory banks for storing the instructions; 

   an instruction bus coupled to the central processing unit for 
transferring the instructions to the central processing unit; 

   a control bus coupled to the central processing unit for 
transferring control data; and 

   a plurality of prefetch elements, each of the plurality of prefetch 
elements coupled to a subgroup of the plurality of memory banks, to the 

instruction bus, and to the control bus, each of the plurality of 
prefetch elements for fetching the instructions from the subgroup of the 

plurality of memory banks and transferring the instructions to the 
instruction bus in response to receiving the control data via the control 

bus. 
A system as claimed in claim 7, wherein the plurality of 
prefetch elements are each operable in a plurality of modes including: 


(a) an idle mode wherein the prefetch element waits for the 
control data before fetching a plurality of instructions from the 

subgroup of the plurality of memory banks; 
(b) a fetching mode wherein the prefetch element fetches the 
plurality of instructions from the subgroup of the plurality of memory 

banks in response to receiving the control data; 
(c) a ready mode wherein the prefetch element has fetched the 
plurality of instructions from the subgroup of the plurality of memory 

banks and is waiting to receive the control data via the control bus 
before transferring the plurality of instructions to the central 

processing unit via the instruction bus; and 
(d) an active mode wherein the prefetch element transfers the 
plurality of instructions to the central processing unit via the 

instruction bus in response to receiving the control data via the control 
bus. 
A system as claimed in claim 7 or claim 8 wherein, the plurality of 
prefetch elements are each coupled to a subgroup of N memory banks, and 

wherein each of the plurality of memory banks is coupled to only one of 
the plurality of prefetch elements. 
A system as claimed in claim 7 or claim 8 wherein, the plurality of 
memory banks for storing the instructions comprises a plurality of memory 

banks having a serial output, and wherein the plurality of prefetch 
elements are each coupled to the serial output of each of a subgroup of N 

of the plurality of memory banks, and wherein each of the plurality of 
memory banks is coupled to only one of the plurality of prefetch 

elements. 
A system as claimed in claim 10 wherein, the central processing 
unit may execute one instruction per cycle time, and wherein a complete 

N-bit instruction word is comprised of bits output from the serial output 
of each of the subgroup of N of the plurality of memory banks, and 

wherein the subgroup of N of the plurality of memory banks are coupled to 
a common clock for clocking an output of a series of N-bit instruction 

words at a rate of at least one instruction per cycle time. 
A system as claimed in claim 11 wherein, the plurality of prefetch 

elements provide address signals and the common clock signal to the 
subgroup of N of the plurality of memory banks, and wherein the timing of 

the common clock signal is independent of the timing of the address 
signals. 
A system as claimed in claim 10 wherein, the control data received 
by the plurality of prefetch elements via the control bus is an activate 

token. 
</CLAIMS>
</TEXT>
</DOC>
