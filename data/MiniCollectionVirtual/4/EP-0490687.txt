<DOC>
<DOCNO>EP-0490687</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Method and apparatus for image processing
</INVENTION-TITLE>
<CLASSIFICATIONS>G06K920	G06K968	G06K968	G06K936	G06K936	G06K920	H04N140	H04N1387	H04N140	H04N1387	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06K	G06K	G06K	G06K	G06K	G06K	H04N	H04N	H04N	H04N	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06K9	G06K9	G06K9	G06K9	G06K9	G06K9	H04N1	H04N1	H04N1	H04N1	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A method and apparatus for differentiating and extracting handwritten annotations 
and machine printed text in an image. The method provides for the use of morphological 

operations, preferably at reduced scale, to eliminate for example, the handwritten annotations 
from an image. A separation mask is produced that, for example, converts all the image pixels 

corresponding to machine printed text, and none of the image pixels corresponding to 
handwritten or handprinted annotations. The separation mask is used in conjunction with the 

original image to produce separate handwritten annotations and machine printed text images. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
XEROX CORP
</APPLICANT-NAME>
<APPLICANT-NAME>
XEROX CORPORATION
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BLOOMBERG DAN S
</INVENTOR-NAME>
<INVENTOR-NAME>
BLOOMBERG, DAN S.
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to the field of image processing, and more particularly to a
method and apparatus for identifying and/or separating machine printed text and handwritten
annotations in an image.US-A-4,821,333 discloses a method for generating a program to be used in image domain
feature discrimination problems. A processor is programmed to perform a series of mathematical
morphological transformations as specified by structuring elements and morphological operations.
A program form and structuring elements can be used to discriminate between samples taken from
two distinct script styles, illustratively Aramaic and Zend.Many documents and their images contain both machine printed text and handwritten
annotations. It would be useful to be able to identify regions of a scanned image that correspond to
handwritten or handprinted annotations. For example, current OCR systems, as well as foreseeable
future OCR systems, are not able to reliably recognize handwritten annotations in an image. When
such text is fed to a conventional OCR system, such systems will often produce unusable results.
The performance of such systems could be improved if handwritten regions could be identified to
avoid processing such regions in the OCR process.On the other hand, identification and retrieval of handwritten annotations on documents are
sometimes important. For example, an image filing system would make use of handwritten notations
by saving the annotations (and their coordinates) along with an OCR-ized version of the image. In
general, if the handwritten annotations are identified as such, the system can save them as bitmap
data, to be fed back to the user in a way that is appropriate to the application.While meeting with some success, prior methods of separating handwritten annotations
and machine printed text have met with a variety of limitations. Some of the prior methods require
equipment which is expensive, complex, and/or unreliable, while other techniques require significant
amounts of computer memory, computer time, or the like. Some of the methods are less than
reliable in detecting and separating handwritten annotations.Accordingly, an improved method and apparatus are desired for detecting the presence of
handwritten annotations and, if present, separating them from machine printed text in a document or
image.It is an object of the present invention to provide a method and apparatus for identifying
and, optionally, separating handwritten annotations and machine printed text in an image or
document,
</DESCRIPTION>
<CLAIMS>
A method of performing image processing, comprising:

obtaining an input image, at least a region of which is expected to consist of
handwritten areas and machine printed text areas;
if necessary, processing 
(1)
 the region of the input image to provide a first version
of the region of the image having a resolution at which the density of single OFF pixels laterally

bounded on both sides by ON pixels is greater in the machine printed text areas than in the
handwritten areas;
processing the region of the input image or the first version of the region using a
sequence of operations 
(2; 3)
, including at least one morphological operation, to produce a
second version of the region, characterised in that:
the sequence of operations

provides at least some ON pixels in portions of the second version of the
region where the density of single OFF pixels laterally bounded on both sides by ON

pixels in the first version of the region is relatively high, and
eliminates ON pixels from portions of the second version of the region
where the density of single OFF pixels laterally bounded on both sides by ON pixels in

the first version of the region is relatively low.
A method as claimed in claim 1, and further comprising processing the second
version of the region 
(4, 8, 6; 5, 8, 6)
 to determine areas of the input image that include machine
printed text substantially to the exclusion of handwritten text. 
A method as claimed in claim 2 in which
said morphological operation

is performed with a first
structuring element (SE) that selectively identifies areas of the first version of the

region in which OFF pixels are laterally bounded by ON pixels.
A method as claimed in claim 3 in which the first SE has two positions and in
which said sequence of operations comprises further comprises:


processing with the first SE to produce a destination image;
XORing the destination image with the first version to produce the
second version.
A method as claimed in claim 3, in which the first SE has left, center, and right
positions, the left and right locations being ON and the center position being OFF.
A method as claimed in claim 3 in which
said morphological operation

is performed with the first SE to
produce a first intermediate image; said sequence of operations further comprising:


closing the first intermediate image with a second SE, the second SE
having at least two vertically adjacent ON pixels; and
opening said first intermediate image with a third SE, the third SE
having at least two vertically adjacent ON pixels.
A method as claimed in any preceding claim in which the second version of the
region is a mask overlaying substantially only the machine printed text areas or

substantially only the handwritten areas.
A method as claimed in claim 7 in which said sequence of operations further comprises:

extracting seed pixels in substantially only said machine printed text
areas or in substantially only said handwritten areas; and
filling said seed pixels to a clipping mask, said clipping mask comprising
substantially solid regions of ON pixels over said machine printed text areas

and said handwritten areas.
A method as claimed in claim 7 in which
said sequence of operations

produces an intermediate image
and further comprises:


closing and opening the intermediate image with SE's each having two or
more laterally adjacent ON pixels to produce the second version of the region.
A method as claimed in any of the claims 7 to 9 further comprising:

ANDing the mask with the input image to form an output image, the output
image including substantially only the machine printed text areas or

substantially only the handwritten areas.
A method as claimed in any preceding claim in which the method further comprises,
before said sequence of operations:


processing the input image to produce the first version of the region of the
input image; comprising:
reducing said input image using a thresholded reduction.
A method as claimed in any of claims 1 to 11 in which the method further comprises,
before said sequence of operations:


processing the input image to produce the first version of the region of the
input image; comprising:
removing regions of the input image that include large solid regions and
finely textured regions.
An apparatus (100) for performing image processing, comprising input means
(103) for providing images; and


processing means (106) for performing a sequence of operations on an input
image from the input means (103) to identify machine printed text areas in the

input image;
characterized in that
the sequence of operations is performed by the processing means on a first
version of a region of the input image, the first version of the region being a

region of the input image, or, if necessary, a region of a reduced version of the
input image, the region of the first version having a resolution at which the

density of single OFF pixels laterally bounded on both sides by ON pixels is
greater in the machine printed text areas than in handwritten areas; and
the processing means includes means for detecting in the first version of the
region, instances of single OFF pixels laterally bounded on both sides by ON

pixels,
means for processing the first version of the region using at least one
morphological operation, to produce a second version of the region, wherein

the second version of the region 
includes at least some ON pixels in portions of the second version of the
region where the density of single OFF pixels laterally bounded on both

sides by ON pixels in the first version of the region is relatively high, and
includes substantially no ON pixels in portions of the second version of
the region where the density of single OFF pixels laterally bounded on

both sides by ON pixels in the first version of the region is relatively low.
An apparatus as claimed in claim 13 further comprising

means for processing the second version of the region to determine areas of
the input image that include machine printed text substantially to the exclusion

of handwritten text.
An apparatus (100) as claimed in claim 14 in which the sequence of operations
performed by the processing means (106) further removes the identified handwritten

areas in the input image before performing optical character recognition.
</CLAIMS>
</TEXT>
</DOC>
