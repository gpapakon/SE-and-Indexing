<DOC>
<DOCNO>WO-1989011703</DOCNO> 
<TEXT>
<INVENTION-TITLE>
DOCUMENT RECOGNITION AND AUTOMATIC INDEXING FOR OPTICAL CHARACTER RECOGNITION
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F1724	G06F1724	G06K920	G06K920	G06K936	G06K936	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	G06F	G06K	G06K	G06K	G06K	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F17	G06F17	G06K9	G06K9	G06K9	G06K9	</CLASSIFICATIONS-FOURTH>
<APPLICANTS>
<APPLICANT-NAME>
EASTMAN KODAK CO
</APPLICANT-NAME>
<APPLICANT-NAME>
EASTMAN KODAK COMPANY
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BARSKI LORI LYNN
</INVENTOR-NAME>
<INVENTOR-NAME>
GABORSKI ROGER STEPHEN
</INVENTOR-NAME>
<INVENTOR-NAME>
BARSKI, LORI, LYNN
</INVENTOR-NAME>
<INVENTOR-NAME>
GABORSKI, ROGER, STEPHEN
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
 DOCUMENT RECOGNITION AND AUTOMATIC INDEXINGFOR OPTICAL CHARACTER RECOGNITIONBACKGROUND OF THE INVENTIONProblem Solved by the InventionOptical character recognition systems are useful for automatically reading the contents of a document for storage in a computer memory. An image sensor scans the document and generates image data, which the optical character recognition system transforms into text. The data representing the text is then immediately stored in a computer memory for instant access and processing by the user. An important requirement is that the optical character recognition system either be able to distinguish between image data representing text characters and image data representing non-text things (e.g., printed lines), or else that the data representing printed lines or other non-text things be deleted from the image data before it is received by the optical character recognition system.When processing a plurality of different business forms, the optical character recognition system may be more efficient if it knows the locations of the various fields in a given business form containing text characters. For example, if the business form is a sales order form, the data may be used more quickly if the system already knows the location on the form of certain critical information such as the price, quantity, type, delivery address, etc... Knowing the location of the various fields on the form may also help the system orient the document image correctly in memory, or determine the boundary in the image data 

between one document and the next document.Thus, the optical character recognition system needs to know to which one of a plurality of known business forms a particular document (represented by incoming image data) corresponds if it is to operate at the highest efficiency. Therefore, for maximum efficiency, the incoming documents must first be grouped according to type of business form before they are processed by the optical character recognition system. As each group of documents is fed to the system, the user must inform the system as to which type of business form the current group corresponds. The sorting or grouping function may require an unacceptably large amount of the user's time.Thus, the problem is how to permit the optical character recognition system to operate at maximum efficiency without requiring the user to sort the incoming documents according to type of business form or to inform the system of the type of document about to be received. Prior Attempts to Solve
</DESCRIPTION>
<CLAIMS>
CLAIMS:
1. A document character recognition system for use with an optical character recognition system, said document character recognition system comprising: means for storing in memory plural reference templates specifying spacings between and the lengths of pre-printed lines in corresponding plural pre-printed forms; means for receiving incoming video data comprising successive video lines thereof representing the image of a document of unknown form; means for generating a sample template from said incoming video data, said sample template specifying spacings between and lengths of pre-printed lines in said image of said document; and means for determining which one of said plural reference templates most closely resembles said sample template.
2. The system of claim 1 wherein said plural reference templates and said sample template each specify the video line number of horizontal pre—printed lines. 3. The system of claim 2 wherein said means for generating a sample template comprise: means for generating a curve representing the linear density of "on" pixels in said video data as a function of video line number; means for locating peaks exceeding a predetermined threshold in said curve and noting the locations of said peaks; and means for determining the longest runlength of "on" video pixels in each video line corresponding to each one of said peaks. 


 4. The system of claim 3 wherein said means for generating a sample template further translates the noted locations of said peaks into a series of numbers representing spacings between successive horizontal lines in said image.
5. The system of claim 3 wherein said means for locating peaks in said curve comprise means for producing the differential of said curve and noting the locations of discontinuities in said differential of said curve.
6. The system of claim 1 wherein said means for determining which one of said plural reference templates most closely resembles said sample template comprises at least one of the following: means for finding which one of said plural reference templates exactly matches said sample template and noting the identity thereof; and means for computing a cross-correlation between each of said plural reference templates and said sample template and noting which one of said plural reference templates has the highest cross—correlation with said sample template.
7. The system of claim 6 wherein said means for determining include both said means for finding an exact match and said means for computing a cross—correlation, and wherein said determining means further comprises: default means responsive whenever said means for finding fails to find an exact match for activating said means for computing said cross-correlation.
8. The system of claim 1 further comprising means for transmitting the contents of the one template identified by said determining 



means to said optical character recognition system and for transmitting said video data representing said one document to said optical character recognition system, whereby said optical character recognition system may associate the contents of said one template with the video data representing said one document.
9. The system of claim 1 further comprising: buffer means for storing the video data representing said one document until said determining means identifies said one reference template; output processor means, responsive whenever said determining means identifies said one template, for fetching the video data from said buffer means and masking therefrom data representing pre-printed lines therein corresponding to the pre-printed line spacings and lengths in said one reference template, and for transmitting the data thus masked to said optical character recognition system, whereby said optical character recognition system is protected from receiving non-text data.
10. The system of claim 1 wherein each of said templates comprises a pair of tables stored in memory, one of said tables listing spacings between subsequent pre-printed lines and the other of said tables represents the corresponding pre-printed line lengths, the contents of each of said two tables being arranged in order of the location of corresponding pre-printed lines on said image.
11. The system of claim 1 wherein said plural reference templates stored in said means for storing are generated by transmitting the image data of the corresponding plural forms in succession to 


 said means for receiving incoming video data, whereby said means for generating a sample template generates corresponding plural sample templates comprising said plural reference templates, which may then be stored in said means for storing.
12. A document character recognition system for use with an optical character recognition system, said document character recognition system comprising: means for storing in memory plural reference templates specifying spacings between pre-printed lines in corresponding plural pre-printed forms; means for receiving incoming video data comprising successive video lines thereof representing the image of a document of unknown form; means for generating a sample template from said incoming video data, said sample template specifying spacings between pre-printed lines in said image of said document; and means for determining which one of said plural reference templates most closely resembles said sample template.
13. The system of claim 12 wherein said plural reference templates and said sample template each specify the video line number of horizontal pre-printed lines.
14. The system of claim 13 wherein said means for generating a sample template comprise: means for generating a curve representing the linear density of "on" pixels in said video data as a function of video line number; means for locating peaks exceeding a predetermined threshold in said curve and noting the locations of said peaks . 


 15. The system of claim 14 wherein said means for generating a sample template further translates the noted locations of said peaks into a series of numbers representing spacings between successive horizontal lines in said image.
16. The system of claim 3 wherein said means for locating peaks in said curve comprise means for producing the differential of said curve and noting the locations of discontinuities in said differential of said curve.
17. The system of claim 12 wherein said means for determining which one of said plural reference templates most closely resembles said sample template comprises at least one of the following: means for finding which one of said plural reference templates exactly matches said sample template and noting the identity thereof; and means for computing a cross—correlation between each of said plural reference templates and said sample template and noting which one of said plural reference templates has the highest cross-correlation with said sample template.
18. The system of claim 17 wherein said means for determining include both said means for finding an exact match and said means for computing a cross-correlation, and wherein said determining means further comprises; default means responsive whenever said means for finding fails to find an exact match for activating said means for computing said cross-correlation.
19. The system of claim 12 further comprising means for transmitting the contents of the one template identified by said determining 


means to said optical character reocgnition system and for transmitting said video data representing said one document to said optical character recognition system, whereby said optical character recognition system may associate the contents of said one template with the video data representing said one document.
20. The system of claim 12 further comprising: buffer means for storing the video data representing said one document until said determining means identifies said one reference template; output processor means, responsive whenever said determining means identifies said one template, for fetching the video data from said buffer means and masking therefrom data representing pre-printed lines therein corresponding to the pre-printed line spacings and lengths in said one reference template, and for transmitting the data thus masked to said optical character recognition system, whereby said optical character recognition system is protected from receiving non-text data.
21. The system of claim 12 wherein each of said templates comprises a pair of tables stored in memory, one of said tables listing spacings between subsequent pre-printed lines and the other of said tables represents the corresponding pre-printed line lengths, the contents of each of said two tables being arranged in order of the location of corresponding pre-printed lines on said image.
22. The system of claim 1 wherein said plural reference templates stored in said means for storing are generated by transmitting the image data of the corresponding plural forms in succession to 


said means for receiving incoming video data, whereby said means for generating a sample template generates corresponding plural sample templates comprising said plural reference templates, which may then be stored in said means for storing.
23. A document character recognition method for use with an optical character recognition system, said document character recognition method comprising: storing in memory plural reference templates specifying spacings between and the lengths of pre-printed lines in corresponding plural pre—printed forms; receiving incoming video data comprising successive video lines thereof representing the image of a document of unknown form; generating a sample template from said incoming video data, said sample template specifying spacings between the lengths of pre—printed lines in said image of said document; and determining which one of said plural reference templates most closely resembles said sample template.
24. The method of claim 23 wherein said plural reference templates and said sample template each specify the video line number of horizontal pre-printed lines.
25. The method of claim 24 wherein said generating step comprises: generating a curve representing the linear density of "on" pixels in said video data as a function of video line number; locating peaks exceeding a predetermined threshold in said curve and noting the locations of said peaks; and 


 determining the longest runlength of "on" video pixels in each video line corresponding to each one of said peaks.
26. The method of claim 25 wherein said generating a sample template step further comprises translating the noted locations of said peaks into a series of numbers representing spacings between successive horizontal lines in said image.
27. The method of claim 23 wherein said step of determining which one of said plural reference templates most closely resembles said sample template comprises at least one of the following steps: finding which one of said plural reference templates exactly matches said sample template and noting the identity thereof; and computing a cross-correlation between each of said plural reference templates and said sample template and noting which one of said plural reference templates has the highest cross-correlation with said sample template.
28. The method of claim 23 further comprising transmitting the contents of the one template identified by said determining means to said optical character recognition system and transmitting said video data representing said one document to said optical character recognition system, whereby said optical character recognition system may associate the contents of said one template with the video data representing said one document.
29. The method of claim 23 further comprising: storing the video data representing said one document in a buffer until said determining 


means identifies said one reference template; whenever said determining step identifies said one template, fetching the video data from said buffer and masking therefrom data representing pre-printed lines therein corresponding to the pre-printed line spacings and lengths in said one reference template, and transmitting the data thus masked to said optical character recognition system, whereby said optical character recognition system is protected from receiving non-text data.
30. The method of claim 23 wherein each of said templates comprises a pair of tables stored in memory, one of said tables listing spacings .between subsequent pre-printed lines and the other of said tables represents the corresponding pre—printed line lengths, the contents of each of said two tables being arranged in order of the location of corresponding pre—printed lines on said image. 

</CLAIMS>
</TEXT>
</DOC>
