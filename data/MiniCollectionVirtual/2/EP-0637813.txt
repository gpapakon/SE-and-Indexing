<DOC>
<DOCNO>EP-0637813</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Image processing
</INVENTION-TITLE>
<CLASSIFICATIONS>G06T1500	G06T1500	G06T1510	G06T1520	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06T	G06T	G06T	G06T	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06T15	G06T15	G06T15	G06T15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
Texture mapping or video mapping is performed in 
such a way as to obtain perspectively correct images, 

while at the same time not requiring excessive 
computational overheads. 
Non-linear functions required to achieve 
perspectively correct images are stored in the form of 

look-up tables. Depth extents at the extremes of a 
locus of interpolation are compared and from this 

comparison a particular look-up table, or a pair of 
look-up tables, are selected. When are pair of look-up 

tables are selected, it is possible to linearly 
interpolate between the two, in order to obtain a closer 

approximation to the desired non-linear response. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
KONINKL PHILIPS ELECTRONICS NV
</APPLICANT-NAME>
<APPLICANT-NAME>
PHILIPS ELECTRONICS UK LTD
</APPLICANT-NAME>
<APPLICANT-NAME>
KONINKLIJKE PHILIPS ELECTRONICS N.V.
</APPLICANT-NAME>
<APPLICANT-NAME>
PHILIPS ELECTRONICS UK LIMITED
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
PENNA DAVID EDWARD
</INVENTOR-NAME>
<INVENTOR-NAME>
PENNA, DAVID EDWARD
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to a method of image
processing and an image processing apparatus.In particular, the present invention relates to
rendering a two dimensional image from three dimensional
image data, wherein a polygon defined in three
dimensional space is projected into two dimensional
space and pixel values from a two dimensional image are
mapped onto pixel positions within said projected two
dimensional polygon.Computer graphics systems are known in which two
dimensional video images or two dimensional textures
appear wrapped around a solid three dimensional object.
A three dimensional object is represented as three
dimensional image data, in which the vertices of
polyhedra are defined as three dimensional co-ordinate
locations within a virtual three dimensional world,
commonly referred to as world-space. The object is
viewed by producing a two dimensional projection from
the three dimensional data, so as to produce a still
two-dimensional image, or a sequence of images, which
may be recorded onto the photographic film or a video
carrying medium. A survey of such known systems is given in "Survey of Texture Mapping", Paul S.
Heckbert, IEEE Computer Graphics and Applications, Volume 6(11), November 1986,
pp. 56-67.The position of objects, along with viewing
position and orientation, may be adjusted within the
three dimensional world-space, resulting in a sequence
of projections being calculated. These projections may 
be calculated on a frame-by-frame basis, possibly in
real time, thereby facilitating the creation of a
virtual interactive environment.In order to effect the rendering of three
dimensional objects, each surface of a polyhedron may be
considered individually, thereby reducing the object to
a net of polygons. Thus, it is possible to project the
object on a polygon-by-polygon basis and to calculate
lighting values for each polygon, so that displayable
pixel values may be determined for the pixel positions
which lie within the projected polygon boundaries.In addition to identifying solid colours for each
polygon surface, it is also possible to map an existing
video frame onto the polygon surfaces, so that it
appears as if a flat two dimensional image has been
wrapped around the three dimensional object. The video
frame may consist of a single image, thereby creating
the effect of a texture being mapped onto the three
dimensional object. Alternatively, the video image may
consist of a video sequence, thereby creating the effect
of a moving video image being wrapped around the
</DESCRIPTION>
<CLAIMS>
An image processing method of rendering a two dimensional
image from three dimensional image data, wherein a polygon (21) defined in

three dimensional space is projected into a two dimensional view and pixel

values from a two dimensional image (25) are mapped onto pixels (X,Y) within
the projected two dimensional polygon (21), 
characterised in that
 the method
includes the steps of:


defining a locus of pixels (X,Y) in the two dimensional projection
between a first pixel (22) and a second pixel (24), the first and second pixels

having corresponding predetermined locations (U,V) in the two dimensional
image (25);
selecting a look-up table from a plurality of look-up tables stored in
storage means (43), each table corresponding to a different scaled perspective

correcting mapping function, the selection being made by reference to a table
selection value obtained by processing depth (z) values of the first and second

pixels (22,24);
obtaining a scaled perspective correcting mapping function from the
selected look-up table; and
using the mapping function to determine locations (U,V) in the image
(25) corresponding to intermediate pixels in the locus.
A method according to claim 1, wherein the table selection value
is obtained by dividing the depth value (z) of the first pixel (22) by the depth

value (z) of the second pixel (24).
A method according to claim 1, wherein the table selection value
is obtained from the logarithm of the depth value of the first pixel and the

logarithm of the depth value of the second pixel. 
A method according to claim 3, wherein the logarithm of each of
the depth values is obtained by shifting the most significant bit of the

respective depth value and an indication of the number of shifts made is
supplied to look-up table means (79) to produce an indication of which look-up

table is to be selected from the storage means (43).
A method according to any one of Claims 1 to 4, wherein two
look-up tables are selected from the storage means (43) and new values for

performing the mapping operation are determined by a process of linear
interpolation between the two functions stored in the look-up tables.
Image processing apparatus arranged to render a two
dimensional image from three dimensional image data, such that a polygon

(21) defined in three dimensional space is projected into a two dimensional
view and pixel values from a two dimensional image (25) are mapped onto

pixels (U,V) within the projected polygon (21), 
characterised in that
processing means (15) are provided for defining a locus of pixels (X,Y)
in the two dimensional projection between a first pixel (22) and a second pixel

(24), the first and second pixels having corresponding predetermined locations
(U,V) in the two dimensional image (25),
storage means (43) are provided for storing a plurality of look-up tables,
each corresponding to a different scaled perspective correcting mapping

function,
a selector (42) is arranged to select a look-up table by reference to a
table selection value obtained by processing depth (z) values of the first and

second pixels (22,24), and
processing means (41) are provided for obtaining a mapping function
from the selected look-up table and using the mapping function to determine

locations (U,V) in the image corresponding to intermediate pixels in the locus.
Apparatus according to claim 6, wherein the selector (42) obtains
the table selection value by dividing the depth value (z) of the first pixel (22) by

the depth value (z) of the second pixel (24).
Apparatus according to claim 6, wherein the selector (42) obtains
the table selection value from the logarithm of the depth value of the first pixel

and the logarithm of the depth value of the second pixel.
Apparatus according to claim 8, wherein the selector (42)
includes a shift register (77,78), means for shifting values in said register and

processing means for processing said shifted values, to provide an indication
of the required look up table.
Apparatus according to any of claims 6 to 9, wherein the selector
(42) is arranged to select two look-up tables and the processor (41) is

arranged to determine new values for the mapping operation by linear
interpolation between the two functions stored in the look-up tables.
</CLAIMS>
</TEXT>
</DOC>
