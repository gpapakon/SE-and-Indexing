<DOC>
<DOCNO>EP-0657053</DOCNO> 
<TEXT>
<INVENTION-TITLE>
METHOD OF DESIGNING A NEURAL NETWORK AND NEURAL NETWORK THEREBY ACHIEVED
</INVENTION-TITLE>
<CLASSIFICATIONS>G06N304	G06N300	G06N308	G06F1518	G06F1518	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06N	G06N	G06N	G06F	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06N3	G06N3	G06N3	G06F15	G06F15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
The invention concerns a method of designing a neural network (5), in which almost any types of neuron can be used in an intermediate layer. An optimization device (6) is used to establish pairs of values (x, y) for the input and output signals (4, 7) of the network (5). Solution of a system of linear equations to obtain the parameters of the neurons in the output layer enables the parameters (8) of the network (5) to be subsequently determined using these pairs of values (x, y). The invention is suitable for use in control-system design.
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
SIEMENS AG
</APPLICANT-NAME>
<APPLICANT-NAME>
SIEMENS AKTIENGESELLSCHAFT
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
KIRCHBERG KARL-HEINZ
</INVENTOR-NAME>
<INVENTOR-NAME>
KIRCHBERG, KARL-HEINZ
</INVENTOR-NAME>
</INVENTORS>
<CLAIMS>
A method of constructing a neural network which 
possesses at least one input and at least one output and 

neurons in a plurality of layers arranged in series, 
wherein in the neurons of an intermediate layer input 

signals are firstly weighted and then logic-linked to 
one another, and with a non-linear element an output 

signal is formed and each output of the output layer of 
the neural network is assigned an output neuron to which 

the output signals of the neurons of the preceding layer 
are fed and in which, by the weighting and logic-linking 

of these signals, an output signal is in each case 
produced 


in the case of which, for each output neuron, q 
support values (xi, yi) for input- and output 

signals are preset, 
 
characterised in that 


the value range of the respective input signal x is 
determined and n auxiliary quantities xi' are 

defined in such manner that they are equally 
distributed over the respective value range, where 

the number n of the auxiliary quantities is equal 
to the number n of the neurons in the respective 

layer, 
the parameters, weight ej and offset quantity dj, 
of the input function of the j-th neuron of a layer 

are defined via the logic-linking of the input 
signals in the neurons of a layer in such manner 

that the analysis of the auxiliary quantities xi' 
results in a square matrix of a given structure 

comprising matrix elements mij, where 

mij = fj (gj (dj, ej, xi')) 
 
and  

 

the row index i of the matrix designates the 
current auxiliary quantity (xi' (1 ≤ i ≤ n), 
the column index j of the matrix designates the j-th 
neuron of the respective layer (1 ≤ j ≤ n), 
gj designates the input function of the j-th neuron 
of the respective layer in dependence upon the 

parameters dj, ej and xi' and 
fj designates the output function of the non-linear 
element at the output of the j-th neuron of the 

respective layer, where 

fj (gj) signifies a nested function for the 
description of a neuron with an input function 

gj and an output function fj; 
the matrix is laid out in such a way that it can be 
easily inverted and 
the weights ai required to form the output signal y 
from the output signals of the neurons of the 

preceding layer in a neuron are determined by 
solving a linear equation system 
M
 . 
a
 = 
y
 which 
consists of q equations for the output signal 

values yi of the q support values (where q ≤ n) in 
which the values mij of the q support values 

obtained by analysis of the input signal values xi 
are in each case multiplied by the corresponding 

weights ai and added. 
A method as claimed in Claim 1, characterised in 
that 


the number q of the support values (xi, yi) is 
equal to the number n of the neurons in an 

intermediate layer so that the equation system can 
be solved unambiguously. 
A method as claimed in Claim 1, characterised in 
that 


the support values (xi, yi) are approximated by 
linear regression if their number q is greater than  

 
the number n of the neurons in an intermediate 

layer. 
A method as claimed in one of Claims 1 to 3, 
characterised in that 


in approximation, a matrix structure is preset 
wherein the elements mij of the matrix on and above 

the diagonal possess the value one and those below 
the diagonal possess the value zero and 
the output function of the non-linear elements fj 
of the neurons approximately possesses the 

characteristic of a sigmoid function. 
A method as claimed in one of Claims 1 to 3, 
characterised in that 


in approximation, a matrix structure is preset 
wherein the elements mij of the matrix on and above 

the diagonal possess the value one and those below 
the diagonal possess the value -1 and 
the output function of the non-linear elements fj 
of the neurons approximately possesses the 

characteristic of a hyperbolic tangent function. 
A method as claimed in one of Claims 1 to 3, 
characterised in that 


in approximation, a matrix corresponding to a unit 
matrix is preset and 
the output function of the non-linear elements fj 
of the neurons approximately possesses the 

characteristic of a bell curve. 
A method as claimed in Claim 6, characterised in 
that 


for the logic linking operation in the neurons of a 
layer, the sum is formed of the squares of the 

input signals (x, y) superimposed with an offset 
(x0, y0). 
A method as claimed in one of the preceding claims, 
characterised in that 


in the event of a logic linking of the signals in 
the neurons of the output layer by multiplication 

or division, instead of the signal values the 
logarithm of the signal values is used to set up 

the linear equation system. 
A neural network obtainable with a method according 
to one of the preceding claims. 
</CLAIMS>
</TEXT>
</DOC>
