<DOC>
<DOCNO>EP-0611022</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Image generator
</INVENTION-TITLE>
<CLASSIFICATIONS>G09B902	G09B930	G06T1500	G06T1500	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G09B	G09B	G06T	G06T	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G09B9	G09B9	G06T15	G06T15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
An apparatus for generating an image to be displayed on a display 
screen from data defining a model including a plurality of opaque and 

translucent features. The image is intended to represent a view of the model 
from a predetermined eyepoint and is made up from an array of screen space 

pixels to be displayed by a raster scanning process. Each pixel is of uniform 
colour and intensity, and the pixels together define an image area. The image 

area is divided into an array of sub-areas each of which covers at least one 
pixel. For each feature in the model that is potentially visible from the 

eyepoint, a test is conducted to determine which of the sub-areas is at least 
partially covered by that feature. A list of feature identifiers is produced in 

respect of each sub-area, the list for any one sub-area identifying features 
which at least partially cover that sub-area. The position in screen space of 

at least one sampling point within each sub-area is determined. For each 
sub-area in turn, and for each sampling point a test is conducted to determine 

which of the features in that sub-area's list cover that sampling point. For 
each feature which covers a sampling point, a function of the di
stance from 
the eyepoint to that feature at the sampling point is determined. Feature 

describing data is stored for each sampling point within a sub-area, the stored 
data being indicative of at least the distance of the opaque feature which 

covers the sampling point and is nearest to the eyepoint and the distance and 
translucency of at least one nearer translucent feature which covers the 

sampling point. An output is produced for each sampling point within a 
sub-area, the sampling point output corresponding to the combined effects of 

the features identified by the stored data. An output for each pixel within a 
sub-area is produced, the pixel output corresponding to the combined effects 

of the sampling point outputs for all sampling points which contribute to that 
pixel, and the pixel outputs are displayed. 
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
THOMSON TRAINING 
&
 SIMULATION
</APPLICANT-NAME>
<APPLICANT-NAME>
THOMSON TRAINING 
&
 SIMULATION LIMITED
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
BAKER STEPHEN JOHN
</INVENTOR-NAME>
<INVENTOR-NAME>
COWDREY DENNIS ALAN
</INVENTOR-NAME>
<INVENTOR-NAME>
OLIVE GRAHAM JOHN
</INVENTOR-NAME>
<INVENTOR-NAME>
WOOD KARL JOSEPH
</INVENTOR-NAME>
<INVENTOR-NAME>
BAKER, STEPHEN JOHN
</INVENTOR-NAME>
<INVENTOR-NAME>
COWDREY, DENNIS ALAN
</INVENTOR-NAME>
<INVENTOR-NAME>
OLIVE, GRAHAM JOHN
</INVENTOR-NAME>
<INVENTOR-NAME>
WOOD, KARL JOSEPH
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to an image generator, and in particular
to a computer image generator suitable for generating information in real
time from which an image can be derived for display in for example a flight
simulator.Real time image generators for flight simulators are used to generate
images which are presented to pilots who are positioned in a mock aircraft
cockpit. In early systems, a visual environment was created using film or
video images obtained from a servo-driven camera that was manoeuvred
above a model of the terrain over which movement was to be simulated.
These approaches were widely used but were found to be incapable of
producing realistic scenes with true perspective from a wide range of
eyepoints. In order to overcome these limitations, image generators
producing computer generated imagery were introduced, the first
commercially successful systems appearing in the early 1970s. Such systems
are now used almost exclusively in flight simulator application, and are
usually referred to as CIG (Computer Image Generation) systems.In a CIG system, the intended viewer of the image produced by the
system, i.e. the simulator pilot, looks out through an imaginary window into
a three dimensional (3-D) world defined by information stored as geometrical
and other characteristic attribute data. A line drawn from the eyepoint
through the window intersects a point in the 3-D world. The colour and
intensity of that point must be "painted" on the window at the point of
intersection of that line with the window. The displayed image is made up
from a series of picture elements (pixels) each of which is of uniform colour
and intensity, the colour and intensity of each pixel being a function of the
position of the eyepoint relative to the 3-D world which the stored data 
represents. In a real time display where hundreds of thousands of pixels must
be updated sufficiently quickly to avoid jumping of the image, it is necessary
to perform many millions of calculations per second to maintain image
fidelity. In most simulator systems producing a wide angle display the image
is made up from three juxtaposed images each derived from a common
database but generated by a respective processing channel. The computational
load is thus shared between the three channels. We are concerned herein
with the processes within a single channel only and therefore the
interrelationship between associated channels will not be discussed.A review of the problems confronted in real time CIG systems and
various approaches
</DESCRIPTION>
<CLAIMS>
An image generator for use with an image projection system in which an

image is projected onto a display surface and the display surface is viewed from a
predetermined eyepoin (106) through an imaginary viewing plane (105) of predetermined area,

the image being projected as a series of raster scan lines each made up from a
respective row of display pixels, wherein the image generator comprises a model

database in which features (94,104,122) of the model are described by geometrical attribute data
defining the feature with reference to world space and non-geometrical attribute data

defining characteristics of the feature, means for determining an eyepoint position in
world space from which the model is to be viewed, means for transforming

geometrical attribute data from world space to eyepoint space, and means for
calculating image data to be displayed on the display surface from the transformed

geometrical attribute data and the non-geometrical attribute data,
wherein the image

data calculating means comprises:

a. means for dividing the viewing plane area into an array of sub-areas (121),
each sub-area being defined by four corner coordinates (123,124,125,126) arranged such

that a projection of the sub-area onto the display surface from the
eyepoint (106) corresponds in shape and area to a portion of the display

surface upon which a predetermined respective group of pixels is
projected,

said image data calculating means being characterized by :

b. means for defining the position of at least one sampling point (95,96) within
each sub-area, each sampling point position being defined by reference

to the corners of the respective sub-area,
c. means for determining from the transformed geometrical feature
attributes and the position of each sampling point (95,96) which of the

sampling points is covered by each of the features (94,104,122), 
d. means (22) in respect of each sampling point (95,96) for storing non-geometrical
attribute data for at least one feature (94,104,122) covering that sampling point,

and
e. means for generating from the stored attribute data an output to the
image projection system in respect of each pixel,

whereby the image data is consistent with the appearance of the model from the eyepoint.
An image generator according to Claim 1, wherein each sub-area (121) has linear
edges.
An image generator according to Claim 1 or 2, wherein each sub-area (121)
corresponds in area to a rectangular array of pixels including a plurality of rows and

columns of pixels.
An image generator according to any one of Claims 1 to 3, comprising a
plurality of sampling points (95,96) per pixel.
An image generator according to any one of Claims 1 to 4, wherein the
attribute storing means (22) comprises means in respect of each sampling point (95,96) for storing

attribute data for one opaque and at least one translucent feature covering that
sampling point.
An image generator according to any one of Claims 1 to 4, wherein the pixel
output generating means comprises means (93) for accumulating and weighting the stored

attribute data from a predetermined group of sampling points (95,96) distributed in the
vicinity of a pixel to produce the said output to the image projection system.
</CLAIMS>
</TEXT>
</DOC>
