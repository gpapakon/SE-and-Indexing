<DOC>
<DOCNO>EP-0643353</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Data processing system and method
</INVENTION-TITLE>
<CLASSIFICATIONS>G06N300	G06N304	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06N	G06N	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06N3	G06N3	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
Universally usable data processing devices and method for data processing using neural networks. Suitable logic combination of a plurality of neural networks. A first neural network (N1) is logically combined with a further neural network (N21) in such a way that input data (E0) are processed both by the first neural network (N1) and by the further neural network (N21) and the data evaluated by the further neural network (N21) are available to the first neural network as further input data (E1). 
<
IMAGE
>
</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
CIT ALCATEL
</APPLICANT-NAME>
<APPLICANT-NAME>
ALCATEL
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
JAENECKE PETER DR
</INVENTOR-NAME>
<INVENTOR-NAME>
JAENECKE, PETER, DR.
</INVENTOR-NAME>
</INVENTORS>
<CLAIMS>
A data processing system composed of a first neural
network (N1) which is an associative memory that contains the

following:

a memory matrix for the associative storage of a
predetermined number of vector pairs respectively

comprising one input vector (→
q
i
) and one pertinent output
vector (→
k
i
),
a means for the input of an input vector (→
q
i
),
a means for determining the pertinent output vector (→
k
i
)
by multiplying the input vector (→
q
i
) by the memory matrix
and performing a threshold value operation, and
a means for the output of the pertinent output vector
(→
k
i
),

characterized in that the first neural network (N1) is connected
to at least one other neural network (N21, N22, ..., N2n) which is

also an associative memory of the first neural network (N1) type,
in a manner so that the first input data (EO) are supplied to

both the first neural network (N1) and the at least one other
neural network (N21, N22, ..., N2n), where data (E11, E12,...,

E1n) which are evaluated by the at least one other neural network
(N21, N22, ..., N2n) are supplied as further input data to the

first neural network (N1).
A system as claimed in claim 1, in which the respective
evaluated data (E11, E12,..., E1n) are supplied to a decision

element (S) which, with the aid of a control information (I) that
is supplied to the decision element, determines which of the

respective evaluated data are supplied to the first neural
network (N1).
A system as claimed in claim 2, wherein the decider
element (S) calculates the data (E) to be supplied to the first

neural network (N1) from the respective evaluated data (E11,
E12,..., E1n). 
A data processing method in which first input data (EO)
are supplied to a first neural network (N1), which is designed as

an associate memory containing the following:

a memory matrix for the associative storage of a
predetermined number of vector pairs respectively

comprising one input vector (→
q
i
) and one pertinent output
vector (→
k
i
),
a means for the input of an input vector (→
q
i
),
a means for determining the pertinent output vector (→
k
i
)
by multiplying the input vector (→
q
i
) by the memory matrix
and performing a threshold value operation, and
a means for the output of the pertinent output vector (→
k
i
),

characterized in that the first input data (EO) are also supplied
to at least one other neural network (N21, N22, ..., N2n) which is

also an associative memory of the first neural network (N1) type,
and that a first evaluation of the first input data (EO) takes

place in the at least one other neural network (N21, N22, ...,
N2n) which thereby produces evaluated data (E11, E12,..., E1n),

and where these are supplied to the first neural network (N1) as
further input data for further evaluation.
A method as claimed in claim 4, in which the first neural
network (N1) and the at least one other neural network (N21,

N22, ..., N2n) are respectively designed as an associative memory
whose storage places are occupied in accordance with the random

principle.
A method as claimed in claim 5, in which during a learning
phase the storage places of the memory matrix in the at least one

other neural network (N21, N22, ..., N2n) are occupied in
accordance with the random principle, and the storage places of

the memory matrix in the first neural network (N1) are occupied
according to a fixed method. 
A method as claimed in claim 5, in which during a learning
phase the storage places of the memory matrix in the at least one

other neural network (N21, N22, ..., N2n) are trained according to
a method that is independent of the application, or are occupied

in a manner that is specific for an application, and the storage
places of the memory matrix in the first neural network (N1) are

occupied according to a fixed method.
A method as claimed in claim 4, in which every at least
one other network (N21, N22, ..., N2n) is respectively used to

process a single feature of the input data.
Use of the system claimed in claim 1 as an optical switch.
</CLAIMS>
</TEXT>
</DOC>
