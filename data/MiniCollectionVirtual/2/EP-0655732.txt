<DOC>
<DOCNO>EP-0655732</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Soft decision speech recognition
</INVENTION-TITLE>
<CLASSIFICATIONS>G10L1528	G10L1522	G10L1510	G10L1500	G10L1508	G10L1500	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G10L	G10L	G10L	G10L	G10L	G10L	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G10L15	G10L15	G10L15	G10L15	G10L15	G10L15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
The invention relates to a method and apparatus for speech recognition, 
the speech to be recognized including one or more words. Recognition is based on 

an analysis of a first and a second utterance. In accordance with the invention, the 
first utterance is compared to one or more models of speech to determine a similarity 

metric for each such comparison. The model of speech which most closely matches 
the first utterance is determined based on the one or more similarity metrics. The 

similarity metric corresponding to the most closely matching model of speech is 
analyzed to determine whether the similarity metric satisfies a first recognition 

criterion. The second utterance is compared to one or more models of speech 
associated with the most closely matching model (which may include the most 

closely matching model) to determine a second utterance similarity metric for each 
such comparison. The one or more second utterance similarity metrics are analyzed 

to determine whether the one or more metrics satisfies a second recognition criteria. 
The second utterance is recognized has the phrase corresponding to the most closely 

matching model of speech when the first and second recognition criteria are satisfied. 
The present invention has application to many problems in speech recognition 

including isolated word recognition and command spotting. An illustrative 
embodiment of the invention in the context of a cellular telephone is provided. 

Other embodiments are also discussed. 

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
AT 
&
 T CORP
</APPLICANT-NAME>
<APPLICANT-NAME>
AT
&
T CORP.
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
ATAL BISHNU SAROOP
</INVENTOR-NAME>
<INVENTOR-NAME>
HAIMI-COHEN RAZIEL
</INVENTOR-NAME>
<INVENTOR-NAME>
ROE DAVID BJORN
</INVENTOR-NAME>
<INVENTOR-NAME>
ATAL, BISHNU SAROOP
</INVENTOR-NAME>
<INVENTOR-NAME>
HAIMI-COHEN, RAZIEL
</INVENTOR-NAME>
<INVENTOR-NAME>
ROE, DAVID BJORN
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to the field of speech recognition generally
and, for example, to the detection of commands in continuous speech.A command spotting system is a speech recognition system which
monitors an audio input channel and takes a predefined action whenever a specific
utterance (the command) appears in the input. The input may contain free speech,
noise, music, etc., and generally does not comply with any a-priori known model.
For each command to be recognized by the system, the system keeps a statistical
model (for example, a template or a hidden Markov model (HMM) well known in
the art) which defines the likelihood that a given segment of input contains the
command utterance. During its operation a conventional command spotting system
continually generates conjectures (or hypotheses) about the identities and locations
of command words in the currently observed input. Each of these hypotheses is
tested against a respective command model and a score is generated for its respective
likelihood. Such a score may be determined by, for example, conventional Viterbi
scoring. If the score exceeds a threshold T, the hypothesis is considered as accepted
and the action associated with it is effected. Otherwise the conjecture is rejected.The probability distribution of the score of either a correct or a false
hypothesis depends on a variety of factors, including the speaker, the transducer and
the acoustical environment. The threshold T is usually set sufficiently high to ensure
an acceptably low false alarm rate over the whole range of expected operating
conditions. Consequently, in various adverse conditions, the scores of correct
hypotheses have a low probability of exceeding the threshold. Therefore, in these
conditions the system seems to "ignore" the user. Lowering the threshold might
solve these "local" problems, however, it may also increase the overall false alarm
rate. Therefore, in general the utility of this approach is limited.US-A-4 827 520 discloses a voice actuated control system for use in a
vehicle. If the user utters a word which is not recognised he/she can try again.GB-A-2 170 936 discloses a voice actuated system which adapts itself to
5 changing circumstances (e.g. in the transmission path between the user and the system).The present invention as claimed in claims 1 and 22 is directed to a speech recognition technique
suitable for, among other applications, command spotting in a range of operating
conditions. The present invention takes advantage of the fact that a user of
</DESCRIPTION>
<CLAIMS>
A method of recognizing a phrase based on a first and a second
utterance of the phrase, the phrase including one or more words, the method comprising

the steps of:

a. comparing (43) the first utterance to one or more models of speech
(44) to determine a similarity metric for each such comparison;
b. determining (46) which model of speech most closely matches the
first utterance based on the one or more similarity metrics;
c. determining (54) for the first utterance whether the similarity metric
corresponding to the most closely matching model of speech satisfies a first recognition

criterion, the first recognition criterion based on a first threshold level T1;
d. recognizing (55) the first utterance as the phrase corresponding to said
most closely matching model of speech when the first recognition criteria is satisfied;

   CHARACTERISED BY

e. determining (58) whether the similarity metric of the first utterance
corresponding to the most closely matching model of speech satisfies a tentative

acceptance criterion TA when the first criterion is not satisfied;
f. if the second utterance of the phrase is received within an attention
interval, comparing (43) the second utterance to one or more models of speech (44)

which correspond to a phrase associated with said most closely matching model of
speech to determine a second utterance similarity metric for each such comparison; and
g. determining (54) whether one or more of the second utterance
similarity metrics satisfy a second recognition criterion, the second recognition criterion

based on a second threshold level T2,
h. the second threshold being less than the first threshold.
The method of claim 1 wherein the step of comparing the first
utterance comprises comparing the first utterance to a model reflecting acoustic

background.
The method of claim 1 wherein the phrase corresponds to an isolated
word.
The method of claim 1 wherein (i) a model of speech which
corresponds to the phrase associated with the most closely matching model and (ii)

the most closely matching model are the same. 
The method of claim 1 wherein a model of speech reflects one or more
predetermined words.
The method of claim 5 wherein the model of speech further reflects an
acoustic background.
The method of claim 5 wherein a predetermined word comprises a
command word for a utilization device.
The method of claim 1 further comprising the step of receiving the
second utterance during a predetermined time interval.
The method of claim 8 further comprising the step of receiving the
first utterance and wherein the predetermined time interval begins at a predetermined

time after receipt of the first utterance.
The method of claim 8 further comprising the step of issuing a
prompt for the second utterance and wherein the predetermined time interval begins

at a predetermined time after issuance of the prompt. 
The method of claim 1 wherein the tentative acceptance threshold
TA and the second recognition criterion are the same.
The method of claim 1 wherein the step of determining whether the
first recognition criterion is satisfied comprises comparing the similarity metric

5 corresponding to said most closely matching model of speech to the first threshold T1. 
The method of claim 1 wherein the step of determining whether the
second recognition criterion is satisfied comprises comparing a second utterance

similarity metric to a second threshold.
The method of claim 1 wherein the step of determining whether the
first recognition criterion is satisfied comprises determining whether the similarity

metric corresponding to said most closely matching model of speech satisfies a first
threshold and wherein the step of determining whether the second recognition

criterion is satisfied comprises determining whether a second utterance similarity
metric satisfies a second threshold.
The method of claim 1 wherein the tentative acceptance threshold TA and the second threshold are the same.
The method of claim 1 wherein the first recognition criterion is based
on the phrase to be recognized.
The method of claim 1 wherein the second recognition criterion is
based on the phrase to be recognized.
The method of claim 1 wherein the first recognition criterion is based
on a state of a utilization device.
The method of claim 1 wherein the second recognition criterion is
based on a state of a utilization device.
The method of claim 1 wherein the steps are implemented in a
telecommunications network to facilitate operation of a network service. 
The method of claim 1 wherein the steps are implemented in a
computer to facilitate operation of the computer.  
An apparatus for recognizing a phrase based on a first and a second
utterance of the phrase, the phrase including one or more words, the speech recognizer

comprising:

a. means (43) for comparing the first utterance to one or more models of
speech (44) to determine a similarity metric for each such comparison;
b. means (46) for determining which model of speech most closely
matches the first utterance based on the one or more similarity metrics;
c. means for determining (54) for the first utterance whether the
similarity metric corresponding to the most closely matching model of speech satisfies a

first recognition criterion, the first recognition criterion based on a first threshold level
T1;
d. means for recognizing (55) the first utterance as the phrase
corresponding to said most closely matching model of speech when the first recognition

criteria is satisfied;

   CHARACTERISED BY

e. means for determining (58) whether the similarity metric of the first
utterance corresponding to the most closely matching model of speech satisfies a

tentative acceptance criterion when the first criterion is not satisfied;
f. means for determining (52) whether the second utterance is received
within an attention interval;
g. means (43) for comparing the second utterance to one or more models
of speech (44) which correspond to a phrase associated with said most closely matching

model of speech to determine a second utterance similarity metric for each such
comparison if the second utterance is received within the attention interval; and
h. means for determining (54) whether one or more of the second
utterance similarity metrics satisfy a second recognition criterion, the second

recognition criterion based on a second threshold level T2. and the determining means
being responsive to the determining means of step f. so that if the second utterance is

received within the attention interval, the second threshold is less than the first
threshold.
The apparatus of claim 22 wherein the means for comparing the first
utterance comprises means for comparing the first utterance to a model reflecting

acoustic background.
The apparatus of claim 22 wherein (i) a model of speech which
corresponds to the phrase associated with the most closely matching model and 
(ii)

the most closely matching model are the same. 
The apparatus of claim 22 wherein a model of speech reflects one or
more predetermined words.
The apparatus of claim 25 wherein the model of speech further
reflects an acoustic background.
The apparatus of claim 25 wherein a predetermined word comprises a
command word for a utilization device.
The apparatus of claim 22 further comprising means for receiving the
second utterance during a predetermined time interval.
The apparatus of claim 28 further comprising means for receiving the
first utterance and wherein the predetermined time interval begins at a predetermined

time after receipt of the first utterance.
The apparatus of claim 28 further comprising means for issuing a
prompt for the second utterance and wherein the predetermined time interval begins

at a predetermined time after issuance of the prompt.
The apparatus of claim 22 wherein the tentative acceptance threshold
TA and the second recognition criterion are the same.
The apparatus of claim 22 wherein the means for determining
whether the first recognition criterion is satisfied comprises means for comparing the

similarity metric corresponding to said most closely matching model of speech to a
first threshold. 
The apparatus of claim 22 wherein the means for determining
whether the second recognition criterion is satisfied comprises means for comparing

a second utterance similarity metric to a second threshold.
The apparatus of claim 22 wherein the means for determining
whether the first recognition criterion is satisfied comprises means for determining

whether the similarity metric corresponding to said most closely matching model of
speech satisfies a first threshold and wherein the means for determining whether a

second recognition criterion is satisfied comprises means for determining whether a
second utterance similarity metric satisfies a second threshold.
The apparatus of claim 34 wherein the tentative acceptance threshold
TA and the second threshold are the same.
The apparatus of claim 22 wherein the first recognition criterion is
based on the phrase to be recognized.
The apparatus of claim 22 wherein the second recognition criterion is
based on the phrase to be recognized.
The apparatus of claim 22 wherein the first
recognition criterion is based on a state of a utilization

device.
The apparatus of claim 22 wherein the second
recognition criterion is based on a state of a utilization

device.  
A telephone comprising:

1. a microphone;
2. apparatus as claimed in any of claims 22 to 39 for recognizing a
phrase based on first and second utterances received from the microphone;
3. a telephone circuit for providing telephone operation in response to
said recognized second utterance.
</CLAIMS>
</TEXT>
</DOC>
