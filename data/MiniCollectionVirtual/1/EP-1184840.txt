<DOC>
<DOCNO>EP-1184840</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Discriminative utterance verification for connected digits recognition
</INVENTION-TITLE>
<CLASSIFICATIONS>G10L1506	G10L1514	G10L1500	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G10L	G10L	G10L	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G10L15	G10L15	G10L15	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
In a speech recognition system, a recognition
processor receives an unknown utterance signal as input.

The recognition processor in response to the unknown
utterance signal input accesses a recognition database

and scores the utterance signal against recognition
models in the recognition database to classify the

unknown utterance and to generate a hypothesis speech
signal. A verification processor receives the hypothesis

speech signal as input to be verified. The verification
processor accesses a verification database to test the

hypothesis speech signal against verification models
reflecting a preselected type of training stored in the

verification database. Based on the verification test,
the verification processor generates a confidence measure

signal. The confidence measure signal can be compared
against a verification threshold to determine the

accuracy of the recognition decision made by the
recognition processor.


</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
AT 
&
 T CORP
</APPLICANT-NAME>
<APPLICANT-NAME>
AT
&
T CORP.
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
CHOU WU
</INVENTOR-NAME>
<INVENTOR-NAME>
JUANG BIING-HWANG
</INVENTOR-NAME>
<INVENTOR-NAME>
LEE CHIN-HUI
</INVENTOR-NAME>
<INVENTOR-NAME>
RAHIM MAZING
</INVENTOR-NAME>
<INVENTOR-NAME>
CHOU, WU
</INVENTOR-NAME>
<INVENTOR-NAME>
JUANG, BIING-HWANG
</INVENTOR-NAME>
<INVENTOR-NAME>
LEE, CHIN-HUI
</INVENTOR-NAME>
<INVENTOR-NAME>
RAHIM, MAZING
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to the field of
speech recognition and verification generally, and more
particularly to the field of speech verification
training.Speech recognition is a process in which an
unknown spoken utterance is identified. Through a
process known as training, known words or word strings
are examined and features of the words or word strings
are sampled and recorded as recognition models in a
speech recognizer memory. The recognition models
represent typical acoustic renditions of known
utterances. In the training process, a training
algorithm is applied to the recognition models to form
these stored representations which will be utilized to
recognize future unknown words and strings of words.In operation, a speech recognizer receives an
unknown utterance and extracts features from an unknown 
utterance in order to recognize the unknown utterance.
The extracted features of the unknown utterance are
referred to as a test pattern.The recognizer then compares combinations of
one or more recognition models in memory to the test
pattern for the unknown utterance. A scoring technique
is used to provide a relative measure of how well each
combination of recognition models matches the test
pattern. The unknown utterance is recognized as the
words associated with the combination of one or more
recognition processor models that most clearly matches
the unknown utterance.Previous speech recognition practice has
utilized a number "N" of valid possibilities or classes
for speech recognition modeling and model training. In
such an N-class model, all utterance input to be
recognized is assumed to be valid. A recognition model
for each of the "N" possible classes of existence is
stored in a recognizer memory. All speech input to be
recognized, whether valid or not, is classified as one of
the N classes. The recognizer calculates a score for the
utterance for each of the N models, and matches the 
utterance to the one class (of the N classes) having the
best score.The concept of an additional or "N+1" class, in
addition to the N valid classes of recognition, has been
developed to provide an associated N+1 model (denoted a
"filler" model). In such a system, the input utterance
to be recognized is scored against each of the N models
for the N valid classes of input and, additionally,
against the N+1 filler class model. The N+1 model is
designed to represent all invalid input. Use of an N+1
filler model further refined the recognition process to
consider that an input utterance or a segment of an input
u
</DESCRIPTION>
<CLAIMS>
A speech recognition system for recognizing a string of connected
spoken words, comprising:


a recognition processor (10) for generating a hypothesis string signal
representing an unknown speech utterance responsive to an acoustic input string of

connected spoken words;
a recognition database (12) for storing recognition models;
a verification processor (14) for generating a string-based confidence
measure signal responsive to the hypothesis string signal representing an unknown

speech utterance; and
a verification database (16) for storing verification models;
further containing
means, coupled to the verification processor, for calculating a verification
threshold signal value of a string-based confidence measure signal;
means for measuring the string-based confidence measure signal to
generate a measured signal value; and
means for comparing the measured signal value to the threshold signal
value.
A speech recognition system according to claim 11, wherein:

   the verification models comprise a set of hidden Markov model
parameters.
A speech recognition system according to claim 1 or claim 2, wherein:

   the verification models are selected from the group consisting of
keyword models, anti-keyword models, acoustic filler models, and combinations

thereof.
A speech recognition system according to any of the preceding claims,
wherein:

   the verification models reflect discriminative training. 
A speech recognition system according to any of the preceding claims,
wherein:


the hypothesis string signal comprises a segmented series of word
signals; and
the verification processor comprises
means for calculating a word-based confidence score for each word
signal of the segmented series; and
means for generating the string-based confidence measure signal
responsive to an average of the word-based confidence scores for each word signal of

the segmented series.
A speech signal processing method for generating a verification
threshold signal sample of a confidence measure signal generated by a verification

processor for a speech recognition system, comprising the following steps:

(A) performing a round of operating the verification processor to

(i) generate a first string-based confidence measure signal based on a
known hypothesis string signal representing a known speech utterance and a current

verification model for the known hypothesis string signal representing a known speech
utterance, and
(ii) generate one or more other string-based confidence measure signals,
each such string-based confidence measure signal based on the known hypothesis string

signal representing a known speech utterance and another verification model;
(B) repeating step (A) for a preselected number of rounds;
(C) recording a first distribution of first string-based confidence measure
signal values for the preselected number of rounds;
(D) recording a second distribution of the one or more other string-based
confidence measure signal values for the preselected number of rounds;
(E) calculating a first mean for the first distribution;
(F) calculating a second mean for the second distribution; and
(G) generating the verification threshold signal sample based on the first
mean and the second mean.
A method according to claim 6, further comprising the steps:

selecting a false rejection verification error rate; 
selecting a false acceptance verification error rate; and
estimating an initial verification threshold signal value based on the
selected false rejection verification error rate and the selected false acceptance

verification error rate.
A method according to claim 7, further comprising the steps of:

generating the verification threshold signal value while the speech
recognition system is operating; and
maintaining the false rejection verification error rate and the false
acceptance verification error rate while the recognition system is operating.
</CLAIMS>
</TEXT>
</DOC>
