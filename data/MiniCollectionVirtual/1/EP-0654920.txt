<DOC>
<DOCNO>EP-0654920</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Method for the efficient updating of the hash value of a data file
</INVENTION-TITLE>
<CLASSIFICATIONS>G06F2124	H04L932	H04L932	G06F100	G06F2100	G09C100	G09C100	G06F2100	G06F100	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G06F	H04L	H04L	G06F	G06F	G09C	G09C	G06F	G06F	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G06F21	H04L9	H04L9	G06F1	G06F21	G09C1	G09C1	G06F21	G06F1	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
The disclosed methodology permits an insecure computing system to
safely perform high security electronic financial transactions. The present

invention permits the hash of a file to be taken on an incremental basis. It
permits any part of the file to be changed while allowing a new aggregate hash

to be computed based on the revised file portion and the prior total hash. The
aggregate hash is readily updatable with each record revision without having to

recompute the hash of the entire file in accordance with conventional
techniques. These objectives using two functions. The first function is an

effective one-way hash function "H" for which it is computationally impossible
to find two data values that hash to the same result. The second function is a

commutative and associative function "F" (and inverse "Finv") and provides a
mechanism for combining the aggregate hash and the hash of updated records.

Examples of these latter functions include exclusive OR ("XOR"), and
arithmetic addition. The methodology involves combining the hash of each file

record and the hash of an identification of the record (i.e., a record number or
key). These hashes are combined using a function ("F") whereby individual

records may be extracted using the inverse of that function (Finv). In this
fashion, an individual record may be extracted from the aggregate hash and

updated. With each update, the file hash as computed according to this
invention is preferably also written after being encrypted under a key known

only to the valid user, or if it is digitally signed by the valid user or if it is
held in a tamper resistant storage. Each record is represented by its

identification hashed together with its data content. All such record are added
together to provide a highly secure integrity check. This aggregate hash

reflects the entire database such that the tampering (or rearranging) of any data
record is revealed by the use of the record identifier (i.e., record number) in

the hash calculation due to its impact on the aggregate hash (e.g., the sum).

</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
FISCHER ADDISON M
</APPLICANT-NAME>
<APPLICANT-NAME>
FISCHER, ADDISON M.
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
FISCHER ADDISON M
</INVENTOR-NAME>
<INVENTOR-NAME>
FISCHER, ADDISON M.
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
This invention generally relates to computer data security. More particularly, it relates to methodology for generating the hash of a file which is periodically updated.Particularly, with the advent of electronic business transactions, ensuring the privacy and integrity of workstation data (whether it is generated by a laptop computer, a mainframe terminal, a stand-alone PC, or any type of computer network workstation), is critically important. For example, many users of laptop computers encrypt all hard drive data to ensure data privacy. The encryption hides the data from unintended disclosure.In and of itself, the encryption does not ensure data integrity. For example, encryption does not prevent an opponent that can gain surreptitious access to the computer from running a special sabotage program which -- although being unable to make sense of a particular piece of encrypted data -- may attempt to randomly over-write the encrypted data with other possibly random information, thereby causing erroneous analysis when the data is eventually decrypted for input to other processes.Depending on the encryption protocol, the type of file that was damaged, and how it was damaged, it is possible that this alteration may go undetected and lead to fallacious results when the data is processed by the proper owner. It is especially easy for this to occur, for example, if the damaged data contains binary numerical data. The owner may be led to erroneous action by incorrect results.It is well-known that file integrity may be protected by taking a one-way hash (e.g., by using MD5 or the secure hash algorithm SHA) over the contents of the file. By implementing and checking a currently computed hash value, with a previously stored hash value, correct file integrity assures the threat of malicious tampering (or even accidental external modification) can be detected - thereby improving the reliability and security of ultimate results. Assuming it is stored in a way that preserves its own integrity, the file hash can be used to insure that the entire file has not been damaged or deliberately tampered.Such a hash can be computed when the file is processed sequentially. The hash can be computed when (or as) the file is sequentially built; and then checked again whenever the file is used. Provided that the hash value is protected from alteration -- such as by being encrypted by a key known only to the user, or by being digitally signed in a way trusted by the user, or by being stored in a trusted token device, the user can be
</DESCRIPTION>
<CLAIMS>
A method for protecting collections of a plurality of discrete data units which are modified from time to time by an associated data processing system including obtaining a hash value for each of the discrete data units by performing a first function, which is a one-way hash function for which it is computationally impossible to find two data values that hash to the same result using at least the data value portion of the data unit which is to be protected, wherein the step of obtaining a hash valve includes the step of including as part of the data to be hashed for each data unit, indicia which distinguishes the relative order of each data unit from the other data units; and

aggregating said hash value of each discrete unit of data using a second function which permits the independent inclusion and deletion of each individual hash value from the aggregate hash value.
A method according to claim 1, further including the step of deleting an individual hash value using the inverse of said second function.
A method according to claim 1, further including the step of updating one of said discrete data units, and

operating on said aggregate hash value using the inverse of said second function.
A method according to claim 1, wherein said indicia is one of a plurality of sequentially ordered data unit numbers.
A method according to claim 1, wherein said indicia is a key value used to associatively index said discrete data units.
A method according to claim 1, wherein said discrete data units are bytes.
A method according to claim 1, wherein said discrete data units are sectors.
A method according to claim 1, further including:

performing said first function on a first data group and indicia identifying said first group;
performing said second function on a second data group and indicia identifying said second group; and
combining the hashes to determine an aggregate hash using said second function whereby said hash of said first group and said hash of said second group may be subsequently extracted from the aggregate hash using the inverse of said other function.
A method according to claim 8, wherein said step of performing an update operation includes the step of:

operating on said aggregate hash using the inverse of said second function.
A method according to claim 8, wherein said step of computing the hash uses indicia identifying said first data group and indicia identifying said second data group.
A method according to claim 1 or 8, wherein said discrete data units or first data group and second data group are records.
A method according to claim 1, further including maintaining a validity indicator of an updatable data file including a plurality of data units and having an associated file hash comprising the steps of:

accessing said file hash;
updating one of said plurality of data units to generate an updated data unit; and
computing an aggregate hash using the updated data unit by applying said second function having both associative and commutative properties to the aggregate hash and the updated data unit.
A method according to claim 1, further including:

combining the informational content of a data record with a record identifier to determine an aggregate data string;
performing said first function on said aggregate data string to determine a hash value; and
applying said second function having both associative and commutative properties to said hash value.
A method according to any one of claims 1, 8, 12, or 13, further including the step of associating a data structure with at least one discrete data unit, or at least one of said first data group and said second data group, or group or data record for use if the data processing system is interrupted while updates for said data unit, group, or record are underway.
A method according to claim 14, further including the step of providing said data structure with a field for identifying an updating operation to be performed on said unit or group.
A method according to claim 14, further including the step of providing said data structure with a field for identifying a revised version of an aggregate hash.
A method according to claim 14, further including the step of providing said data structure with a field for storing the hash of fields in said data structure.
A method according to claim 14, further including the step of encrypting at least part of said structure.
A method according to any one of claims 1, 8, 12, or 16, further including the step of storing said aggregate hash.
A method according to any one of claims 1, 8, 12, or 16, further including the step of storing said aggregate hash such that it can not be modified by anyone other than an authorized user.
A method according to any one of claims 1, 8, 12 or 13, wherein said second function is an exclusive OR operation.
A method according to any one of claims 1, 8, 12 or 13, wherein said second function is an addition operation.
</CLAIMS>
</TEXT>
</DOC>
