<DOC>
<DOCNO>EP-0649260</DOCNO> 
<TEXT>
<INVENTION-TITLE>
Method for expressing and restoring image data.
</INVENTION-TITLE>
<CLASSIFICATIONS>G01R3100	G01R3100	G06T300	G06T300	G06T900	G06T900	G06T920	G06T920	H04N141	H04N141	H04N726	H04N726	</CLASSIFICATIONS>
<CLASSIFICATIONS-THIRD>G01R	G01R	G06T	G06T	G06T	G06T	G06T	G06T	H04N	H04N	H04N	H04N	</CLASSIFICATIONS-THIRD>
<CLASSIFICATIONS-FOURTH>G01R31	G01R31	G06T3	G06T3	G06T9	G06T9	G06T9	G06T9	H04N1	H04N1	H04N7	H04N7	</CLASSIFICATIONS-FOURTH>
<ABSTRACT>
A method for expressing image data and for image restoration 
does not depend on the format of input/output devices, does 

not suffer from block distortion in the restored image, 
provides superior scale ability, and can be easily applied 

to motion pictures. The distribution of a pixel feature, 
such as luminance or chrominance, in a two dimensional (x,y) 

image space is expressed by contours, 
i.e.
 an isoluminance 
line or a line of equal color difference, on a curved 

surface with the feature along a z-axis. When restoring 

image data, regions between contours of the feature and 
regions in which peaks or saddles exist, even if the 

contours do not accompany them, are feature interpolated, 
and said curved surface is reproduced as a surface of a 

polyhedron, wherein the contour is a contour of a cross-sectional 
area of a curved surface that represents an image 

in x-y-z space in which the two-dimensional image on x-y 
plane is combined with the feature along z-axis. 


</ABSTRACT>
<APPLICANTS>
<APPLICANT-NAME>
HEWLETT PACKARD CO
</APPLICANT-NAME>
<APPLICANT-NAME>
HEWLETT-PACKARD COMPANY
</APPLICANT-NAME>
</APPLICANTS>
<INVENTORS>
<INVENTOR-NAME>
KAMAE TAKAHIKO
</INVENTOR-NAME>
<INVENTOR-NAME>
YAMAMOTO AKIO
</INVENTOR-NAME>
<INVENTOR-NAME>
KAMAE, TAKAHIKO
</INVENTOR-NAME>
<INVENTOR-NAME>
YAMAMOTO, AKIO
</INVENTOR-NAME>
</INVENTORS>
<DESCRIPTION>
The present invention relates to a method for expressing and 
restoring image data, for example to a method for image 
expression and image restoration that does not depend on the 
image input/output devices, that does not suffer from block 
distortion in the restored image, that provides superior 
scale ability, and that is readily applied to motion video 
data. In recent years, developments in large scale integrated 
circuit technology have enabled advances in electronics at 
a rapidly increasing pace. With the development inexpensive, 
large capacity storage media having fast access times, it 
has become easy to process a large volume of data quickly. 
Images, including image information such as motion 
pictures, which were in the past mainly processed as analog 
signals are now progressively processed in a digital format. 
It has also become possible to combine text data and digital 
audio signals with digital images on a computer, 
creating so-called multimedia technology. Further, through 
the digitization of images it has also become easy, for 
example, to modify and/or process information, such that 
digital imaging technologies are increasingly applied to a 
variety of applications, such as movies, printing, and 
medical services. As a result of these developments, the use of image data in 
each application has advanced the "multi-use" of 
information. For example, image data used in one 
application is often reused for another application, 
bringing about the interactive exchange of image information 
and data between respective applications. It is therefore essential that common digital image 
technology is established to advance the interactive use of  
 
image information. Because items such as the required 
resolution, gradation, and number of colors are respectively 
different for each application in which a digital image is 
used, it is necessary to bring about a systemization of 
technologies and harmonization of standards to enhance 
the degree of hierarchical scale ability by formats, 
and thereby provide a common encoding algorithm. 
However, at present the format of the digital image depends 
on such factors as the input or output device. This is one 
obstruction to the progress of interactive image 
information. Furthermore, even when the digital image is only used 
within a specific application, if the format of the image 
data heavily depends on a particular input or output device, 
data use is also greatly hindered. For example, if a camera 
is used as the image data input
</DESCRIPTION>
<CLAIMS>
A method for image transmission and/or storage, said 
method comprising the step of: 

   expressing image data, wherein said image data spreads 
over a two-dimensional figure on an x-y plane accompanied by 

a data image pixel feature in a third dimension z, said 
expressing step comprising the steps of: 

   providing a three-dimensional (x-y-z) curved surface 
z=f(x,y) where f is a single valued function; 

   slicing said curved surface to obtain cross-sectional 
areas that are perpendicular to said z-axis at z=z0, z1, z2, 

...., zN, where N is zero or a positive integer; 
   creating at least one polygon that approximates 

contours of said cross-sectional areas; and 
   vector coding said at least one polygon. 
The method of Claim 1, further comprising the steps of: 
   restoring said image data from said at least one vector 

coded polygon as a polyhedron z=g(x,y); 
   computing a first error curved surface z=g(x,y)-f(x,y)=h(x,y); 

   slicing said first error curved surface to obtain 
cross-sectional error areas perpendicular to said z-axis at 

a predetermined plurality of levels; 
   creating error polygons that approximate contours of 

said cross-sectional error areas; 
   vector coding said polygons; and

 
   repeating said restoration, computation, slicing, 

creation, and vector coding steps recursively for a 
predetermined time, where a value f(x,y) is replaced by a 

previously computed value h(x,y), and a value h(x,y) is 
successively replaced by a previous value h(x,y) in said 

computation. 
The method of Claim 2, wherein said error curved surface 
z=h(x,y) is split into a non-negative valued function 

z=h1(x,y) and a negative valued function z=h2(x,y). 
The method of any of Claims 1 to 3, further comprising 
the step of: 

   reproducing said curved surface as a polyhedron by 
feature interpolation of regions between said contour lines 

and of regions in which peaks or saddles exist without 
coinciding contour lines. 
The method of any of Claims 1 to 4, wherein said curved 
surface is reproduced as a polygon by covering said regions 

between contour lines with any of triangular and 
quadrangular patches to interpolate feature values. 
The method of any of Claims 1 to 5, wherein said 
feature is luminance, and wherein said feature takes only 

two values that are interchangeably assigned to regions 
separated by a contour line. 
A method for restoring image data especially in 
accordance with the method of any of Claims 1 to 6, wherein 

said image data is spread on an x-y plane of an x-y-z 
coordinate system and forms a curved surface z=f(x,y), the 

method comprising the steps of: 
   providing an input set of polygons that respectively 

approximate contours of cross sectional areas that are 
perpendicular to a feature axis (z-axis) at mutually 

different levels; and 
   connecting mutually adjacent polygons by plane patches 

to form a tube. 
The method of Claim 7, wherein said providing step 
further comprises the steps of: 

   providing one of said polygons; and 
   modifying said one of said polygons by subtracting 

errors in coding to said polygons. 
The method of Claims 7 or 8, wherein said connecting 
step further comprises: 

   estimating a saddle point of a bifurcation on said 
curved surface. 
A method for expressing and restoring an image 
especially in accordance with any of Claims 1 to 

9,comprising the steps of: 
   representing said image as a two-dimensional figure in 

which image pixels accompany corresponding feature values to 
 

form a three-dimensional curved surface in which the z-axis 
in an x-y-z coordinate system is a feature axis; 

   slicing said curved surface to obtain contour lines 
that are perpendicular to said z-axis at a plurality of z 

values; 
   transmitting data relating to said contour lines; 

   receiving and approximating each of said contour lines 
to corresponding polygons that approximate said contour 

lines; and 
   paving a region between two mutually adjacent polygons 

by plane patches. 
A method for expressing motion in a dynamic image 
especially in accordnace with any of Claims 1 to 10, 

comprising the steps of: 
   representing a series of frames, each of said frames 

including a time stamped image at a time instant, wherein 
said time stamped image is represented by a curved surface 

in a three-dimensional x-y-z coordinate system in which said 
time stamped image is figured on an x-y plane and a feature 

of said time stamped image is measured on a z-axis; 
   slicing each said curved surface to obtain a cross-sectional 

area perpendicular to said z-axis at a level on 
said z-axis; 

   computing a center of gravity of corresponding to each 

of said cross-sectional areas in at least two of said time 
stamped images; and

 
   translating said cross-sectional area from locations of 

said centers of gravity based on said dynamic image. 
The method of Claim 11, further comprising the steps 
of: 

   moving one of said cross-sectional areas along said 
translation to reach coincidence of a center of gravity of 

said one cross-sectional area with a center of gravity of 
another corresponding cross-sectional area; 

   rotating said one of said cross-sectional areas around 
said common center of gravity to obtain a maximum overlap on 

said another corresponding cross-sectional area; and 
   determining rotation of said cross-sectional area from 

an angle of rotation. 
</CLAIMS>
</TEXT>
</DOC>
